{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkashB7/Self-Evolving-Neural-Network-Model-for-Multiclass-Classification/blob/main/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-7C1rgQMcCY",
        "outputId": "e97380d8-16df-4606-9626-1f87405469d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Output (d):\n",
            "[[0.0222042 ]\n",
            " [0.9510067 ]\n",
            " [0.94840088]\n",
            " [0.06049689]]\n",
            "Actual Output (y):\n",
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n",
            "Mean of Predicted Output (E(d)): 0.49552716889603016\n",
            "Mean of Predicted Output Squared (E(d^2)): 0.45200771928163413\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.weights1 = np.random.randn(self.input_dim, self.hidden_dim)\n",
        "        self.weights2 = np.random.randn(self.hidden_dim, self.output_dim)\n",
        "\n",
        "        self.bias1 = np.zeros((1, self.hidden_dim))\n",
        "        self.bias2 = np.zeros((1, self.output_dim))\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.hidden_layer = np.dot(X, self.weights1) + self.bias1\n",
        "        self.hidden_activation = self.sigmoid(self.hidden_layer)\n",
        "        self.output_layer = np.dot(self.hidden_activation, self.weights2) + self.bias2\n",
        "        self.predicted_output = self.sigmoid(self.output_layer)\n",
        "\n",
        "    def backward(self, X, y, learning_rate):\n",
        "        error = self.predicted_output - y\n",
        "\n",
        "        d_output = error * self.sigmoid_derivative(self.predicted_output)\n",
        "        d_hidden = np.dot(d_output, self.weights2.T) * self.sigmoid_derivative(self.hidden_activation)\n",
        "\n",
        "        self.weights2 -= learning_rate * np.dot(self.hidden_activation.T, d_output)\n",
        "        self.bias2 -= learning_rate * np.sum(d_output, axis=0, keepdims=True)\n",
        "        self.weights1 -= learning_rate * np.dot(X.T, d_hidden)\n",
        "        self.bias1 -= learning_rate * np.sum(d_hidden, axis=0, keepdims=True)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "mlp = MLP(2, 4, 1)\n",
        "\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    mlp.forward(X)\n",
        "\n",
        "    mlp.backward(X, y, learning_rate)\n",
        "\n",
        "mlp.forward(X)\n",
        "d = mlp.predicted_output\n",
        "y_actual = y\n",
        "\n",
        "E_d = np.mean(d)\n",
        "E_d_squared = np.mean(d**2)\n",
        "\n",
        "print(\"Predicted Output (d):\")\n",
        "print(d)\n",
        "print(\"Actual Output (y):\")\n",
        "print(y_actual)\n",
        "print(\"Mean of Predicted Output (E(d)):\", E_d)\n",
        "print(\"Mean of Predicted Output Squared (E(d^2)):\", E_d_squared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTWKiIMnlKSP",
        "outputId": "369e3c20-7428-48eb-8afa-cc590d3de319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of Predicted Output (E(d)):  0.12738908483304806\n",
            "Mean of Predicted Output Squared (E(d^2)):  0.0933277094922941\n",
            "400\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "input_size = 10\n",
        "hidden_size = 5\n",
        "output_size = 1\n",
        "\n",
        "def forward_propagation(X, weights):\n",
        "    z1 = np.dot(X, weights['W1'])\n",
        "    a1 = sigmoid(z1)\n",
        "\n",
        "    z2 = np.dot(a1, weights['W2'])\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    return a1, a2\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def mse_loss(y_pred, y_true):\n",
        "    return np.mean((y_pred - y_true) ** 2)\n",
        "\n",
        "def backward_propagation(X, y_true, weights, a1, a2):\n",
        "    delta2 = (a2 - y_true) * sigmoid_derivative(a2)\n",
        "    dW2 = np.dot(a1.T, delta2)\n",
        "\n",
        "    delta1 = np.dot(delta2, weights['W2'].T) * sigmoid_derivative(a1)\n",
        "    dW1 = np.dot(X.T, delta1)\n",
        "\n",
        "    return {'W1': dW1, 'W2': dW2}\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "X = np.random.randn(400, input_size)\n",
        "y_true = np.random.randn(400, output_size)\n",
        "\n",
        "weights = {\n",
        "    'W1': np.random.randn(input_size, hidden_size),\n",
        "    'W2': np.random.randn(hidden_size, output_size)\n",
        "}\n",
        "\n",
        "learning_rate = 0.1\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    a1, a2 = forward_propagation(X, weights)\n",
        "\n",
        "    gradients = backward_propagation(X, y_true, weights, a1, a2)\n",
        "\n",
        "    weights['W1'] -= learning_rate * gradients['W1']\n",
        "    weights['W2'] -= learning_rate * gradients['W2']\n",
        "\n",
        "_, y_pred = forward_propagation(X, weights)\n",
        "\n",
        "E_d = np.mean(y_pred)\n",
        "E_d_squared = np.mean(y_pred ** 2)\n",
        "\n",
        "print(\"Mean of Predicted Output (E(d)): \", E_d)\n",
        "print(\"Mean of Predicted Output Squared (E(d^2)): \", E_d_squared)\n",
        "\n",
        "print(X.shape[0])\n",
        "print(X.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOnkDh3aKtX-",
        "outputId": "2b28d323-b0a7-4b80-e711-1a7f732fa756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Output (d):\n",
            "[[0.09611195]\n",
            " [0.0066334 ]\n",
            " [0.05475127]\n",
            " [0.01899855]\n",
            " [0.0238622 ]\n",
            " [0.03091592]\n",
            " [0.02693625]\n",
            " [0.0274587 ]\n",
            " [0.01194565]\n",
            " [0.0074861 ]\n",
            " [0.05344164]\n",
            " [0.01495646]\n",
            " [0.03843164]\n",
            " [0.00747351]\n",
            " [0.01291976]\n",
            " [0.0310117 ]\n",
            " [0.00595011]\n",
            " [0.02932019]\n",
            " [0.09510114]\n",
            " [0.04086157]\n",
            " [0.02477996]\n",
            " [0.03953478]\n",
            " [0.02826289]\n",
            " [0.10406524]\n",
            " [0.11450218]\n",
            " [0.04880297]\n",
            " [0.01999538]\n",
            " [0.04359055]\n",
            " [0.13992056]\n",
            " [0.01345931]\n",
            " [0.00879658]\n",
            " [0.08217739]\n",
            " [0.00899606]\n",
            " [0.01177305]\n",
            " [0.02223105]\n",
            " [0.07105182]\n",
            " [0.0064216 ]\n",
            " [0.05051498]\n",
            " [0.03961177]\n",
            " [0.01299844]\n",
            " [0.05072176]\n",
            " [0.01124446]\n",
            " [0.00579808]\n",
            " [0.03094606]\n",
            " [0.0423006 ]\n",
            " [0.01035384]\n",
            " [0.00870973]\n",
            " [0.12570046]\n",
            " [0.0433678 ]\n",
            " [0.01553592]\n",
            " [0.04237958]\n",
            " [0.08238271]\n",
            " [0.00898794]\n",
            " [0.02092431]\n",
            " [0.02278914]\n",
            " [0.03335939]\n",
            " [0.09820151]\n",
            " [0.03229863]\n",
            " [0.04503394]\n",
            " [0.02332039]\n",
            " [0.02017143]\n",
            " [0.03424238]\n",
            " [0.10201379]\n",
            " [0.0478735 ]\n",
            " [0.02809467]\n",
            " [0.07712682]\n",
            " [0.04683266]\n",
            " [0.01339988]\n",
            " [0.02286523]\n",
            " [0.02284007]\n",
            " [0.02541611]\n",
            " [0.03051446]\n",
            " [0.02276517]\n",
            " [0.17266111]\n",
            " [0.16419138]\n",
            " [0.08081635]\n",
            " [0.024268  ]\n",
            " [0.11451897]\n",
            " [0.02500003]\n",
            " [0.01995869]\n",
            " [0.08660974]\n",
            " [0.03985309]\n",
            " [0.03462791]\n",
            " [0.07449414]\n",
            " [0.03217228]\n",
            " [0.05476943]\n",
            " [0.01798042]\n",
            " [0.12654203]\n",
            " [0.02019118]\n",
            " [0.20240101]\n",
            " [0.04023944]\n",
            " [0.10977111]\n",
            " [0.06471381]\n",
            " [0.0208349 ]\n",
            " [0.05389851]\n",
            " [0.03001545]\n",
            " [0.03964769]\n",
            " [0.07329878]\n",
            " [0.00782874]\n",
            " [0.04143354]\n",
            " [0.04608398]\n",
            " [0.027143  ]\n",
            " [0.14121294]\n",
            " [0.15942357]\n",
            " [0.04165879]\n",
            " [0.00810921]\n",
            " [0.0344429 ]\n",
            " [0.00847828]\n",
            " [0.01130519]\n",
            " [0.0219579 ]\n",
            " [0.02254716]\n",
            " [0.03496216]\n",
            " [0.05340303]\n",
            " [0.0162134 ]\n",
            " [0.03281741]\n",
            " [0.03603632]\n",
            " [0.03599756]\n",
            " [0.02744916]\n",
            " [0.03021601]\n",
            " [0.07273834]\n",
            " [0.04945245]\n",
            " [0.01703143]\n",
            " [0.03046064]\n",
            " [0.00720866]\n",
            " [0.01121208]\n",
            " [0.02152291]\n",
            " [0.02396392]\n",
            " [0.02892225]\n",
            " [0.0574703 ]\n",
            " [0.02595167]\n",
            " [0.04349968]\n",
            " [0.03926104]\n",
            " [0.04666275]\n",
            " [0.009304  ]\n",
            " [0.00882142]\n",
            " [0.01300994]\n",
            " [0.04683194]\n",
            " [0.03810714]\n",
            " [0.04742637]\n",
            " [0.00862886]\n",
            " [0.02559222]\n",
            " [0.01407086]\n",
            " [0.13713048]\n",
            " [0.00513744]\n",
            " [0.004482  ]\n",
            " [0.0086655 ]\n",
            " [0.10125399]\n",
            " [0.03737282]\n",
            " [0.01619041]\n",
            " [0.12754746]\n",
            " [0.00891091]\n",
            " [0.02075188]\n",
            " [0.04534643]\n",
            " [0.00704497]\n",
            " [0.03417694]\n",
            " [0.02062333]\n",
            " [0.09813131]\n",
            " [0.0117685 ]\n",
            " [0.01238692]\n",
            " [0.14069135]\n",
            " [0.04130568]\n",
            " [0.02612501]\n",
            " [0.01674698]\n",
            " [0.00794667]\n",
            " [0.1358599 ]\n",
            " [0.10902208]\n",
            " [0.0605841 ]\n",
            " [0.05132863]\n",
            " [0.01578582]\n",
            " [0.042102  ]\n",
            " [0.01788115]\n",
            " [0.01612533]\n",
            " [0.01917283]\n",
            " [0.02586726]\n",
            " [0.03289943]\n",
            " [0.05786069]\n",
            " [0.02282718]\n",
            " [0.04729561]\n",
            " [0.05750598]\n",
            " [0.19176953]\n",
            " [0.01269081]\n",
            " [0.02159369]\n",
            " [0.01666002]\n",
            " [0.05660734]\n",
            " [0.02085271]\n",
            " [0.03871693]\n",
            " [0.01917181]\n",
            " [0.04589639]\n",
            " [0.03110033]\n",
            " [0.04266441]\n",
            " [0.02350257]\n",
            " [0.01573963]\n",
            " [0.01872786]\n",
            " [0.00777968]\n",
            " [0.05926572]\n",
            " [0.0200051 ]\n",
            " [0.00980174]\n",
            " [0.03128794]\n",
            " [0.02272355]\n",
            " [0.01335221]\n",
            " [0.01333915]\n",
            " [0.03739655]\n",
            " [0.07089507]\n",
            " [0.05160223]\n",
            " [0.02211291]\n",
            " [0.00998406]\n",
            " [0.03911036]\n",
            " [0.00810142]\n",
            " [0.07557268]\n",
            " [0.10992678]\n",
            " [0.02165025]\n",
            " [0.02754934]\n",
            " [0.02483789]\n",
            " [0.01232636]\n",
            " [0.01530832]\n",
            " [0.01123155]\n",
            " [0.00916187]\n",
            " [0.07732593]\n",
            " [0.02711144]\n",
            " [0.02355746]\n",
            " [0.02137315]\n",
            " [0.01886596]\n",
            " [0.01780429]\n",
            " [0.10298926]\n",
            " [0.15467698]\n",
            " [0.0448626 ]\n",
            " [0.03992896]\n",
            " [0.02785978]\n",
            " [0.02092146]\n",
            " [0.00813094]\n",
            " [0.00842686]\n",
            " [0.00894091]\n",
            " [0.02985477]\n",
            " [0.00906802]\n",
            " [0.12304133]\n",
            " [0.0072189 ]\n",
            " [0.03574024]\n",
            " [0.08130915]\n",
            " [0.03638936]\n",
            " [0.04927073]\n",
            " [0.04511356]\n",
            " [0.0298616 ]\n",
            " [0.01402635]\n",
            " [0.02386617]\n",
            " [0.02220644]\n",
            " [0.01471636]\n",
            " [0.01114797]\n",
            " [0.15961579]\n",
            " [0.02526727]\n",
            " [0.02429114]\n",
            " [0.09761401]\n",
            " [0.01414715]\n",
            " [0.02563415]\n",
            " [0.05500602]\n",
            " [0.09181068]\n",
            " [0.04664932]\n",
            " [0.04330336]\n",
            " [0.03354654]\n",
            " [0.01611958]\n",
            " [0.0095094 ]\n",
            " [0.017288  ]\n",
            " [0.02155203]\n",
            " [0.03253924]\n",
            " [0.00915784]\n",
            " [0.12717407]\n",
            " [0.02394244]\n",
            " [0.05638648]\n",
            " [0.00777361]\n",
            " [0.02484462]\n",
            " [0.05149377]\n",
            " [0.02874845]\n",
            " [0.07613283]\n",
            " [0.06430842]\n",
            " [0.01770799]\n",
            " [0.03321537]\n",
            " [0.00993605]\n",
            " [0.03295546]\n",
            " [0.02800088]\n",
            " [0.02413961]\n",
            " [0.03772818]\n",
            " [0.02718723]\n",
            " [0.01084729]\n",
            " [0.00827156]\n",
            " [0.04660982]\n",
            " [0.02256282]\n",
            " [0.01049717]\n",
            " [0.02083268]\n",
            " [0.02978305]\n",
            " [0.02318531]\n",
            " [0.0258211 ]\n",
            " [0.0076097 ]\n",
            " [0.01346763]\n",
            " [0.18049455]\n",
            " [0.03106387]\n",
            " [0.05543257]\n",
            " [0.00758369]\n",
            " [0.02605677]\n",
            " [0.03026311]\n",
            " [0.02382052]\n",
            " [0.04742984]\n",
            " [0.02573037]\n",
            " [0.02411917]\n",
            " [0.08485869]\n",
            " [0.05128551]\n",
            " [0.01100523]\n",
            " [0.02231918]\n",
            " [0.09356269]\n",
            " [0.05731229]\n",
            " [0.03079013]\n",
            " [0.03294143]\n",
            " [0.03591751]\n",
            " [0.01551317]\n",
            " [0.01541921]\n",
            " [0.01151524]\n",
            " [0.02881699]\n",
            " [0.0086098 ]\n",
            " [0.00889106]\n",
            " [0.13017945]\n",
            " [0.01470938]\n",
            " [0.0478814 ]\n",
            " [0.02253483]\n",
            " [0.04473656]\n",
            " [0.01028181]\n",
            " [0.04639287]\n",
            " [0.02805453]\n",
            " [0.08869934]\n",
            " [0.0121669 ]\n",
            " [0.03571222]\n",
            " [0.08854408]\n",
            " [0.02830714]\n",
            " [0.03643346]\n",
            " [0.0317721 ]\n",
            " [0.01053672]\n",
            " [0.01527409]\n",
            " [0.01922953]\n",
            " [0.01673162]\n",
            " [0.0076708 ]\n",
            " [0.03328136]\n",
            " [0.11214154]\n",
            " [0.09585568]\n",
            " [0.02534137]\n",
            " [0.03971431]\n",
            " [0.00875572]\n",
            " [0.02467736]\n",
            " [0.04771459]\n",
            " [0.0336886 ]\n",
            " [0.05122647]\n",
            " [0.01203635]\n",
            " [0.02521023]\n",
            " [0.04236082]\n",
            " [0.05777894]\n",
            " [0.0158222 ]\n",
            " [0.02675827]\n",
            " [0.05213118]\n",
            " [0.02182169]\n",
            " [0.04852023]\n",
            " [0.01560893]\n",
            " [0.04063966]\n",
            " [0.01331545]\n",
            " [0.02727315]\n",
            " [0.07458377]\n",
            " [0.04542051]\n",
            " [0.03032789]\n",
            " [0.09376215]\n",
            " [0.03556064]\n",
            " [0.03082646]\n",
            " [0.02755951]\n",
            " [0.04429384]\n",
            " [0.01153368]\n",
            " [0.0225168 ]\n",
            " [0.07427111]\n",
            " [0.02765203]\n",
            " [0.03498671]\n",
            " [0.02137046]\n",
            " [0.0797856 ]\n",
            " [0.0209055 ]\n",
            " [0.01041376]\n",
            " [0.0129448 ]\n",
            " [0.04444921]\n",
            " [0.01324188]\n",
            " [0.00908379]\n",
            " [0.03849345]\n",
            " [0.03008458]\n",
            " [0.02206583]\n",
            " [0.01714288]\n",
            " [0.11187232]\n",
            " [0.03812173]\n",
            " [0.02200984]\n",
            " [0.12233735]\n",
            " [0.03103885]\n",
            " [0.02908172]\n",
            " [0.03348965]\n",
            " [0.01062729]\n",
            " [0.02357391]\n",
            " [0.01467523]\n",
            " [0.0205829 ]\n",
            " [0.02669708]\n",
            " [0.00813751]\n",
            " [0.01835783]\n",
            " [0.10932755]]\n",
            "Actual Output (y):\n",
            "[[ 1.88891660e-02]\n",
            " [-7.05515595e-01]\n",
            " [-9.59507296e-02]\n",
            " [-1.07699124e+00]\n",
            " [ 7.38422978e-02]\n",
            " [ 5.65895703e-01]\n",
            " [ 1.19486071e+00]\n",
            " [-9.70530412e-01]\n",
            " [ 1.06108452e+00]\n",
            " [-9.12836674e-01]\n",
            " [ 5.34608595e-01]\n",
            " [-1.81872341e+00]\n",
            " [ 1.25559892e+00]\n",
            " [-2.50231712e-01]\n",
            " [-2.27790914e-01]\n",
            " [-4.63906146e-01]\n",
            " [-3.77645426e-01]\n",
            " [-1.87061219e-01]\n",
            " [ 1.30160113e+00]\n",
            " [ 5.25212261e-01]\n",
            " [-4.42839020e-01]\n",
            " [-1.18994456e+00]\n",
            " [ 2.57770284e+00]\n",
            " [-6.18897724e-01]\n",
            " [ 1.27493243e-01]\n",
            " [ 2.02736243e+00]\n",
            " [-6.84924365e-01]\n",
            " [ 2.17836883e-02]\n",
            " [-3.45259262e-01]\n",
            " [-3.46542315e-01]\n",
            " [-1.26051825e-02]\n",
            " [ 6.58838677e-01]\n",
            " [ 3.06606488e-01]\n",
            " [-1.93584172e-03]\n",
            " [-4.56914971e-01]\n",
            " [ 1.93738009e+00]\n",
            " [ 2.95552524e-01]\n",
            " [-2.16378724e-01]\n",
            " [-3.77084163e-01]\n",
            " [-1.71017095e+00]\n",
            " [-4.94217734e-01]\n",
            " [ 1.37623328e+00]\n",
            " [-1.72523282e+00]\n",
            " [ 5.21447310e-01]\n",
            " [ 1.91990992e-01]\n",
            " [ 1.96857213e+00]\n",
            " [ 4.92733773e-02]\n",
            " [-1.12673745e-01]\n",
            " [ 1.39680182e+00]\n",
            " [-8.95212474e-01]\n",
            " [-5.65521823e-01]\n",
            " [ 2.93460137e-01]\n",
            " [-1.68858244e+00]\n",
            " [-1.67612331e+00]\n",
            " [-4.85009980e-01]\n",
            " [ 4.10291159e-01]\n",
            " [ 1.78560691e-01]\n",
            " [-3.83907392e-01]\n",
            " [ 2.62542441e-01]\n",
            " [ 4.75469216e-01]\n",
            " [-4.52966678e-01]\n",
            " [-2.14997736e-02]\n",
            " [ 4.12513810e-01]\n",
            " [-4.96222418e-01]\n",
            " [ 1.17866070e+00]\n",
            " [-7.35575296e-01]\n",
            " [ 4.33155910e-01]\n",
            " [-3.03098418e-01]\n",
            " [ 5.40067658e-01]\n",
            " [-1.43161008e+00]\n",
            " [ 1.31683577e-01]\n",
            " [-9.30831401e-01]\n",
            " [ 9.82229120e-01]\n",
            " [ 1.87422880e+00]\n",
            " [-2.92412912e-01]\n",
            " [ 3.30984196e-01]\n",
            " [ 9.02801839e-01]\n",
            " [ 1.22724448e+00]\n",
            " [ 9.58213694e-01]\n",
            " [-9.54573713e-01]\n",
            " [ 5.26225851e-01]\n",
            " [ 1.32314928e+00]\n",
            " [-1.58154320e+00]\n",
            " [-1.11004507e+00]\n",
            " [-7.31394243e-02]\n",
            " [ 6.60599526e-01]\n",
            " [-4.40591450e-01]\n",
            " [-1.21881998e-02]\n",
            " [-9.14308617e-01]\n",
            " [ 1.40839197e+00]\n",
            " [-4.69566841e-02]\n",
            " [ 1.70665066e+00]\n",
            " [-5.44018009e-01]\n",
            " [-6.58080373e-01]\n",
            " [ 7.83197225e-01]\n",
            " [ 7.96152166e-01]\n",
            " [-5.17446666e-02]\n",
            " [-1.14803381e+00]\n",
            " [ 2.64474869e-01]\n",
            " [-6.69438508e-01]\n",
            " [-1.29941746e+00]\n",
            " [ 1.74609924e+00]\n",
            " [ 1.36579798e-01]\n",
            " [ 1.04598710e+00]\n",
            " [ 1.57395568e+00]\n",
            " [-1.20928288e+00]\n",
            " [ 1.19426189e-01]\n",
            " [ 4.79643467e-01]\n",
            " [ 8.28511621e-01]\n",
            " [-6.83090625e-01]\n",
            " [ 6.65038588e-01]\n",
            " [ 2.68691896e-01]\n",
            " [-2.30467496e+00]\n",
            " [ 1.13562094e+00]\n",
            " [-1.06784525e+00]\n",
            " [-7.77695944e-01]\n",
            " [ 2.09409585e-02]\n",
            " [ 4.61894666e-01]\n",
            " [ 3.15994387e+00]\n",
            " [ 5.86098135e-01]\n",
            " [-8.30496898e-01]\n",
            " [-9.31288923e-01]\n",
            " [ 1.71576348e+00]\n",
            " [-1.61518585e+00]\n",
            " [ 2.37938135e+00]\n",
            " [ 1.72431085e-01]\n",
            " [ 1.76286655e+00]\n",
            " [-1.34083546e+00]\n",
            " [-9.03348462e-01]\n",
            " [-2.50540169e-01]\n",
            " [ 6.11443476e-01]\n",
            " [-1.61905815e+00]\n",
            " [-1.13334124e-01]\n",
            " [ 6.07274868e-01]\n",
            " [-9.21114477e-01]\n",
            " [-1.38747425e+00]\n",
            " [-1.02249663e-02]\n",
            " [ 1.56790873e-01]\n",
            " [ 9.79922920e-01]\n",
            " [ 1.44347198e+00]\n",
            " [-2.26291097e+00]\n",
            " [ 2.33604566e-01]\n",
            " [-1.09976124e+00]\n",
            " [ 1.21641214e+00]\n",
            " [-1.09633825e+00]\n",
            " [-6.21022298e-01]\n",
            " [ 2.27071957e+00]\n",
            " [-7.93297633e-01]\n",
            " [-1.44563755e+00]\n",
            " [ 1.01798771e-01]\n",
            " [ 1.04465331e+00]\n",
            " [-6.18833182e-01]\n",
            " [ 1.18015578e+00]\n",
            " [-8.67096654e-01]\n",
            " [-6.34025582e-01]\n",
            " [ 3.62601079e-01]\n",
            " [-1.46181829e+00]\n",
            " [-4.63431753e-01]\n",
            " [ 6.55876325e-01]\n",
            " [-9.34217813e-01]\n",
            " [ 7.48949405e-02]\n",
            " [-2.55533722e+00]\n",
            " [-3.09213274e-01]\n",
            " [ 6.71955300e-01]\n",
            " [ 2.32737917e-01]\n",
            " [-2.36539679e-02]\n",
            " [ 3.42635412e-01]\n",
            " [ 4.28072202e-01]\n",
            " [ 1.89737116e+00]\n",
            " [-1.27326507e+00]\n",
            " [-8.00683615e-03]\n",
            " [ 1.60707926e+00]\n",
            " [-1.25399998e+00]\n",
            " [ 6.34408354e-01]\n",
            " [-1.64730255e-01]\n",
            " [-2.74823888e-01]\n",
            " [-1.50164172e+00]\n",
            " [ 8.33862095e-01]\n",
            " [-6.54863241e-01]\n",
            " [ 1.23396068e+00]\n",
            " [-1.72691662e+00]\n",
            " [ 6.09521608e-01]\n",
            " [-1.23438302e+00]\n",
            " [-1.56016600e-01]\n",
            " [ 6.02468839e-01]\n",
            " [-2.32639826e-01]\n",
            " [-6.53891248e-01]\n",
            " [ 9.02913054e-02]\n",
            " [-7.56062166e-01]\n",
            " [ 7.81762570e-01]\n",
            " [ 6.63892567e-01]\n",
            " [ 1.32955520e+00]\n",
            " [-9.70295113e-02]\n",
            " [-1.04945439e+00]\n",
            " [-2.76847471e+00]\n",
            " [ 8.95439501e-01]\n",
            " [ 3.80628449e-01]\n",
            " [ 1.06410992e+00]\n",
            " [ 2.30909508e-01]\n",
            " [-3.89252348e-01]\n",
            " [ 2.50918868e+00]\n",
            " [-1.72673983e+00]\n",
            " [-2.00680633e+00]\n",
            " [ 1.47927844e+00]\n",
            " [-4.21335780e-01]\n",
            " [ 2.23978855e+00]\n",
            " [-6.75754148e-01]\n",
            " [-4.17637937e-01]\n",
            " [-4.78067070e-01]\n",
            " [-6.45160692e-01]\n",
            " [ 1.88342423e-01]\n",
            " [ 5.91887155e-02]\n",
            " [-9.24586410e-01]\n",
            " [-3.01567173e-01]\n",
            " [-8.34653621e-01]\n",
            " [ 3.70624238e-01]\n",
            " [-2.57234633e-01]\n",
            " [-8.68254748e-01]\n",
            " [ 4.29628531e-01]\n",
            " [ 1.15434003e+00]\n",
            " [-9.10349621e-01]\n",
            " [ 7.41737097e-01]\n",
            " [-2.36286117e-01]\n",
            " [ 1.11250796e+00]\n",
            " [ 5.27864272e-01]\n",
            " [ 1.51991009e+00]\n",
            " [-3.21994776e-01]\n",
            " [-6.71753597e-01]\n",
            " [ 3.48347480e-01]\n",
            " [ 1.07063179e+00]\n",
            " [-3.23968890e-01]\n",
            " [ 4.80810407e-01]\n",
            " [ 1.11877936e+00]\n",
            " [ 8.40312590e-01]\n",
            " [-6.86735870e-01]\n",
            " [-7.53052815e-01]\n",
            " [-1.09062283e+00]\n",
            " [ 6.09382483e-01]\n",
            " [ 6.81144693e-01]\n",
            " [ 8.18064599e-01]\n",
            " [-1.34677740e+00]\n",
            " [-1.04294257e+00]\n",
            " [-2.94639237e-01]\n",
            " [ 2.07862860e+00]\n",
            " [-1.55218783e-01]\n",
            " [ 3.16038282e-01]\n",
            " [-6.24328520e-01]\n",
            " [ 9.21579056e-01]\n",
            " [ 1.15349837e+00]\n",
            " [-4.90968391e-01]\n",
            " [ 1.14641237e+00]\n",
            " [-1.18988114e+00]\n",
            " [-9.91568026e-01]\n",
            " [-8.65400837e-01]\n",
            " [ 2.39533986e+00]\n",
            " [ 8.38197462e-01]\n",
            " [ 9.53569312e-01]\n",
            " [-6.42673995e-01]\n",
            " [-7.99504165e-01]\n",
            " [-5.73794974e-01]\n",
            " [ 3.46463436e-01]\n",
            " [ 2.24310776e-01]\n",
            " [-1.53148443e-01]\n",
            " [-1.79469322e-01]\n",
            " [-1.10234381e-01]\n",
            " [ 5.37357245e-01]\n",
            " [ 1.08101238e-01]\n",
            " [-5.93266359e-01]\n",
            " [ 1.11683909e+00]\n",
            " [-5.04953556e-01]\n",
            " [-1.08305016e+00]\n",
            " [ 6.93325028e-01]\n",
            " [-1.59155342e+00]\n",
            " [ 1.57470882e-01]\n",
            " [ 3.39778702e-01]\n",
            " [-1.09390976e+00]\n",
            " [ 6.48171814e-01]\n",
            " [ 8.69877083e-01]\n",
            " [ 4.73268977e-01]\n",
            " [ 8.75656482e-01]\n",
            " [-7.85486139e-01]\n",
            " [ 4.23619285e-01]\n",
            " [-2.73121977e-01]\n",
            " [ 2.11836806e-01]\n",
            " [ 3.39550229e-01]\n",
            " [-5.91577827e-01]\n",
            " [-2.10592611e-01]\n",
            " [ 4.67141387e-01]\n",
            " [ 3.15632152e-01]\n",
            " [ 3.55180498e-01]\n",
            " [-8.16610732e-02]\n",
            " [-3.68458868e+00]\n",
            " [ 4.44190038e-01]\n",
            " [ 6.10516779e-01]\n",
            " [ 1.96236410e+00]\n",
            " [ 4.31296194e-02]\n",
            " [-3.56269861e-01]\n",
            " [ 5.64679090e-01]\n",
            " [-9.23889795e-02]\n",
            " [-1.66062420e+00]\n",
            " [-1.90953896e+00]\n",
            " [-1.21092889e+00]\n",
            " [ 2.85745055e-02]\n",
            " [-1.17924897e+00]\n",
            " [ 4.39736165e-01]\n",
            " [ 2.37557064e-01]\n",
            " [-1.84423537e-01]\n",
            " [-4.30417024e-01]\n",
            " [-4.14991721e-01]\n",
            " [-1.25982553e+00]\n",
            " [-1.15183266e+00]\n",
            " [-3.39969325e-01]\n",
            " [-1.81857134e-01]\n",
            " [-2.33600820e-01]\n",
            " [ 1.13616876e-02]\n",
            " [ 1.45867691e+00]\n",
            " [-3.29494629e-01]\n",
            " [ 5.83273660e-01]\n",
            " [ 1.10527124e+00]\n",
            " [-5.30164790e-01]\n",
            " [-8.91833814e-01]\n",
            " [ 1.78427255e+00]\n",
            " [-8.01224020e-01]\n",
            " [-5.47897790e-01]\n",
            " [-3.84238139e-01]\n",
            " [-3.91880476e-01]\n",
            " [-2.05963737e+00]\n",
            " [ 5.61188919e-01]\n",
            " [-9.18394454e-01]\n",
            " [ 1.12455296e+00]\n",
            " [-2.02449900e+00]\n",
            " [-1.05145895e+00]\n",
            " [-2.13005345e-01]\n",
            " [-1.02583773e+00]\n",
            " [-8.06552377e-01]\n",
            " [-3.00149985e-01]\n",
            " [-8.41079273e-01]\n",
            " [ 2.77442616e-01]\n",
            " [ 4.47655668e-01]\n",
            " [-1.23360597e+00]\n",
            " [ 1.44778149e+00]\n",
            " [ 1.90147356e-02]\n",
            " [-4.07422905e-01]\n",
            " [ 4.32546573e-01]\n",
            " [-8.30825953e-01]\n",
            " [-1.31652810e+00]\n",
            " [-9.37867716e-02]\n",
            " [-1.03370084e+00]\n",
            " [-3.61569724e-01]\n",
            " [ 8.66045551e-01]\n",
            " [ 9.10394640e-01]\n",
            " [ 1.22145109e+00]\n",
            " [-1.41508080e-01]\n",
            " [ 2.84556436e-01]\n",
            " [ 4.44986399e-01]\n",
            " [ 3.04439913e-01]\n",
            " [-2.75922046e-03]\n",
            " [-3.81807840e-01]\n",
            " [-5.52456362e-01]\n",
            " [ 1.04449579e+00]\n",
            " [-7.39385721e-01]\n",
            " [-4.41398190e-01]\n",
            " [ 9.04927862e-02]\n",
            " [-9.88401297e-01]\n",
            " [-4.95018158e-02]\n",
            " [ 6.82527231e-01]\n",
            " [-1.18424389e-01]\n",
            " [ 7.11848821e-01]\n",
            " [-1.70357016e+00]\n",
            " [ 1.59468146e+00]\n",
            " [-1.07419043e+00]\n",
            " [-3.79169202e-01]\n",
            " [ 1.12341835e+00]\n",
            " [-5.80510572e-01]\n",
            " [ 5.56283561e-01]\n",
            " [ 6.59009447e-01]\n",
            " [ 1.00857782e+00]\n",
            " [-1.10192996e+00]\n",
            " [ 5.09518457e-01]\n",
            " [ 8.71567390e-01]\n",
            " [-7.55900171e-01]\n",
            " [ 1.94550633e+00]\n",
            " [ 6.90912593e-01]\n",
            " [-2.40724545e-01]\n",
            " [-1.29581529e+00]\n",
            " [-1.07887823e+00]\n",
            " [-1.28829004e+00]\n",
            " [ 1.22096343e+00]\n",
            " [ 1.20185529e+00]\n",
            " [-1.74331528e+00]\n",
            " [-1.72885139e-01]\n",
            " [ 1.62334840e+00]\n",
            " [-9.39588655e-01]\n",
            " [-3.08931627e-01]\n",
            " [ 6.76090953e-02]\n",
            " [-1.66057788e+00]\n",
            " [ 1.04264475e-01]\n",
            " [-3.81679290e-01]\n",
            " [ 6.89578918e-01]\n",
            " [-1.76254805e-03]]\n",
            "Mean of Predicted Output (E(d)): 0.03939272538639758\n",
            "Mean of Predicted Output Squared (E(d^2)): 0.002771022578817841\n",
            "Loss: 0.9745458894959168\n",
            "Accuracy: -350.6917895023693\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "input_size = 10\n",
        "hidden_size = 5\n",
        "output_size = 1\n",
        "batch_size = 20\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.weights1 = np.random.randn(self.input_dim, self.hidden_dim)\n",
        "        self.weights2 = np.random.randn(self.hidden_dim, self.output_dim)\n",
        "\n",
        "        self.bias1 = np.zeros((1, self.hidden_dim))\n",
        "        self.bias2 = np.zeros((1, self.output_dim))\n",
        "\n",
        "    def forward(self, X, bs):\n",
        "        self.batch_size = bs\n",
        "\n",
        "        self.hidden_layer = np.dot(X, self.weights1) + self.bias1\n",
        "        self.hidden_activation = self.sigmoid(self.hidden_layer)\n",
        "        self.output_layer = np.dot(self.hidden_activation, self.weights2) + self.bias2\n",
        "        self.predicted_output = self.sigmoid(self.output_layer)\n",
        "\n",
        "    def backward(self, X, y, learning_rate):\n",
        "        error = self.predicted_output - y\n",
        "\n",
        "        d_output = error * self.sigmoid_derivative(self.predicted_output)\n",
        "        d_hidden = np.dot(d_output, self.weights2.T) * self.sigmoid_derivative(self.hidden_activation)\n",
        "\n",
        "        self.weights2 -= learning_rate * np.dot(self.hidden_activation.T, d_output) / self.batch_size\n",
        "        self.bias2 -= learning_rate * np.sum(d_output, axis=0, keepdims=True) / self.batch_size\n",
        "        self.weights1 -= learning_rate * np.dot(X.T, d_hidden) / self.batch_size\n",
        "        self.bias1 -= learning_rate * np.sum(d_hidden, axis=0, keepdims=True) / self.batch_size\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "\n",
        "X = np.random.randn(400, input_size)\n",
        "y_true = np.random.randn(400, output_size)\n",
        "\n",
        "mlp = MLP(input_size, hidden_size, output_size)\n",
        "\n",
        "learning_rate = 0.1\n",
        "epochs = 100\n",
        "\n",
        "num_batches = X.shape[0] // 20  # batch_size=20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch in range(num_batches):\n",
        "        start_idx = batch * batch_size\n",
        "        end_idx = (batch + 1) * batch_size\n",
        "\n",
        "        batch_X = X[start_idx:end_idx]\n",
        "        batch_y = y_true[start_idx:end_idx]\n",
        "\n",
        "        mlp.forward(batch_X, batch_size)\n",
        "        mlp.backward(batch_X, batch_y, learning_rate)\n",
        "\n",
        "mlp.forward(X, batch_size)\n",
        "d = mlp.predicted_output\n",
        "y_actual = y_true\n",
        "\n",
        "E_d = np.mean(d)\n",
        "E_d_squared = np.mean(d ** 2)\n",
        "\n",
        "loss = np.mean((y_actual - d) ** 2)\n",
        "accuracy = 1 - loss / E_d_squared\n",
        "\n",
        "print(\"Predicted Output (d):\")\n",
        "print(d)\n",
        "print(\"Actual Output (y):\")\n",
        "print(y_actual)\n",
        "print(\"Mean of Predicted Output (E(d)):\", E_d)\n",
        "print(\"Mean of Predicted Output Squared (E(d^2)):\", E_d_squared)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DbWmt84k9cI",
        "outputId": "835db70b-35d8-4d9c-829f-fdbcc048e8fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch: 0, Loss: 1.1629487943023538, Accuracy: -5.843381714650218\n",
            "Batch: 10, Loss: 1.142373027135848, Accuracy: -6.688206476738188\n",
            "Batch: 0, Loss: 1.1208609580143902, Accuracy: -7.892343394124717\n",
            "Batch: 10, Loss: 1.1076901579729412, Accuracy: -8.8496595317877\n",
            "Batch: 0, Loss: 1.0925690580879766, Accuracy: -10.30282678479973\n",
            "Batch: 10, Loss: 1.0840251539956107, Accuracy: -11.331663708976654\n",
            "Batch: 0, Loss: 1.0731259068165047, Accuracy: -13.019191895137874\n",
            "Batch: 10, Loss: 1.0674440765923623, Accuracy: -14.08461757512502\n",
            "Batch: 0, Loss: 1.0593585483648673, Accuracy: -15.99061497027688\n",
            "Batch: 10, Loss: 1.0554747613038038, Accuracy: -17.065016664683455\n",
            "Batch: 0, Loss: 1.049309803913575, Accuracy: -19.173687633497085\n",
            "Batch: 10, Loss: 1.0465842864049788, Accuracy: -20.235884001656764\n",
            "Batch: 0, Loss: 1.0417672605077866, Accuracy: -22.53202753833137\n",
            "Batch: 10, Loss: 1.039808618753498, Accuracy: -23.56588895485147\n",
            "Batch: 0, Loss: 1.0359637187141655, Accuracy: -26.035111706663535\n",
            "Batch: 10, Loss: 1.0345265118975264, Accuracy: -27.02831581156778\n",
            "Batch: 0, Loss: 1.0314004212985959, Accuracy: -29.657124712725764\n",
            "Batch: 10, Loss: 1.0303265877907106, Accuracy: -30.60019033400892\n",
            "Batch: 0, Loss: 1.0277439865555855, Accuracy: -33.376020273201426\n",
            "Batch: 10, Loss: 1.0269290588149167, Accuracy: -34.26159749497324\n",
            "Batch: 0, Loss: 1.0247655848130515, Accuracy: -37.17279933629402\n",
            "Batch: 10, Loss: 1.0241388181501856, Accuracy: -37.995156524962724\n",
            "Batch: 0, Loss: 1.0223042594098768, Accuracy: -41.030960864842434\n",
            "Batch: 10, Loss: 1.0218166652987137, Accuracy: -41.785613626342005\n",
            "Batch: 0, Loss: 1.0202442505233653, Accuracy: -44.936080699475276\n",
            "Batch: 10, Loss: 1.01986121122503, Accuracy: -45.61952083029474\n",
            "Batch: 0, Loss: 1.018500617309167, Accuracy: -48.87548363865019\n",
            "Batch: 10, Loss: 1.0181972173723317, Accuracy: -49.484978310464\n",
            "Batch: 0, Loss: 1.017009896953611, Accuracy: -52.837983634560445\n",
            "Batch: 10, Loss: 1.0167679042808346, Accuracy: -53.37142424811342\n",
            "Batch: 0, Loss: 1.0157238957237498, Accuracy: -56.81367447811454\n",
            "Batch: 10, Loss: 1.0155297674497612, Accuracy: -57.26946106513225\n",
            "Batch: 0, Loss: 1.0146054734261953, Accuracy: -60.79375859966271\n",
            "Batch: 10, Loss: 1.014449012547346, Accuracy: -61.17071003582197\n",
            "Batch: 0, Loss: 1.0136256248258046, Accuracy: -64.77040519919777\n",
            "Batch: 10, Loss: 1.0134990586299635, Accuracy: -65.06768844881003\n",
            "Batch: 0, Loss: 1.0127614224094128, Accuracy: -68.73663135853016\n",
            "Batch: 10, Loss: 1.012658759595017, Accuracy: -68.95370497066925\n",
            "Batch: 0, Loss: 1.011994542199637, Accuracy: -72.68620145973665\n",
            "Batch: 10, Loss: 1.0119111174360544, Accuracy: -72.8227698972233\n",
            "Batch: 0, Loss: 1.0113101912621345, Accuracy: -76.61354139738928\n",
            "Batch: 10, Loss: 1.011242337919264, Accuracy: -76.66951771778433\n",
            "Batch: 0, Loss: 1.0106963165101108, Accuracy: -80.51366489627556\n",
            "Batch: 10, Loss: 1.0106411283807197, Accuracy: -80.48913995807467\n",
            "Batch: 0, Loss: 1.0101430134880176, Accuracy: -84.3821098417907\n",
            "Batch: 10, Loss: 1.0100981691854702, Accuracy: -84.27732667140596\n",
            "Batch: 0, Loss: 1.0096420793220724, Accuracy: -88.21488296882615\n",
            "Batch: 10, Loss: 1.0096057114051615, Accuracy: -88.03021525537928\n",
            "Batch: 0, Loss: 1.0091866709550914, Accuracy: -92.0084115841206\n",
            "Batch: 10, Loss: 1.0091572673655682, Accuracy: -91.74434550992518\n",
            "Batch: 0, Loss: 1.0087710411988595, Accuracy: -95.75950124827796\n",
            "Batch: 10, Loss: 1.008747370311205, Accuracy: -95.41662004025436\n",
            "Batch: 0, Loss: 1.00839033294885, Accuracy: -99.46529853841908\n",
            "Batch: 10, Loss: 1.0083713860593009, Accuracy: -99.0442692579874\n",
            "Batch: 0, Loss: 1.0080404173253843, Accuracy: -103.12325816550837\n",
            "Batch: 10, Loss: 1.008025364149829, Accuracy: -102.62482035440226\n",
            "Batch: 0, Loss: 1.007717765313607, Accuracy: -106.73111384219376\n",
            "Batch: 10, Loss: 1.0077059192802382, Accuracy: -106.15606971793895\n",
            "Batch: 0, Loss: 1.00741934518322, Accuracy: -110.28685239493932\n",
            "Batch: 10, Loss: 1.0074101361645296, Accuracy: -109.63605834866017\n",
            "Batch: 0, Loss: 1.0071425399172496, Accuracy: -113.78869069375455\n",
            "Batch: 10, Loss: 1.0071354926587899, Accuracy: -113.06304988892549\n",
            "Batch: 0, Loss: 1.0068850802954719, Accuracy: -117.23505503790952\n",
            "Batch: 10, Loss: 1.0068797972406653, Accuracy: -116.43551094485866\n",
            "Batch: 0, Loss: 1.0066449903181196, Accuracy: -120.62456268971111\n",
            "Batch: 10, Loss: 1.0066411378500069, Accuracy: -119.7520934194299\n",
            "Batch: 0, Loss: 1.0064205424262884, Accuracy: -123.95600529296556\n",
            "Batch: 10, Loss: 1.0064178397833523, Accuracy: -123.01161861680752\n",
            "Batch: 0, Loss: 1.0062102205518462, Accuracy: -127.22833394995789\n",
            "Batch: 10, Loss: 1.0062084308500545, Accuracy: -126.21306291039292\n",
            "Batch: 0, Loss: 1.0060126894642605, Accuracy: -130.4406457619962\n",
            "Batch: 10, Loss: 1.006011612388172, Accuracy: -129.35554479469772\n",
            "Batch: 0, Loss: 1.005826769212073, Accuracy: -133.59217166490592\n",
            "Batch: 10, Loss: 1.0058262350362042, Accuracy: -132.43831316480805\n",
            "Batch: 0, Loss: 1.0056514137096741, Accuracy: -136.6822654131578\n",
            "Batch: 10, Loss: 1.005651278385888, Accuracy: -135.46073668729835\n",
            "Batch: 0, Loss: 1.0054856927150748, Accuracy: -139.71039358528228\n",
            "Batch: 10, Loss: 1.0054858338186574, Accuracy: -138.42229414367776\n",
            "Batch: 0, Loss: 1.0053287765958183, Accuracy: -142.67612649941663\n",
            "Batch: 10, Loss: 1.005329089966624, Accuracy: -141.32256564222826\n",
            "Batch: 0, Loss: 1.0051799233984788, Accuracy: -145.5791299416971\n",
            "Batch: 10, Loss: 1.005180320347328, Accuracy: -144.1612246068206\n",
            "Batch: 0, Loss: 1.0050384678302218, Accuracy: -148.41915762212955\n",
            "Batch: 10, Loss: 1.0050388728070114, Accuracy: -146.93803046227396\n",
            "Batch: 0, Loss: 1.004903811834442, Accuracy: -151.1960442828441\n",
            "Batch: 10, Loss: 1.0049041604749887, Accuracy: -149.652821945333\n",
            "Batch: 0, Loss: 1.0047754165009786, Accuracy: -153.90969939252707\n",
            "Batch: 10, Loss: 1.0047756539857655, Accuracy: -152.30551097858546\n",
            "Batch: 0, Loss: 1.0046527950981343, Accuracy: -156.56010136851538\n",
            "Batch: 10, Loss: 1.0046528747689152, Accuracy: -154.8960770518146\n",
            "Batch: 0, Loss: 1.0045355070512836, Accuracy: -159.14729227473822\n",
            "Batch: 10, Loss: 1.0045353892416309, Accuracy: -157.42456206153636\n",
            "Batch: 0, Loss: 1.0044231527231577, Accuracy: -161.67137294952155\n",
            "Batch: 10, Loss: 1.0044228037671417, Accuracy: -159.89106556493965\n",
            "Batch: 0, Loss: 1.0043153688754733, Accuracy: -164.13249852236066\n",
            "Batch: 10, Loss: 1.004314760265141, Accuracy: -162.29574040922705\n",
            "Batch: 0, Loss: 1.0042118247115916, Accuracy: -166.53087428323084\n",
            "Batch: 10, Loss: 1.0042109323791424, Accuracy: -164.638788701558\n",
            "Batch: 0, Loss: 1.004112218416272, Accuracy: -168.86675187191346\n",
            "Batch: 10, Loss: 1.0041110221210447, Accuracy: -166.92045808848567\n",
            "Batch: 0, Loss: 1.0040162741220378, Accuracy: -171.14042575826002\n",
            "Batch: 10, Loss: 1.0040147569258457, Accuracy: -169.1410383170352\n",
            "Batch: 0, Loss: 1.003923739242755, Accuracy: -173.35222998734403\n",
            "Batch: 10, Loss: 1.0039218870599043, Accuracy: -171.30085805243618\n",
            "Batch: 0, Loss: 1.0038343821242157, Accuracy: -175.50253516612625\n",
            "Batch: 10, Loss: 1.0038321833348165, Accuracy: -173.40028193007132\n",
            "Batch: 0, Loss: 1.0037479899691337, Accuracy: -177.5917456706295\n",
            "Batch: 10, Loss: 1.0037454350861887, Accuracy: -175.43970782143992\n",
            "Batch: 0, Loss: 1.003664367000322, Accuracy: -179.6202970547091\n",
            "Batch: 10, Loss: 1.0036614483826183, Accuracy: -177.41956429594583\n",
            "Batch: 0, Loss: 1.0035833328311365, Accuracy: -181.58865364337754\n",
            "Batch: 10, Loss: 1.0035800444352359, Accuracy: -179.3403082620817\n",
            "Batch: 0, Loss: 1.0035047210167307, Accuracy: -183.49730629528406\n",
            "Batch: 10, Loss: 1.003501058182415, Accuracy: -181.20242277317104\n",
            "Batch: 0, Loss: 1.0034283777634223, Accuracy: -185.3467703204382\n",
            "Batch: 10, Loss: 1.003424337027817, Accuracy: -183.0064149842348\n",
            "Batch: 0, Loss: 1.0033541607766425, Accuracy: -187.13758354057222\n",
            "Batch: 10, Loss: 1.0033497397129805, Accuracy: -184.7528142478083\n",
            "Batch: 0, Loss: 1.0032819382306195, Accuracy: -188.87030448071613\n",
            "Batch: 10, Loss: 1.003277135308211, Accuracy: -186.44217033766333\n",
            "Batch: 0, Loss: 1.0032115878452337, Accuracy: -190.54551068161805\n",
            "Batch: 10, Loss: 1.0032064023077276, Accuracy: -188.07505179039998\n",
            "Batch: 0, Loss: 1.0031429960574154, Accuracy: -192.16379712357147\n",
            "Batch: 10, Loss: 1.003137427816855, Accuracy: -189.65204435577436\n",
            "Batch: 0, Loss: 1.0030760572761184, Accuracy: -193.72577475307637\n",
            "Batch: 10, Loss: 1.0030701068206682, Accuracy: -191.1737495474481\n",
            "Batch: 0, Loss: 1.0030106732113129, Accuracy: -195.23206910450463\n",
            "Batch: 10, Loss: 1.0030043415248335, Accuracy: -192.64078328657413\n",
            "Batch: 0, Loss: 1.0029467522686695, Accuracy: -196.6833190096417\n",
            "Batch: 10, Loss: 1.002940040760573, Accuracy: -194.05377463129332\n",
            "Batch: 0, Loss: 1.002884209002637, Accuracy: -198.08017538857905\n",
            "Batch: 10, Loss: 1.0028771194466828, Accuracy: -195.41336458581668\n",
            "Batch: 0, Loss: 1.002822963621532, Accuracy: -199.4233001160052\n",
            "Batch: 10, Loss: 1.002815498102402, Accuracy: -196.72020498329874\n",
            "Batch: 0, Loss: 1.0027629415390287, Accuracy: -200.71336495743387\n",
            "Batch: 10, Loss: 1.0027551024056824, Accuracy: -197.97495743719915\n",
            "Batch: 0, Loss: 1.0027040729671162, Accuracy: -201.95105057037284\n",
            "Batch: 10, Loss: 1.0026958627920641, Accuracy: -199.1782923562692\n",
            "Batch: 0, Loss: 1.0026462925461737, Accuracy: -203.137045565845\n",
            "Batch: 10, Loss: 1.0026377140899165, Accuracy: -200.33088801869857\n",
            "Batch: 0, Loss: 1.0025895390083213, Accuracy: -204.2720456260512\n",
            "Batch: 10, Loss: 1.0025805951883149, Accuracy: -201.43342970132215\n",
            "Batch: 0, Loss: 1.0025337548706545, Accuracy: -205.35675267430625\n",
            "Batch: 10, Loss: 1.0025244487342277, Accuracy: -202.48660886011385\n",
            "Batch: 0, Loss: 1.00247888615535, Accuracy: -206.3918740936829\n",
            "Batch: 10, Loss: 1.0024692208560912, Accuracy: -203.4911223584975\n",
            "Batch: 0, Loss: 1.0024248821339663, Accuracy: -207.37812199108865\n",
            "Batch: 10, Loss: 1.002414860911153, Accuracy: -204.44767174027405\n",
            "Batch: 0, Loss: 1.0023716950935755, Accuracy: -208.31621250374965\n",
            "Batch: 10, Loss: 1.0023613212542706, Accuracy: -205.35696254421813\n",
            "Batch: 0, Loss: 1.0023192801226, Accuracy: -209.2068651453151\n",
            "Batch: 10, Loss: 1.0023085570260943, Accuracy: -206.21970365761948\n",
            "Batch: 0, Loss: 1.0022675949144755, Accuracy: -210.05080218901017\n",
            "Batch: 10, Loss: 1.00225652595879, Accuracy: -207.03660670625766\n",
            "Batch: 0, Loss: 1.0022165995874537, Accuracy: -210.84874808545314\n",
            "Batch: 10, Loss: 1.0022051881976524, Accuracy: -207.80838547848225\n",
            "Batch: 0, Loss: 1.0021662565190361, Accuracy: -211.60142891294288\n",
            "Batch: 10, Loss: 1.0021545061371355, Accuracy: -208.53575538125284\n",
            "Batch: 0, Loss: 1.0021165301936943, Accuracy: -212.30957185817772\n",
            "Batch: 10, Loss: 1.0021044442699725, Accuracy: -209.2194329261404\n",
            "Batch: 0, Loss: 1.002067387062661, Accuracy: -212.9739047255213\n",
            "Batch: 10, Loss: 1.0020549690482041, Accuracy: -209.86013524345535\n",
            "Batch: 0, Loss: 1.002018795414708, Accuracy: -213.59515547306572\n",
            "Batch: 10, Loss: 1.0020060487550428, Accuracy: -210.45857962278137\n",
            "Batch: 0, Loss: 1.001970725256931, Accuracy: -214.17405177387533\n",
            "Batch: 10, Loss: 1.001957653386616, Accuracy: -211.01548307833482\n",
            "Batch: 0, Loss: 1.0019231482046655, Accuracy: -214.7113206009015\n",
            "Batch: 10, Loss: 1.0019097545427227, Accuracy: -211.53156193767222\n",
            "Batch: 0, Loss: 1.0018760373797304, Accuracy: -215.20768783417293\n",
            "Batch: 10, Loss: 1.0018623253258232, Accuracy: -212.0075314523781\n",
            "Batch: 0, Loss: 1.0018293673162932, Accuracy: -215.66387788896293\n",
            "Batch: 10, Loss: 1.0018153402475543, Accuracy: -212.444105429458\n",
            "Batch: 0, Loss: 1.0017831138737023, Accuracy: -216.08061336372623\n",
            "Batch: 10, Loss: 1.001768775142137, Accuracy: -212.84199588225442\n",
            "Batch: 0, Loss: 1.0017372541556997, Accuracy: -216.45861470667595\n",
            "Batch: 10, Loss: 1.001722607086096, Accuracy: -213.20191269977948\n",
            "Batch: 0, Loss: 1.0016917664354885, Accuracy: -216.79859989996316\n",
            "Batch: 10, Loss: 1.0016768143237689, Accuracy: -213.52456333344026\n",
            "Batch: 0, Loss: 1.001646630086166, Accuracy: -217.10128416047277\n",
            "Batch: 10, Loss: 1.001631376198131, Accuracy: -213.8106525001971\n",
            "Batch: 0, Loss: 1.0016018255160903, Accuracy: -217.36737965633313\n",
            "Batch: 10, Loss: 1.0015862730865024, Accuracy: -214.06088190126198\n",
            "Batch: 0, Loss: 1.0015573341087824, Accuracy: -217.59759523829104\n",
            "Batch: 10, Loss: 1.0015414863407477, Accuracy: -214.27594995550348\n",
            "Batch: 0, Loss: 1.001513138166996, Accuracy: -217.79263618515498\n",
            "Batch: 10, Loss: 1.0014969982316098, Accuracy: -214.45655154678357\n",
            "Batch: 0, Loss: 1.0014692208606346, Accuracy: -217.95320396257475\n",
            "Batch: 10, Loss: 1.0014527918968517, Accuracy: -214.60337778449352\n",
            "Batch: 0, Loss: 1.001425566178208, Accuracy: -218.07999599445904\n",
            "Batch: 10, Loss: 1.001408851292912, Accuracy: -214.71711577661515\n",
            "Batch: 0, Loss: 1.0013821588815555, Accuracy: -218.17370544639087\n",
            "Batch: 10, Loss: 1.0013651611498005, Accuracy: -214.79844841466914\n",
            "Batch: 0, Loss: 1.0013389844635876, Accuracy: -218.23502102043528\n",
            "Batch: 10, Loss: 1.0013217069289866, Accuracy: -214.8480541699583\n",
            "Batch: 0, Loss: 1.0012960291088167, Accuracy: -218.26462676077344\n",
            "Batch: 10, Loss: 1.001278474784057, Accuracy: -214.86660690054777\n",
            "Batch: 0, Loss: 1.0012532796564602, Accuracy: -218.2632018696323\n",
            "Batch: 10, Loss: 1.0012354515239288, Accuracy: -214.8547756684616\n",
            "Batch: 0, Loss: 1.001210723565936, Accuracy: -218.2314205330208\n",
            "Batch: 10, Loss: 1.0011926245784364, Accuracy: -214.81322456661138\n",
            "\n",
            "Final Results:\n",
            "Predicted Output (d):\n",
            "[[0.08298596]\n",
            " [0.02748859]\n",
            " [0.02038308]\n",
            " [0.03141047]\n",
            " [0.02060521]\n",
            " [0.04109903]\n",
            " [0.01906279]\n",
            " [0.03028752]\n",
            " [0.02130389]\n",
            " [0.04930989]\n",
            " [0.02370959]\n",
            " [0.06635444]\n",
            " [0.03423687]\n",
            " [0.04012671]\n",
            " [0.05210046]\n",
            " [0.01776909]\n",
            " [0.05926147]\n",
            " [0.23645666]\n",
            " [0.05836407]\n",
            " [0.03704617]\n",
            " [0.03624712]\n",
            " [0.07019669]\n",
            " [0.09084908]\n",
            " [0.00661489]\n",
            " [0.02221251]\n",
            " [0.00863454]\n",
            " [0.04790911]\n",
            " [0.03222034]\n",
            " [0.03770323]\n",
            " [0.03850865]\n",
            " [0.07808003]\n",
            " [0.02061092]\n",
            " [0.02598714]\n",
            " [0.05215485]\n",
            " [0.03982733]\n",
            " [0.00514834]\n",
            " [0.08675532]\n",
            " [0.04848985]\n",
            " [0.03231232]\n",
            " [0.0184489 ]\n",
            " [0.02286419]\n",
            " [0.06153391]\n",
            " [0.01471048]\n",
            " [0.05627367]\n",
            " [0.00640634]\n",
            " [0.02932275]\n",
            " [0.01860896]\n",
            " [0.01813268]\n",
            " [0.02168721]\n",
            " [0.00614255]\n",
            " [0.15227201]\n",
            " [0.01773425]\n",
            " [0.02166591]\n",
            " [0.12631073]\n",
            " [0.05441848]\n",
            " [0.09421289]\n",
            " [0.01446513]\n",
            " [0.03940031]\n",
            " [0.0060241 ]\n",
            " [0.05487914]\n",
            " [0.03081381]\n",
            " [0.04801153]\n",
            " [0.0499792 ]\n",
            " [0.06814782]\n",
            " [0.01930224]\n",
            " [0.02968908]\n",
            " [0.00681274]\n",
            " [0.14245559]\n",
            " [0.05742503]\n",
            " [0.05038434]\n",
            " [0.06317592]\n",
            " [0.02098184]\n",
            " [0.04822736]\n",
            " [0.00583687]\n",
            " [0.00880681]\n",
            " [0.02550714]\n",
            " [0.01196295]\n",
            " [0.04049013]\n",
            " [0.01275472]\n",
            " [0.04240641]\n",
            " [0.03577761]\n",
            " [0.02873159]\n",
            " [0.00768278]\n",
            " [0.00560787]\n",
            " [0.00596199]\n",
            " [0.05681009]\n",
            " [0.04590434]\n",
            " [0.01943347]\n",
            " [0.05088348]\n",
            " [0.03629065]\n",
            " [0.00662583]\n",
            " [0.02580132]\n",
            " [0.06352674]\n",
            " [0.00522846]\n",
            " [0.05892348]\n",
            " [0.01179492]\n",
            " [0.06117906]\n",
            " [0.01815362]\n",
            " [0.01879941]\n",
            " [0.00835654]\n",
            " [0.15962539]\n",
            " [0.03656132]\n",
            " [0.0177803 ]\n",
            " [0.01288195]\n",
            " [0.03469077]\n",
            " [0.04475183]\n",
            " [0.04685024]\n",
            " [0.01400276]\n",
            " [0.0129537 ]\n",
            " [0.1277862 ]\n",
            " [0.0222563 ]\n",
            " [0.09723224]\n",
            " [0.01828532]\n",
            " [0.01246815]\n",
            " [0.03409551]\n",
            " [0.03695379]\n",
            " [0.17381488]\n",
            " [0.00452829]\n",
            " [0.03897183]\n",
            " [0.03601052]\n",
            " [0.04003898]\n",
            " [0.03594124]\n",
            " [0.01287414]\n",
            " [0.017882  ]\n",
            " [0.04540556]\n",
            " [0.03141398]\n",
            " [0.01962555]\n",
            " [0.0145529 ]\n",
            " [0.06155885]\n",
            " [0.05105511]\n",
            " [0.00540635]\n",
            " [0.00673942]\n",
            " [0.03524418]\n",
            " [0.02183459]\n",
            " [0.03549255]\n",
            " [0.02173627]\n",
            " [0.19277261]\n",
            " [0.04475857]\n",
            " [0.00592927]\n",
            " [0.05152862]\n",
            " [0.01833788]\n",
            " [0.06419459]\n",
            " [0.00908122]\n",
            " [0.01612935]\n",
            " [0.03525653]\n",
            " [0.01835672]\n",
            " [0.00854492]\n",
            " [0.03116216]\n",
            " [0.0710434 ]\n",
            " [0.07408125]\n",
            " [0.02439427]\n",
            " [0.06252481]\n",
            " [0.02771394]\n",
            " [0.14655546]\n",
            " [0.0556921 ]\n",
            " [0.02388161]\n",
            " [0.04670165]\n",
            " [0.03291059]\n",
            " [0.11587546]\n",
            " [0.17248205]\n",
            " [0.02258838]\n",
            " [0.15435188]\n",
            " [0.02465426]\n",
            " [0.01925721]\n",
            " [0.03525579]\n",
            " [0.08950141]\n",
            " [0.00911933]\n",
            " [0.01618573]\n",
            " [0.02137893]\n",
            " [0.04834513]\n",
            " [0.09774698]\n",
            " [0.10608399]\n",
            " [0.02014401]\n",
            " [0.01579596]\n",
            " [0.32918667]\n",
            " [0.01046567]\n",
            " [0.05163185]\n",
            " [0.0385043 ]\n",
            " [0.09460073]\n",
            " [0.04323908]\n",
            " [0.04605775]\n",
            " [0.07481816]\n",
            " [0.01596621]\n",
            " [0.02230113]\n",
            " [0.01240395]\n",
            " [0.03841678]\n",
            " [0.00948646]\n",
            " [0.03837823]\n",
            " [0.1115579 ]\n",
            " [0.03028714]\n",
            " [0.01839008]\n",
            " [0.01553521]\n",
            " [0.00705002]\n",
            " [0.04868286]\n",
            " [0.11086494]\n",
            " [0.04969546]\n",
            " [0.0389113 ]\n",
            " [0.01315391]\n",
            " [0.20439108]\n",
            " [0.02668125]\n",
            " [0.02798618]\n",
            " [0.04140005]\n",
            " [0.04050068]\n",
            " [0.00833183]\n",
            " [0.02009234]\n",
            " [0.00912629]\n",
            " [0.08769516]\n",
            " [0.02380198]\n",
            " [0.01217697]\n",
            " [0.00842812]\n",
            " [0.02464512]\n",
            " [0.02309188]\n",
            " [0.04821226]\n",
            " [0.07136837]\n",
            " [0.20396218]\n",
            " [0.00528863]\n",
            " [0.04393961]\n",
            " [0.06990478]\n",
            " [0.03661666]\n",
            " [0.08505668]\n",
            " [0.03715254]\n",
            " [0.04209107]\n",
            " [0.02743995]\n",
            " [0.02531719]\n",
            " [0.04669162]\n",
            " [0.04591707]\n",
            " [0.03942406]\n",
            " [0.00737171]\n",
            " [0.0061281 ]\n",
            " [0.04505204]\n",
            " [0.03057986]\n",
            " [0.05917063]\n",
            " [0.10423917]\n",
            " [0.03220522]\n",
            " [0.03657899]\n",
            " [0.06796178]\n",
            " [0.02656549]\n",
            " [0.02232797]\n",
            " [0.08808775]\n",
            " [0.01604911]\n",
            " [0.1284763 ]\n",
            " [0.02371115]\n",
            " [0.14499735]\n",
            " [0.03175829]\n",
            " [0.11678085]\n",
            " [0.06411917]\n",
            " [0.0419257 ]\n",
            " [0.016807  ]\n",
            " [0.16657091]\n",
            " [0.05580755]\n",
            " [0.03178196]\n",
            " [0.05766113]\n",
            " [0.08079035]\n",
            " [0.1060864 ]\n",
            " [0.12801379]\n",
            " [0.01234034]\n",
            " [0.05286676]\n",
            " [0.00994794]\n",
            " [0.01557694]\n",
            " [0.00928875]\n",
            " [0.01754083]\n",
            " [0.02086294]\n",
            " [0.04601835]\n",
            " [0.05001466]\n",
            " [0.03826527]\n",
            " [0.08550718]\n",
            " [0.01216466]\n",
            " [0.06058559]\n",
            " [0.00875834]\n",
            " [0.01976978]\n",
            " [0.03895561]\n",
            " [0.15603889]\n",
            " [0.00760352]\n",
            " [0.05038134]\n",
            " [0.0287689 ]\n",
            " [0.04063473]\n",
            " [0.20169115]\n",
            " [0.02340746]\n",
            " [0.02468987]\n",
            " [0.07302746]\n",
            " [0.03472088]\n",
            " [0.0220983 ]\n",
            " [0.03106873]\n",
            " [0.04782556]\n",
            " [0.02574335]\n",
            " [0.02590349]\n",
            " [0.04574376]\n",
            " [0.00380917]\n",
            " [0.02002436]\n",
            " [0.05905633]\n",
            " [0.03655956]\n",
            " [0.03490347]\n",
            " [0.03413239]\n",
            " [0.00899727]\n",
            " [0.15175973]\n",
            " [0.0557476 ]\n",
            " [0.02525788]\n",
            " [0.0417675 ]\n",
            " [0.09844301]\n",
            " [0.04010269]\n",
            " [0.03952174]\n",
            " [0.20375227]\n",
            " [0.02258202]\n",
            " [0.00946411]\n",
            " [0.24087665]\n",
            " [0.03360923]\n",
            " [0.02375905]\n",
            " [0.02738128]\n",
            " [0.24402745]\n",
            " [0.04111892]\n",
            " [0.14553509]\n",
            " [0.01226927]\n",
            " [0.04460848]\n",
            " [0.08332003]\n",
            " [0.01730984]\n",
            " [0.01046245]\n",
            " [0.01344354]\n",
            " [0.00504733]\n",
            " [0.03122864]\n",
            " [0.01682831]\n",
            " [0.00815309]\n",
            " [0.04370434]\n",
            " [0.02182761]\n",
            " [0.0136247 ]\n",
            " [0.049212  ]\n",
            " [0.26608014]\n",
            " [0.01822045]\n",
            " [0.01466614]\n",
            " [0.03462687]\n",
            " [0.06902132]\n",
            " [0.04025353]\n",
            " [0.02978953]\n",
            " [0.05634286]\n",
            " [0.04237855]\n",
            " [0.20523849]\n",
            " [0.06096825]\n",
            " [0.02535556]\n",
            " [0.02222711]\n",
            " [0.0338336 ]\n",
            " [0.02441189]\n",
            " [0.08308915]\n",
            " [0.07169795]\n",
            " [0.03705512]\n",
            " [0.02792015]\n",
            " [0.04993977]\n",
            " [0.10900603]\n",
            " [0.15950168]\n",
            " [0.12891401]\n",
            " [0.02041594]\n",
            " [0.07800626]\n",
            " [0.07380487]\n",
            " [0.04142885]\n",
            " [0.03843081]\n",
            " [0.07159926]\n",
            " [0.04860587]\n",
            " [0.08774393]\n",
            " [0.0185469 ]\n",
            " [0.02691411]\n",
            " [0.01896222]\n",
            " [0.03887058]\n",
            " [0.01414757]\n",
            " [0.03527387]\n",
            " [0.08242863]\n",
            " [0.05775018]\n",
            " [0.05000944]\n",
            " [0.00759104]\n",
            " [0.21123844]\n",
            " [0.01466137]\n",
            " [0.02616654]\n",
            " [0.00995044]\n",
            " [0.10900222]\n",
            " [0.12783216]\n",
            " [0.0485267 ]\n",
            " [0.01318951]\n",
            " [0.07135753]\n",
            " [0.02084753]\n",
            " [0.03531908]\n",
            " [0.06340556]\n",
            " [0.14483716]\n",
            " [0.02722636]\n",
            " [0.03548525]\n",
            " [0.04285615]\n",
            " [0.01231032]\n",
            " [0.05232898]\n",
            " [0.09912592]\n",
            " [0.07862623]\n",
            " [0.04288378]\n",
            " [0.02105661]\n",
            " [0.04100584]\n",
            " [0.07975015]\n",
            " [0.02051786]\n",
            " [0.03547363]\n",
            " [0.01830507]\n",
            " [0.05686977]\n",
            " [0.05494208]\n",
            " [0.05591786]\n",
            " [0.03632982]\n",
            " [0.02557579]\n",
            " [0.0313421 ]\n",
            " [0.14167501]]\n",
            "Actual Output (y):\n",
            "[[-1.62844808e+00]\n",
            " [-3.14221727e-01]\n",
            " [ 9.07926346e-02]\n",
            " [-8.40637216e-01]\n",
            " [-7.45742912e-01]\n",
            " [-1.19554447e+00]\n",
            " [ 3.57454977e-01]\n",
            " [-3.29508699e-02]\n",
            " [ 1.64296227e+00]\n",
            " [ 3.69515739e-01]\n",
            " [ 1.09805189e+00]\n",
            " [ 9.33467741e-03]\n",
            " [ 3.65127571e-01]\n",
            " [-2.27495318e+00]\n",
            " [-1.51251988e-01]\n",
            " [-1.45738263e+00]\n",
            " [-9.62717457e-01]\n",
            " [ 1.16732814e+00]\n",
            " [ 9.46677203e-02]\n",
            " [ 2.85651402e-01]\n",
            " [ 1.76406974e-01]\n",
            " [ 2.65840907e+00]\n",
            " [ 2.61829866e+00]\n",
            " [-1.07081959e+00]\n",
            " [ 4.09795892e-01]\n",
            " [-1.18283627e+00]\n",
            " [-9.01311815e-01]\n",
            " [ 6.18244467e-01]\n",
            " [ 2.05895312e+00]\n",
            " [-1.82218709e-01]\n",
            " [ 9.61178928e-01]\n",
            " [-3.17750034e-01]\n",
            " [-4.44294732e-01]\n",
            " [-1.23507729e+00]\n",
            " [ 5.51931056e-01]\n",
            " [-5.67415080e-01]\n",
            " [-1.28386276e+00]\n",
            " [ 2.76242844e-01]\n",
            " [ 7.34464288e-01]\n",
            " [ 2.68529753e-01]\n",
            " [-1.80857368e+00]\n",
            " [ 2.56809810e-01]\n",
            " [-1.65017188e+00]\n",
            " [ 6.71721415e-01]\n",
            " [-1.37065455e+00]\n",
            " [ 2.74869327e-01]\n",
            " [ 4.57803668e-01]\n",
            " [ 4.09732009e-01]\n",
            " [-1.33165815e+00]\n",
            " [ 2.32491384e-02]\n",
            " [ 4.94816289e-01]\n",
            " [ 3.24213222e+00]\n",
            " [-4.41340924e-03]\n",
            " [-4.68532929e-02]\n",
            " [-5.01310249e-01]\n",
            " [ 8.57533683e-01]\n",
            " [ 1.53894167e+00]\n",
            " [ 5.51156128e-01]\n",
            " [ 3.43929652e-02]\n",
            " [-1.47143586e+00]\n",
            " [-1.09814502e+00]\n",
            " [-6.15793441e-01]\n",
            " [ 4.25637791e-01]\n",
            " [ 4.17744174e-01]\n",
            " [-3.83839375e-01]\n",
            " [-2.59077833e-01]\n",
            " [-1.13651293e+00]\n",
            " [ 2.72756874e-01]\n",
            " [ 1.51737196e-01]\n",
            " [ 1.11700832e+00]\n",
            " [ 2.23420599e-01]\n",
            " [-5.48510256e-01]\n",
            " [-1.41130313e+00]\n",
            " [-1.31335704e+00]\n",
            " [ 3.65892496e-01]\n",
            " [ 8.63129096e-01]\n",
            " [-8.66710955e-01]\n",
            " [ 2.31986388e-01]\n",
            " [-5.77531661e-01]\n",
            " [-1.77074146e+00]\n",
            " [ 6.32424236e-01]\n",
            " [-4.76268334e-01]\n",
            " [ 4.39461664e-01]\n",
            " [-9.08697578e-01]\n",
            " [ 5.62451927e-01]\n",
            " [-5.40689841e-01]\n",
            " [-3.86768749e-01]\n",
            " [-8.96165509e-02]\n",
            " [-1.20963857e+00]\n",
            " [ 1.68379040e+00]\n",
            " [-2.84469469e+00]\n",
            " [ 6.17332448e-01]\n",
            " [-1.02863329e+00]\n",
            " [-1.61762609e-02]\n",
            " [ 1.86544491e+00]\n",
            " [ 1.95699751e+00]\n",
            " [-3.49092372e-01]\n",
            " [ 1.09247330e+00]\n",
            " [-1.40212853e+00]\n",
            " [ 5.05082371e-01]\n",
            " [ 1.10986852e+00]\n",
            " [-7.17578197e-01]\n",
            " [ 7.51430781e-01]\n",
            " [ 1.93049419e-01]\n",
            " [-3.81573130e-01]\n",
            " [ 6.83478514e-01]\n",
            " [ 1.56233731e+00]\n",
            " [-1.26446213e+00]\n",
            " [ 7.85259559e-01]\n",
            " [ 1.50042432e+00]\n",
            " [-5.16994098e-01]\n",
            " [ 2.12064697e+00]\n",
            " [ 8.44895279e-01]\n",
            " [ 1.44910634e-01]\n",
            " [-3.15631373e-02]\n",
            " [ 4.98654135e-01]\n",
            " [ 4.33480507e-01]\n",
            " [ 1.27656348e+00]\n",
            " [ 4.29749149e-01]\n",
            " [ 5.33375020e-01]\n",
            " [ 1.25165116e+00]\n",
            " [-8.74640015e-01]\n",
            " [-1.19022745e+00]\n",
            " [-3.44076135e-01]\n",
            " [-3.48242235e-01]\n",
            " [-2.68546612e-01]\n",
            " [ 7.90840860e-01]\n",
            " [ 1.09589441e+00]\n",
            " [-1.31123470e+00]\n",
            " [-1.33918265e+00]\n",
            " [ 1.40069828e+00]\n",
            " [-1.18762392e+00]\n",
            " [ 2.28153236e-01]\n",
            " [ 1.05696223e+00]\n",
            " [ 4.77914871e-02]\n",
            " [ 1.11027554e+00]\n",
            " [-5.49817491e-01]\n",
            " [ 4.01906106e-01]\n",
            " [-8.75116113e-02]\n",
            " [ 6.06352955e-01]\n",
            " [-1.80262941e+00]\n",
            " [-1.16424393e-01]\n",
            " [ 4.07117601e-01]\n",
            " [ 9.69770678e-02]\n",
            " [-5.50786067e-01]\n",
            " [ 6.02039064e-01]\n",
            " [ 1.84998894e+00]\n",
            " [ 1.56269716e+00]\n",
            " [ 1.12613023e+00]\n",
            " [-1.01062920e+00]\n",
            " [ 2.59086930e+00]\n",
            " [ 2.14211059e-01]\n",
            " [-3.44892705e-01]\n",
            " [-8.07924086e-01]\n",
            " [ 8.46163312e-01]\n",
            " [ 5.00206390e-01]\n",
            " [-1.21752072e+00]\n",
            " [-2.37636967e+00]\n",
            " [-1.00653789e+00]\n",
            " [ 6.25296800e-01]\n",
            " [ 5.37946643e-01]\n",
            " [ 1.41904550e+00]\n",
            " [ 4.24963703e-01]\n",
            " [ 2.77928564e-01]\n",
            " [ 7.04142011e-02]\n",
            " [ 6.00725143e-01]\n",
            " [-4.45617184e-01]\n",
            " [-6.61052618e-02]\n",
            " [ 4.17890921e-01]\n",
            " [-1.83642692e+00]\n",
            " [-1.39684411e-01]\n",
            " [ 4.86438759e-01]\n",
            " [-2.56569764e-01]\n",
            " [ 2.06626768e+00]\n",
            " [ 1.99332225e+00]\n",
            " [-2.08452508e-01]\n",
            " [-8.52156308e-01]\n",
            " [ 2.78222340e-01]\n",
            " [ 1.23831369e+00]\n",
            " [ 1.20148743e+00]\n",
            " [ 8.15590320e-01]\n",
            " [ 5.34682196e-01]\n",
            " [ 1.79923322e+00]\n",
            " [ 1.26840002e+00]\n",
            " [-5.29807877e-01]\n",
            " [-1.08127230e+00]\n",
            " [ 1.90239495e+00]\n",
            " [-3.23155617e-01]\n",
            " [-1.36548116e-01]\n",
            " [-4.75240991e-01]\n",
            " [ 6.20392438e-01]\n",
            " [-8.71188020e-03]\n",
            " [ 3.98494386e-01]\n",
            " [ 1.39722913e+00]\n",
            " [ 7.04989306e-01]\n",
            " [-3.04529138e-01]\n",
            " [-9.91451041e-01]\n",
            " [-2.61979954e-01]\n",
            " [ 1.09968727e+00]\n",
            " [-4.98148467e-01]\n",
            " [ 9.84375814e-03]\n",
            " [-3.22084388e-01]\n",
            " [-1.20461698e+00]\n",
            " [ 4.34388669e-01]\n",
            " [-2.73932724e-01]\n",
            " [-1.85510189e+00]\n",
            " [-1.44392235e+00]\n",
            " [ 3.05332731e-01]\n",
            " [ 6.55921917e-01]\n",
            " [ 1.30615059e+00]\n",
            " [-1.46542203e+00]\n",
            " [-1.07553201e-03]\n",
            " [-1.17239778e+00]\n",
            " [ 6.08239279e-01]\n",
            " [-1.13296321e+00]\n",
            " [-6.85000598e-01]\n",
            " [ 2.31789470e-01]\n",
            " [-1.01688168e+00]\n",
            " [-6.51918311e-02]\n",
            " [ 1.25601286e+00]\n",
            " [-1.71573719e-01]\n",
            " [ 1.11360389e+00]\n",
            " [ 1.40209556e+00]\n",
            " [ 3.47151286e-01]\n",
            " [-8.94887428e-01]\n",
            " [ 8.08237113e-01]\n",
            " [ 8.42022803e-01]\n",
            " [ 3.93053812e-01]\n",
            " [-3.16662609e-01]\n",
            " [-7.21707724e-02]\n",
            " [-1.39332671e+00]\n",
            " [-1.04033898e+00]\n",
            " [ 5.88114384e-01]\n",
            " [ 6.25719421e-01]\n",
            " [-5.52624956e-01]\n",
            " [ 1.59507006e-01]\n",
            " [-7.10466284e-01]\n",
            " [-2.41488147e+00]\n",
            " [-7.31074171e-01]\n",
            " [ 1.41633002e+00]\n",
            " [-1.19712344e+00]\n",
            " [ 7.67452833e-01]\n",
            " [ 3.43370075e-01]\n",
            " [-1.09246048e+00]\n",
            " [ 1.65259526e-01]\n",
            " [ 1.16131080e+00]\n",
            " [ 1.47396354e+00]\n",
            " [ 1.35171185e-01]\n",
            " [-9.63351672e-01]\n",
            " [ 3.24270359e-01]\n",
            " [ 2.49866217e+00]\n",
            " [-7.67260420e-01]\n",
            " [ 1.31190224e+00]\n",
            " [-6.23332255e-01]\n",
            " [ 5.12086626e-01]\n",
            " [ 3.60641931e-01]\n",
            " [-9.62450102e-01]\n",
            " [ 3.63111767e-01]\n",
            " [ 5.70574075e-01]\n",
            " [-1.36818967e+00]\n",
            " [-1.11290307e+00]\n",
            " [-6.08531002e-01]\n",
            " [-4.56004895e-01]\n",
            " [-2.06815499e+00]\n",
            " [ 9.72826315e-01]\n",
            " [ 1.45967130e+00]\n",
            " [ 5.42752537e-03]\n",
            " [ 1.71400695e+00]\n",
            " [-2.07658899e+00]\n",
            " [ 1.54092131e+00]\n",
            " [-6.84318149e-01]\n",
            " [ 5.65186893e-01]\n",
            " [-8.68595340e-01]\n",
            " [ 6.41582261e-01]\n",
            " [-1.36488913e+00]\n",
            " [-1.41675437e+00]\n",
            " [-8.29763977e-01]\n",
            " [-3.18123476e-01]\n",
            " [-7.61174972e-01]\n",
            " [ 2.71648129e-01]\n",
            " [-2.08474283e-01]\n",
            " [ 5.82820649e-01]\n",
            " [-1.71956856e-01]\n",
            " [ 4.67871939e-01]\n",
            " [ 1.10618657e+00]\n",
            " [ 8.85832509e-01]\n",
            " [ 1.95873077e+00]\n",
            " [ 1.54930539e+00]\n",
            " [-1.24395196e-01]\n",
            " [-2.56173475e-01]\n",
            " [-2.55680472e-01]\n",
            " [-1.15089647e-01]\n",
            " [ 4.80826683e-02]\n",
            " [-9.51001054e-01]\n",
            " [-5.11953480e-01]\n",
            " [ 8.44747381e-01]\n",
            " [ 2.91591346e-01]\n",
            " [-1.51744648e-01]\n",
            " [ 5.88146909e-01]\n",
            " [ 1.00456276e+00]\n",
            " [ 6.20694573e-01]\n",
            " [-5.44020168e-01]\n",
            " [-7.60591717e-01]\n",
            " [-3.35015294e-01]\n",
            " [ 1.02153675e+00]\n",
            " [ 1.62990047e-01]\n",
            " [ 4.87611568e-01]\n",
            " [-1.09765818e+00]\n",
            " [ 1.64581023e+00]\n",
            " [ 1.27640135e+00]\n",
            " [-4.77391479e-01]\n",
            " [-9.23041546e-01]\n",
            " [-1.01953320e+00]\n",
            " [-1.38352852e+00]\n",
            " [-1.31424614e+00]\n",
            " [ 1.87906598e-02]\n",
            " [ 5.00919275e-01]\n",
            " [-1.79129908e+00]\n",
            " [ 1.45235471e-01]\n",
            " [ 5.69950543e-01]\n",
            " [-1.30949675e+00]\n",
            " [ 7.44825697e-01]\n",
            " [ 4.40787382e-01]\n",
            " [ 8.35035411e-01]\n",
            " [-3.50980938e-01]\n",
            " [-9.57697062e-02]\n",
            " [ 6.84711723e-01]\n",
            " [ 2.51855805e-01]\n",
            " [ 2.99100276e-01]\n",
            " [ 9.89131009e-01]\n",
            " [ 5.12594964e-01]\n",
            " [-1.31318397e+00]\n",
            " [-7.85165856e-01]\n",
            " [ 4.33054708e-01]\n",
            " [-1.48045735e+00]\n",
            " [ 1.94310397e-01]\n",
            " [-4.99667236e-02]\n",
            " [-1.35512424e-01]\n",
            " [ 4.36868660e-01]\n",
            " [ 4.29206853e-01]\n",
            " [ 1.62434784e+00]\n",
            " [-4.78831812e-01]\n",
            " [-1.86407976e+00]\n",
            " [ 2.67024799e-01]\n",
            " [ 1.39941072e+00]\n",
            " [-4.52012712e-01]\n",
            " [ 5.45648859e-01]\n",
            " [ 2.34837206e-01]\n",
            " [-4.90844391e-01]\n",
            " [ 1.38055165e+00]\n",
            " [ 1.82092005e+00]\n",
            " [-1.25523864e-01]\n",
            " [-5.16037411e-01]\n",
            " [ 6.45392737e-01]\n",
            " [ 3.25416553e-01]\n",
            " [-1.16375846e+00]\n",
            " [-9.78224280e-01]\n",
            " [-8.53014556e-01]\n",
            " [-6.08605623e-01]\n",
            " [-5.01448336e-01]\n",
            " [ 1.66487187e+00]\n",
            " [-3.44984063e-01]\n",
            " [-1.33817059e-02]\n",
            " [ 2.04336886e-01]\n",
            " [-1.59396473e+00]\n",
            " [ 4.68024955e-01]\n",
            " [-7.84241580e-01]\n",
            " [-5.50719457e-01]\n",
            " [-2.59695570e-01]\n",
            " [ 2.06084055e+00]\n",
            " [ 1.19556447e+00]\n",
            " [-1.83624497e-01]\n",
            " [ 9.50133699e-01]\n",
            " [ 1.36949264e+00]\n",
            " [-2.39453541e+00]\n",
            " [-1.49219602e-01]\n",
            " [-1.01562827e+00]\n",
            " [ 1.53647531e+00]\n",
            " [-2.30377769e-01]\n",
            " [-1.18551162e+00]\n",
            " [ 2.71510571e-02]\n",
            " [ 3.18190813e-01]\n",
            " [-4.06620030e-01]\n",
            " [ 7.48666572e-01]\n",
            " [-1.48241624e+00]\n",
            " [ 1.62120957e+00]\n",
            " [ 4.04673752e-01]\n",
            " [ 2.90064848e-01]\n",
            " [ 5.73313971e-01]\n",
            " [-1.08382967e+00]\n",
            " [ 5.67852909e-01]\n",
            " [-8.78351808e-01]\n",
            " [-5.67923431e-01]\n",
            " [ 6.67526525e-01]\n",
            " [-2.96123010e+00]\n",
            " [-8.08371794e-01]\n",
            " [ 2.48759562e-01]\n",
            " [ 1.98570705e-01]\n",
            " [ 1.01097158e+00]\n",
            " [ 2.47867357e-01]]\n",
            "Mean of Predicted Output (E(d)): 0.04875393662109234\n",
            "Mean of Predicted Output Squared (E(d^2)): 0.004574490886058668\n",
            "Loss: 1.0011692424381222\n",
            "Accuracy: -217.8591621177584\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "input_size = 10\n",
        "hidden_size = 5\n",
        "output_size = 1\n",
        "batch_size = 20\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.weights1 = np.random.randn(self.input_dim, self.hidden_dim)\n",
        "        self.weights2 = np.random.randn(self.hidden_dim, self.output_dim)\n",
        "\n",
        "        self.bias1 = np.zeros((1, self.hidden_dim))\n",
        "        self.bias2 = np.zeros((1, self.output_dim))\n",
        "\n",
        "    def forward(self, X, bs):\n",
        "        self.batch_size = bs\n",
        "\n",
        "        self.hidden_layer = np.dot(X, self.weights1) + self.bias1\n",
        "        self.hidden_activation = self.sigmoid(self.hidden_layer)\n",
        "        self.output_layer = np.dot(self.hidden_activation, self.weights2) + self.bias2\n",
        "        self.predicted_output = self.sigmoid(self.output_layer)\n",
        "\n",
        "    def backward(self, X, y, learning_rate):\n",
        "        error = self.predicted_output - y\n",
        "\n",
        "        d_output = error * self.sigmoid_derivative(self.predicted_output)\n",
        "        d_hidden = np.dot(d_output, self.weights2.T) * self.sigmoid_derivative(self.hidden_activation)\n",
        "\n",
        "        self.weights2 -= learning_rate * np.dot(self.hidden_activation.T, d_output) / self.batch_size\n",
        "        self.bias2 -= learning_rate * np.sum(d_output, axis=0, keepdims=True) / self.batch_size\n",
        "        self.weights1 -= learning_rate * np.dot(X.T, d_hidden) / self.batch_size\n",
        "        self.bias1 -= learning_rate * np.sum(d_hidden, axis=0, keepdims=True) / self.batch_size\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "\n",
        "X = np.random.randn(400, input_size)\n",
        "y_true = np.random.randn(400, output_size)\n",
        "\n",
        "mlp = MLP(input_size, hidden_size, output_size)\n",
        "\n",
        "learning_rate = 0.1\n",
        "epochs = 100\n",
        "\n",
        "num_batches = X.shape[0] // 20  # batch_size=20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch in range(num_batches):\n",
        "        start_idx = batch * batch_size\n",
        "        end_idx = (batch + 1) * batch_size\n",
        "\n",
        "        batch_X = X[start_idx:end_idx]\n",
        "        batch_y = y_true[start_idx:end_idx]\n",
        "\n",
        "        mlp.forward(batch_X, batch_size)\n",
        "        mlp.backward(batch_X, batch_y, learning_rate)\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            mlp.forward(X, batch_size)\n",
        "            d = mlp.predicted_output\n",
        "            y_actual = y_true\n",
        "\n",
        "            E_d = np.mean(d)\n",
        "            E_d_squared = np.mean(d ** 2)\n",
        "\n",
        "            loss = np.mean((y_actual - d) ** 2)\n",
        "            accuracy = 1 - loss / E_d_squared\n",
        "\n",
        "            print(f\"Batch: {batch}, Loss: {loss}, Accuracy: {accuracy}\")\n",
        "\n",
        "mlp.forward(X, batch_size)\n",
        "d = mlp.predicted_output\n",
        "y_actual = y_true\n",
        "\n",
        "E_d = np.mean(d)\n",
        "E_d_squared = np.mean(d ** 2)\n",
        "\n",
        "loss = np.mean((y_actual - d) ** 2)\n",
        "accuracy = 1 - loss / E_d_squared\n",
        "\n",
        "print(\"\\nFinal Results:\")\n",
        "print(\"Predicted Output (d):\")\n",
        "print(d)\n",
        "print(\"Actual Output (y):\")\n",
        "print(y_actual)\n",
        "print(\"Mean of Predicted Output (E(d)):\", E_d)\n",
        "print(\"Mean of Predicted Output Squared (E(d^2)):\", E_d_squared)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6XAC6wgr9er",
        "outputId": "7447745d-5348-4655-d830-ec0720d4d01f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch: 0, Loss: 2.376748934931022, Accuracy: 0.11236666666666667\n",
            "Batch: 10, Loss: 2.1860256850802915, Accuracy: 0.3015\n",
            "Batch: 20, Loss: 2.102355904607788, Accuracy: 0.17078333333333334\n",
            "Batch: 30, Loss: 1.9813679658971053, Accuracy: 0.51195\n",
            "Batch: 40, Loss: 1.878724980540914, Accuracy: 0.57485\n",
            "Batch: 50, Loss: 1.7810213593119388, Accuracy: 0.65265\n",
            "Batch: 60, Loss: 1.671878001235389, Accuracy: 0.70015\n",
            "Batch: 70, Loss: 1.5860062082870312, Accuracy: 0.69535\n",
            "Batch: 80, Loss: 1.5019501280233758, Accuracy: 0.7326166666666667\n",
            "Batch: 90, Loss: 1.4015245018077578, Accuracy: 0.7435166666666667\n",
            "Batch: 100, Loss: 1.31980581915553, Accuracy: 0.7136833333333333\n",
            "Batch: 110, Loss: 1.2532061278098654, Accuracy: 0.75825\n",
            "Batch: 120, Loss: 1.1833487130670728, Accuracy: 0.7631\n",
            "Batch: 130, Loss: 1.125027825353433, Accuracy: 0.75585\n",
            "Batch: 140, Loss: 1.065675864656514, Accuracy: 0.79695\n",
            "Batch: 150, Loss: 1.0156549801688766, Accuracy: 0.8120833333333334\n",
            "Batch: 160, Loss: 0.9697274539245075, Accuracy: 0.8189333333333333\n",
            "Batch: 170, Loss: 0.9303517855950972, Accuracy: 0.8149166666666666\n",
            "Batch: 180, Loss: 0.8964252286079364, Accuracy: 0.8014833333333333\n",
            "Batch: 190, Loss: 0.8586698485118578, Accuracy: 0.8291166666666666\n",
            "Batch: 200, Loss: 0.8400811981486546, Accuracy: 0.8317\n",
            "Batch: 210, Loss: 0.8035404189690095, Accuracy: 0.8230666666666666\n",
            "Batch: 220, Loss: 0.7825398440047838, Accuracy: 0.8154666666666667\n",
            "Batch: 230, Loss: 0.750230972466098, Accuracy: 0.8388666666666666\n",
            "Epoch: 1, Loss: 0.7503652983365978, Accuracy: 0.8288666666666666\n",
            "Batch: 0, Loss: 0.7479417271609707, Accuracy: 0.8270666666666666\n",
            "Batch: 10, Loss: 0.7235202352401918, Accuracy: 0.8320166666666666\n",
            "Batch: 20, Loss: 0.7083129050063822, Accuracy: 0.83185\n",
            "Batch: 30, Loss: 0.6914362271495289, Accuracy: 0.84175\n",
            "Batch: 40, Loss: 0.6783403830138824, Accuracy: 0.8403333333333334\n",
            "Batch: 50, Loss: 0.6595417844245014, Accuracy: 0.84835\n",
            "Batch: 60, Loss: 0.6429580804855168, Accuracy: 0.8497666666666667\n",
            "Batch: 70, Loss: 0.635574091392789, Accuracy: 0.8483333333333334\n",
            "Batch: 80, Loss: 0.6254545576868215, Accuracy: 0.8527333333333333\n",
            "Batch: 90, Loss: 0.6079304069639394, Accuracy: 0.8574\n",
            "Batch: 100, Loss: 0.5988879125955273, Accuracy: 0.8599\n",
            "Batch: 110, Loss: 0.5932732520819943, Accuracy: 0.8571\n",
            "Batch: 120, Loss: 0.5895954913410651, Accuracy: 0.8541333333333333\n",
            "Batch: 130, Loss: 0.574022828360973, Accuracy: 0.86\n",
            "Batch: 140, Loss: 0.5696614141750433, Accuracy: 0.8554333333333334\n",
            "Batch: 150, Loss: 0.559897472604908, Accuracy: 0.8645833333333334\n",
            "Batch: 160, Loss: 0.5485593198347329, Accuracy: 0.8669666666666667\n",
            "Batch: 170, Loss: 0.542429807606444, Accuracy: 0.8684\n",
            "Batch: 180, Loss: 0.5413496448839498, Accuracy: 0.8607666666666667\n",
            "Batch: 190, Loss: 0.5275660078213535, Accuracy: 0.86965\n",
            "Batch: 200, Loss: 0.5319396425829352, Accuracy: 0.8659166666666667\n",
            "Batch: 210, Loss: 0.5240503420981427, Accuracy: 0.86495\n",
            "Batch: 220, Loss: 0.5125887614725239, Accuracy: 0.8692333333333333\n",
            "Batch: 230, Loss: 0.5033948051570062, Accuracy: 0.87415\n",
            "Epoch: 2, Loss: 0.5080260826878545, Accuracy: 0.86695\n",
            "Batch: 0, Loss: 0.5067505414176183, Accuracy: 0.8676833333333334\n",
            "Batch: 10, Loss: 0.4977404461254228, Accuracy: 0.8715333333333334\n",
            "Batch: 20, Loss: 0.4938294675987212, Accuracy: 0.8730666666666667\n",
            "Batch: 30, Loss: 0.49395731648902563, Accuracy: 0.8717833333333334\n",
            "Batch: 40, Loss: 0.48767723121127204, Accuracy: 0.87235\n",
            "Batch: 50, Loss: 0.483701241378831, Accuracy: 0.8740666666666667\n",
            "Batch: 60, Loss: 0.4761206571222256, Accuracy: 0.8752166666666666\n",
            "Batch: 70, Loss: 0.47587979437789996, Accuracy: 0.8751333333333333\n",
            "Batch: 80, Loss: 0.4737138632288506, Accuracy: 0.8757\n",
            "Batch: 90, Loss: 0.4650973882400957, Accuracy: 0.8782833333333333\n",
            "Batch: 100, Loss: 0.46313050371815473, Accuracy: 0.8803333333333333\n",
            "Batch: 110, Loss: 0.46263626540130853, Accuracy: 0.8784666666666666\n",
            "Batch: 120, Loss: 0.46439031154860094, Accuracy: 0.8781166666666667\n",
            "Batch: 130, Loss: 0.45435024876730823, Accuracy: 0.87905\n",
            "Batch: 140, Loss: 0.4568712699037124, Accuracy: 0.87555\n",
            "Batch: 150, Loss: 0.4523699360927576, Accuracy: 0.8816\n",
            "Batch: 160, Loss: 0.4440088705504441, Accuracy: 0.8830666666666667\n",
            "Batch: 170, Loss: 0.44372891209037835, Accuracy: 0.8838\n",
            "Batch: 180, Loss: 0.44463513238142377, Accuracy: 0.8798166666666667\n",
            "Batch: 190, Loss: 0.43576415484573827, Accuracy: 0.8833666666666666\n",
            "Batch: 200, Loss: 0.4418632924140154, Accuracy: 0.8811333333333333\n",
            "Batch: 210, Loss: 0.43886507716620315, Accuracy: 0.88145\n",
            "Batch: 220, Loss: 0.42992036634530384, Accuracy: 0.8838833333333334\n",
            "Batch: 230, Loss: 0.4253189250671922, Accuracy: 0.8868666666666667\n",
            "Epoch: 3, Loss: 0.4297919964334369, Accuracy: 0.8814333333333333\n",
            "Batch: 0, Loss: 0.42841646509070963, Accuracy: 0.88245\n",
            "Batch: 10, Loss: 0.4231300680673313, Accuracy: 0.8851666666666667\n",
            "Batch: 20, Loss: 0.4209254395409983, Accuracy: 0.8870666666666667\n",
            "Batch: 30, Loss: 0.424981737875172, Accuracy: 0.88375\n",
            "Batch: 40, Loss: 0.4194622553520224, Accuracy: 0.8846\n",
            "Batch: 50, Loss: 0.4198802647507801, Accuracy: 0.8845\n",
            "Batch: 60, Loss: 0.4135530468007401, Accuracy: 0.8869166666666667\n",
            "Batch: 70, Loss: 0.4145637608107271, Accuracy: 0.8865833333333333\n",
            "Batch: 80, Loss: 0.4144387669594707, Accuracy: 0.8858333333333334\n",
            "Batch: 90, Loss: 0.4092853448445693, Accuracy: 0.8877666666666667\n",
            "Batch: 100, Loss: 0.40826990686489834, Accuracy: 0.8890666666666667\n",
            "Batch: 110, Loss: 0.40884633757799066, Accuracy: 0.8873166666666666\n",
            "Batch: 120, Loss: 0.41163870580087863, Accuracy: 0.8875833333333333\n",
            "Batch: 130, Loss: 0.4030999089746513, Accuracy: 0.88865\n",
            "Batch: 140, Loss: 0.4069802893832375, Accuracy: 0.88585\n",
            "Batch: 150, Loss: 0.40443869544328204, Accuracy: 0.8890333333333333\n",
            "Batch: 160, Loss: 0.39759680295543615, Accuracy: 0.891\n",
            "Batch: 170, Loss: 0.3985969027630582, Accuracy: 0.8915333333333333\n",
            "Batch: 180, Loss: 0.39934106578931905, Accuracy: 0.8895\n",
            "Batch: 190, Loss: 0.39288143777998974, Accuracy: 0.8915833333333333\n",
            "Batch: 200, Loss: 0.39891580668415544, Accuracy: 0.8890666666666667\n",
            "Batch: 210, Loss: 0.3969370105232779, Accuracy: 0.89035\n",
            "Batch: 220, Loss: 0.3898556969012023, Accuracy: 0.8923333333333333\n",
            "Batch: 230, Loss: 0.387041543552704, Accuracy: 0.8937333333333334\n",
            "Epoch: 4, Loss: 0.39118198774229607, Accuracy: 0.8891666666666667\n",
            "Batch: 0, Loss: 0.3897821554550573, Accuracy: 0.8900166666666667\n",
            "Batch: 10, Loss: 0.38595023247129184, Accuracy: 0.89265\n",
            "Batch: 20, Loss: 0.3841738031733032, Accuracy: 0.8937833333333334\n",
            "Batch: 30, Loss: 0.38945851170633894, Accuracy: 0.8913\n",
            "Batch: 40, Loss: 0.38436691672881707, Accuracy: 0.8917166666666667\n",
            "Batch: 50, Loss: 0.3865419657229602, Accuracy: 0.8911\n",
            "Batch: 60, Loss: 0.3804944380088392, Accuracy: 0.89315\n",
            "Batch: 70, Loss: 0.3816924921431248, Accuracy: 0.8935\n",
            "Batch: 80, Loss: 0.38230794012643443, Accuracy: 0.8923333333333333\n",
            "Batch: 90, Loss: 0.3791951269372672, Accuracy: 0.89385\n",
            "Batch: 100, Loss: 0.37816318302955687, Accuracy: 0.8946166666666666\n",
            "Batch: 110, Loss: 0.3790393410217081, Accuracy: 0.8935833333333333\n",
            "Batch: 120, Loss: 0.38227473572689785, Accuracy: 0.8937166666666667\n",
            "Batch: 130, Loss: 0.37425607365669744, Accuracy: 0.8945\n",
            "Batch: 140, Loss: 0.37831176507180736, Accuracy: 0.8922\n",
            "Batch: 150, Loss: 0.3768591977049298, Accuracy: 0.8945\n",
            "Batch: 160, Loss: 0.37096030995431756, Accuracy: 0.8962333333333333\n",
            "Batch: 170, Loss: 0.3722342473769065, Accuracy: 0.8973\n",
            "Batch: 180, Loss: 0.37265082357077933, Accuracy: 0.89495\n",
            "Batch: 190, Loss: 0.3675827197519687, Accuracy: 0.8966666666666666\n",
            "Batch: 200, Loss: 0.3731795139186931, Accuracy: 0.8945\n",
            "Batch: 210, Loss: 0.37156076100620494, Accuracy: 0.8958833333333334\n",
            "Batch: 220, Loss: 0.3657640199085652, Accuracy: 0.8974333333333333\n",
            "Batch: 230, Loss: 0.36388756049203064, Accuracy: 0.89805\n",
            "Epoch: 5, Loss: 0.367678162026986, Accuracy: 0.89395\n",
            "Batch: 0, Loss: 0.3663198728497307, Accuracy: 0.8949666666666667\n",
            "Batch: 10, Loss: 0.36318920030981794, Accuracy: 0.89755\n",
            "Batch: 20, Loss: 0.36162286305182006, Accuracy: 0.8984666666666666\n",
            "Batch: 30, Loss: 0.36735508483990786, Accuracy: 0.8963166666666667\n",
            "Batch: 40, Loss: 0.36256200815143125, Accuracy: 0.8957\n",
            "Batch: 50, Loss: 0.36563451354293713, Accuracy: 0.8955\n",
            "Batch: 60, Loss: 0.3596545795184538, Accuracy: 0.8972666666666667\n",
            "Batch: 70, Loss: 0.36078418129325607, Accuracy: 0.8982666666666667\n",
            "Batch: 80, Loss: 0.36175151021969626, Accuracy: 0.8969666666666667\n",
            "Batch: 90, Loss: 0.35993229545216865, Accuracy: 0.89765\n",
            "Batch: 100, Loss: 0.3587384938856659, Accuracy: 0.8990166666666667\n",
            "Batch: 110, Loss: 0.35970935639819496, Accuracy: 0.8976166666666666\n",
            "Batch: 120, Loss: 0.3632012794983338, Accuracy: 0.8980666666666667\n",
            "Batch: 130, Loss: 0.3554065112387648, Accuracy: 0.8982833333333333\n",
            "Batch: 140, Loss: 0.3593877670837272, Accuracy: 0.8966166666666666\n",
            "Batch: 150, Loss: 0.35860596096625386, Accuracy: 0.8984166666666666\n",
            "Batch: 160, Loss: 0.3533142617060189, Accuracy: 0.89955\n",
            "Batch: 170, Loss: 0.35459985161179547, Accuracy: 0.9010333333333334\n",
            "Batch: 180, Loss: 0.35477374928908806, Accuracy: 0.8988666666666667\n",
            "Batch: 190, Loss: 0.3505647156157852, Accuracy: 0.8998333333333334\n",
            "Batch: 200, Loss: 0.35566578758794287, Accuracy: 0.8986166666666666\n",
            "Batch: 210, Loss: 0.3542731600818889, Accuracy: 0.9002\n",
            "Batch: 220, Loss: 0.34937302876982085, Accuracy: 0.90105\n",
            "Batch: 230, Loss: 0.3480582815185184, Accuracy: 0.9017166666666667\n",
            "Epoch: 6, Loss: 0.3515245310721901, Accuracy: 0.8980333333333334\n",
            "Batch: 0, Loss: 0.3502307133620903, Accuracy: 0.8989666666666667\n",
            "Batch: 10, Loss: 0.3475044929752966, Accuracy: 0.9013333333333333\n",
            "Batch: 20, Loss: 0.3461055228074729, Accuracy: 0.9016166666666666\n",
            "Batch: 30, Loss: 0.3520100604535781, Accuracy: 0.9001833333333333\n",
            "Batch: 40, Loss: 0.3474236154163621, Accuracy: 0.8992333333333333\n",
            "Batch: 50, Loss: 0.35103617800862713, Accuracy: 0.8992333333333333\n",
            "Batch: 60, Loss: 0.3450500357159097, Accuracy: 0.9006166666666666\n",
            "Batch: 70, Loss: 0.3460527902906737, Accuracy: 0.90215\n",
            "Batch: 80, Loss: 0.34723172783443207, Accuracy: 0.9009166666666667\n",
            "Batch: 90, Loss: 0.34628019528207815, Accuracy: 0.90055\n",
            "Batch: 100, Loss: 0.3449232997570219, Accuracy: 0.9025\n",
            "Batch: 110, Loss: 0.345927151170334, Accuracy: 0.9013166666666667\n",
            "Batch: 120, Loss: 0.3495669357804185, Accuracy: 0.9012\n",
            "Batch: 130, Loss: 0.34190585351085895, Accuracy: 0.9013333333333333\n",
            "Batch: 140, Loss: 0.3457806808639513, Accuracy: 0.89985\n",
            "Batch: 150, Loss: 0.34542671728111296, Accuracy: 0.90185\n",
            "Batch: 160, Loss: 0.3405501583764557, Accuracy: 0.9028\n",
            "Batch: 170, Loss: 0.34177111454956055, Accuracy: 0.9038\n",
            "Batch: 180, Loss: 0.34178699517842664, Accuracy: 0.90145\n",
            "Batch: 190, Loss: 0.3381424966030291, Accuracy: 0.90305\n",
            "Batch: 200, Loss: 0.3427845365175966, Accuracy: 0.9023166666666667\n",
            "Batch: 210, Loss: 0.3415695999231526, Accuracy: 0.9036333333333333\n",
            "Batch: 220, Loss: 0.3373169948724937, Accuracy: 0.9037833333333334\n",
            "Batch: 230, Loss: 0.3363646251508985, Accuracy: 0.9046333333333333\n",
            "Epoch: 7, Loss: 0.3395439395601174, Accuracy: 0.9012833333333333\n",
            "Batch: 0, Loss: 0.3383220019662292, Accuracy: 0.9016833333333333\n",
            "Batch: 10, Loss: 0.335865196961821, Accuracy: 0.9041833333333333\n",
            "Batch: 20, Loss: 0.3346144803085164, Accuracy: 0.9046333333333333\n",
            "Batch: 30, Loss: 0.34057781724709224, Accuracy: 0.9025333333333333\n",
            "Batch: 40, Loss: 0.3361369675278211, Accuracy: 0.9018833333333334\n",
            "Batch: 50, Loss: 0.3401083105373429, Accuracy: 0.9013666666666666\n",
            "Batch: 60, Loss: 0.3340846343491878, Accuracy: 0.9032833333333333\n",
            "Batch: 70, Loss: 0.3349582687778095, Accuracy: 0.9049666666666667\n",
            "Batch: 80, Loss: 0.33628342651235155, Accuracy: 0.9036833333333333\n",
            "Batch: 90, Loss: 0.33594688812714096, Accuracy: 0.9026666666666666\n",
            "Batch: 100, Loss: 0.33444713695206707, Accuracy: 0.9047333333333333\n",
            "Batch: 110, Loss: 0.33546285137363646, Accuracy: 0.9035166666666666\n",
            "Batch: 120, Loss: 0.33917418941744165, Accuracy: 0.9035\n",
            "Batch: 130, Loss: 0.33162598709341556, Accuracy: 0.9039166666666667\n",
            "Batch: 140, Loss: 0.33540899941756236, Accuracy: 0.9025\n",
            "Batch: 150, Loss: 0.3353337382796365, Accuracy: 0.9043333333333333\n",
            "Batch: 160, Loss: 0.3307574270436474, Accuracy: 0.9054333333333333\n",
            "Batch: 170, Loss: 0.33189312116800646, Accuracy: 0.9064666666666666\n",
            "Batch: 180, Loss: 0.33180760173056595, Accuracy: 0.9041166666666667\n",
            "Batch: 190, Loss: 0.32855771860759203, Accuracy: 0.9055833333333333\n",
            "Batch: 200, Loss: 0.33280039483993545, Accuracy: 0.9045833333333333\n",
            "Batch: 210, Loss: 0.3317300297826708, Accuracy: 0.9056\n",
            "Batch: 220, Loss: 0.3279619777341275, Accuracy: 0.9058333333333334\n",
            "Batch: 230, Loss: 0.3272556753847534, Accuracy: 0.9071833333333333\n",
            "Epoch: 8, Loss: 0.3301855173808506, Accuracy: 0.9037666666666667\n",
            "Batch: 0, Loss: 0.32903619756096897, Accuracy: 0.9044166666666666\n",
            "Batch: 10, Loss: 0.32677809804291624, Accuracy: 0.9062666666666667\n",
            "Batch: 20, Loss: 0.3256577073485796, Accuracy: 0.9068833333333334\n",
            "Batch: 30, Loss: 0.3316260250365885, Accuracy: 0.9047166666666666\n",
            "Batch: 40, Loss: 0.3272910746407548, Accuracy: 0.9041\n",
            "Batch: 50, Loss: 0.33151667851464073, Accuracy: 0.9036166666666666\n",
            "Batch: 60, Loss: 0.3254429800744386, Accuracy: 0.9057\n",
            "Batch: 70, Loss: 0.3262012596368746, Accuracy: 0.9071166666666667\n",
            "Batch: 80, Loss: 0.327634319442729, Accuracy: 0.9055833333333333\n",
            "Batch: 90, Loss: 0.32775354979769256, Accuracy: 0.9049666666666667\n",
            "Batch: 100, Loss: 0.3261319903935219, Accuracy: 0.9071666666666667\n",
            "Batch: 110, Loss: 0.3271508157181382, Accuracy: 0.90565\n",
            "Batch: 120, Loss: 0.33087905449244903, Accuracy: 0.9056833333333333\n",
            "Batch: 130, Loss: 0.323445705836874, Accuracy: 0.9064666666666666\n",
            "Batch: 140, Loss: 0.327156246189541, Accuracy: 0.9049166666666667\n",
            "Batch: 150, Loss: 0.3272662978258686, Accuracy: 0.90595\n",
            "Batch: 160, Loss: 0.3229164739320585, Accuracy: 0.9078166666666667\n",
            "Batch: 170, Loss: 0.32396538316693657, Accuracy: 0.9087333333333333\n",
            "Batch: 180, Loss: 0.3238131552734004, Accuracy: 0.9061833333333333\n",
            "Batch: 190, Loss: 0.3208553419624503, Accuracy: 0.9081333333333333\n",
            "Batch: 200, Loss: 0.3247574584030472, Accuracy: 0.9064666666666666\n",
            "Batch: 210, Loss: 0.3238037574717842, Accuracy: 0.9078\n",
            "Batch: 220, Loss: 0.3204106348432024, Accuracy: 0.9079\n",
            "Batch: 230, Loss: 0.31987792694000505, Accuracy: 0.9089333333333334\n",
            "Epoch: 9, Loss: 0.322592172891642, Accuracy: 0.9063666666666667\n",
            "Batch: 0, Loss: 0.32151251351937177, Accuracy: 0.9067\n",
            "Batch: 10, Loss: 0.3194112130784169, Accuracy: 0.90815\n",
            "Batch: 20, Loss: 0.3184030062732615, Accuracy: 0.9088666666666667\n",
            "Batch: 30, Loss: 0.32434755110877905, Accuracy: 0.9064\n",
            "Batch: 40, Loss: 0.32009250993760885, Accuracy: 0.90675\n",
            "Batch: 50, Loss: 0.3245068853799778, Accuracy: 0.9055833333333333\n",
            "Batch: 60, Loss: 0.3183804929313342, Accuracy: 0.90775\n",
            "Batch: 70, Loss: 0.31904047031648286, Accuracy: 0.9089833333333334\n",
            "Batch: 80, Loss: 0.32055526476552276, Accuracy: 0.9072166666666667\n",
            "Batch: 90, Loss: 0.3210234993129814, Accuracy: 0.9068166666666667\n",
            "Batch: 100, Loss: 0.31929922258045496, Accuracy: 0.9086666666666666\n",
            "Batch: 110, Loss: 0.3203163255579848, Accuracy: 0.9076833333333333\n",
            "Batch: 120, Loss: 0.3240231270048671, Accuracy: 0.9078666666666667\n",
            "Batch: 130, Loss: 0.3167123158709045, Accuracy: 0.9084666666666666\n",
            "Batch: 140, Loss: 0.320365390285969, Accuracy: 0.9066666666666666\n",
            "Batch: 150, Loss: 0.32060158693668206, Accuracy: 0.9081166666666667\n",
            "Batch: 160, Loss: 0.3164277896635115, Accuracy: 0.90975\n",
            "Batch: 170, Loss: 0.317395323598591, Accuracy: 0.9106833333333333\n",
            "Batch: 180, Loss: 0.31719711297424247, Accuracy: 0.9081666666666667\n",
            "Batch: 190, Loss: 0.31446647307552017, Accuracy: 0.9097333333333333\n",
            "Batch: 200, Loss: 0.31807913102966423, Accuracy: 0.9083333333333333\n",
            "Batch: 210, Loss: 0.31721840623794667, Accuracy: 0.9096166666666666\n",
            "Batch: 220, Loss: 0.31412444651801064, Accuracy: 0.91005\n",
            "Batch: 230, Loss: 0.3137177221752238, Accuracy: 0.9106333333333333\n",
            "Epoch: 10, Loss: 0.316245901531327, Accuracy: 0.9079\n",
            "Batch: 0, Loss: 0.3152309007546128, Accuracy: 0.9085166666666666\n",
            "Batch: 10, Loss: 0.31325885475099835, Accuracy: 0.9099833333333334\n",
            "Batch: 20, Loss: 0.31234563380541286, Accuracy: 0.9104833333333333\n",
            "Batch: 30, Loss: 0.31824959173279604, Accuracy: 0.9084\n",
            "Batch: 40, Loss: 0.31405713301597626, Accuracy: 0.9084\n",
            "Batch: 50, Loss: 0.3186166398786876, Accuracy: 0.9073166666666667\n",
            "Batch: 60, Loss: 0.31244027846317196, Accuracy: 0.9094166666666667\n",
            "Batch: 70, Loss: 0.3130180992905984, Accuracy: 0.9109166666666667\n",
            "Batch: 80, Loss: 0.3145951094002841, Accuracy: 0.9088166666666667\n",
            "Batch: 90, Loss: 0.31533698199387866, Accuracy: 0.9084\n",
            "Batch: 100, Loss: 0.31352691092431917, Accuracy: 0.9102166666666667\n",
            "Batch: 110, Loss: 0.3145387368357296, Accuracy: 0.9094333333333333\n",
            "Batch: 120, Loss: 0.3181980441577304, Accuracy: 0.9092833333333333\n",
            "Batch: 130, Loss: 0.3110171171085853, Accuracy: 0.91015\n",
            "Batch: 140, Loss: 0.3146226488823119, Accuracy: 0.9085833333333333\n",
            "Batch: 150, Loss: 0.314947168767703, Accuracy: 0.90945\n",
            "Batch: 160, Loss: 0.31091317740334107, Accuracy: 0.91105\n",
            "Batch: 170, Loss: 0.311807055972336, Accuracy: 0.9121666666666667\n",
            "Batch: 180, Loss: 0.311575169885422, Accuracy: 0.90995\n",
            "Batch: 190, Loss: 0.3090285830167194, Accuracy: 0.9111833333333333\n",
            "Batch: 200, Loss: 0.3123942493789262, Accuracy: 0.9098\n",
            "Batch: 210, Loss: 0.3116068857647796, Accuracy: 0.9110666666666667\n",
            "Batch: 220, Loss: 0.30875832608773207, Accuracy: 0.9113833333333333\n",
            "Batch: 230, Loss: 0.30844486075765315, Accuracy: 0.9120333333333334\n",
            "Epoch: 11, Loss: 0.3108122661065884, Accuracy: 0.9093666666666667\n",
            "Batch: 0, Loss: 0.30985604490982344, Accuracy: 0.90955\n",
            "Batch: 10, Loss: 0.30799358750689837, Accuracy: 0.9115333333333333\n",
            "Batch: 20, Loss: 0.30715994462337615, Accuracy: 0.9120833333333334\n",
            "Batch: 30, Loss: 0.3130129590740637, Accuracy: 0.9098833333333334\n",
            "Batch: 40, Loss: 0.3088712124132719, Accuracy: 0.90995\n",
            "Batch: 50, Loss: 0.3135452245890619, Accuracy: 0.9088666666666667\n",
            "Batch: 60, Loss: 0.3073245450094655, Accuracy: 0.9108833333333334\n",
            "Batch: 70, Loss: 0.3078341963408672, Accuracy: 0.9123\n",
            "Batch: 80, Loss: 0.30945814055055165, Accuracy: 0.9102166666666667\n",
            "Batch: 90, Loss: 0.31041838821516793, Accuracy: 0.9100333333333334\n",
            "Batch: 100, Loss: 0.3085372422208144, Accuracy: 0.91155\n",
            "Batch: 110, Loss: 0.3095407685888092, Accuracy: 0.9106666666666666\n",
            "Batch: 120, Loss: 0.31313548017626375, Accuracy: 0.9104833333333333\n",
            "Batch: 130, Loss: 0.3060897024612018, Accuracy: 0.9113833333333333\n",
            "Batch: 140, Loss: 0.3096536003716434, Accuracy: 0.91035\n",
            "Batch: 150, Loss: 0.3100421322018278, Accuracy: 0.9110333333333334\n",
            "Batch: 160, Loss: 0.30612102860648954, Accuracy: 0.9126833333333333\n",
            "Batch: 170, Loss: 0.30694937897742003, Accuracy: 0.9132666666666667\n",
            "Batch: 180, Loss: 0.3066911500937932, Accuracy: 0.9116833333333333\n",
            "Batch: 190, Loss: 0.30429853661784123, Accuracy: 0.9124666666666666\n",
            "Batch: 200, Loss: 0.30745195799008973, Accuracy: 0.9110666666666667\n",
            "Batch: 210, Loss: 0.30672207162472925, Accuracy: 0.9123666666666667\n",
            "Batch: 220, Loss: 0.3040797536851826, Accuracy: 0.9129333333333334\n",
            "Batch: 230, Loss: 0.3038361589952726, Accuracy: 0.9133333333333333\n",
            "Epoch: 12, Loss: 0.30606419203148966, Accuracy: 0.9111166666666667\n",
            "Batch: 0, Loss: 0.30516080016144276, Accuracy: 0.9108666666666667\n",
            "Batch: 10, Loss: 0.3033929937390426, Accuracy: 0.91285\n",
            "Batch: 20, Loss: 0.30262563926738106, Accuracy: 0.9134166666666667\n",
            "Batch: 30, Loss: 0.3084212645759193, Accuracy: 0.9111\n",
            "Batch: 40, Loss: 0.3043218053544304, Accuracy: 0.91125\n",
            "Batch: 50, Loss: 0.3090878359102508, Accuracy: 0.9101666666666667\n",
            "Batch: 60, Loss: 0.3028299104371481, Accuracy: 0.9123833333333333\n",
            "Batch: 70, Loss: 0.3032830418355677, Accuracy: 0.9133166666666667\n",
            "Batch: 80, Loss: 0.30494163536166186, Accuracy: 0.91115\n",
            "Batch: 90, Loss: 0.30607862496708726, Accuracy: 0.9112166666666667\n",
            "Batch: 100, Loss: 0.3041389035084736, Accuracy: 0.9126833333333333\n",
            "Batch: 110, Loss: 0.30513152892654094, Accuracy: 0.9121333333333334\n",
            "Batch: 120, Loss: 0.30865081761313135, Accuracy: 0.9116666666666666\n",
            "Batch: 130, Loss: 0.3017432517449817, Accuracy: 0.9126666666666666\n",
            "Batch: 140, Loss: 0.30526860397970385, Accuracy: 0.9118666666666667\n",
            "Batch: 150, Loss: 0.30570550898606597, Accuracy: 0.9123666666666667\n",
            "Batch: 160, Loss: 0.3018767796197573, Accuracy: 0.9136333333333333\n",
            "Batch: 170, Loss: 0.3026473306101446, Accuracy: 0.9146166666666666\n",
            "Batch: 180, Loss: 0.3023671755057562, Accuracy: 0.9132333333333333\n",
            "Batch: 190, Loss: 0.3001065553245471, Accuracy: 0.9136166666666666\n",
            "Batch: 200, Loss: 0.30307605630385687, Accuracy: 0.9126833333333333\n",
            "Batch: 210, Loss: 0.3023910139671642, Accuracy: 0.91365\n",
            "Batch: 220, Loss: 0.29992566988716524, Accuracy: 0.9142\n",
            "Batch: 230, Loss: 0.2997346593211517, Accuracy: 0.9144833333333333\n",
            "Epoch: 13, Loss: 0.3018412368928696, Accuracy: 0.9126833333333333\n",
            "Batch: 0, Loss: 0.30098515302072976, Accuracy: 0.9122166666666667\n",
            "Batch: 10, Loss: 0.2993001515735777, Accuracy: 0.9140333333333334\n",
            "Batch: 20, Loss: 0.2985879023391244, Accuracy: 0.9145\n",
            "Batch: 30, Loss: 0.3043222571279275, Accuracy: 0.9122333333333333\n",
            "Batch: 40, Loss: 0.3002588583839669, Accuracy: 0.9128166666666667\n",
            "Batch: 50, Loss: 0.3050997638626773, Accuracy: 0.9109666666666667\n",
            "Batch: 60, Loss: 0.2988121287337718, Accuracy: 0.91335\n",
            "Batch: 70, Loss: 0.2992182624618474, Accuracy: 0.9146\n",
            "Batch: 80, Loss: 0.3009014813699569, Accuracy: 0.91245\n",
            "Batch: 90, Loss: 0.3021832183224162, Accuracy: 0.9120833333333334\n",
            "Batch: 100, Loss: 0.3001952772059779, Accuracy: 0.9138\n",
            "Batch: 110, Loss: 0.30117488015398663, Accuracy: 0.91325\n",
            "Batch: 120, Loss: 0.3046121438552407, Accuracy: 0.9128666666666667\n",
            "Batch: 130, Loss: 0.29784404942428827, Accuracy: 0.9135666666666666\n",
            "Batch: 140, Loss: 0.3013320734989388, Accuracy: 0.9132833333333333\n",
            "Batch: 150, Loss: 0.3018073458512827, Accuracy: 0.9133666666666667\n",
            "Batch: 160, Loss: 0.2980550714150028, Accuracy: 0.9148\n",
            "Batch: 170, Loss: 0.2987748287535871, Accuracy: 0.91575\n",
            "Batch: 180, Loss: 0.29847545315591817, Accuracy: 0.9145\n",
            "Batch: 190, Loss: 0.2963300834116273, Accuracy: 0.9148\n",
            "Batch: 200, Loss: 0.2991387701057849, Accuracy: 0.9140166666666667\n",
            "Batch: 210, Loss: 0.29848869004879136, Accuracy: 0.9148166666666666\n",
            "Batch: 220, Loss: 0.29617788891065544, Accuracy: 0.9150833333333334\n",
            "Batch: 230, Loss: 0.2960263137485053, Accuracy: 0.9153\n",
            "Epoch: 14, Loss: 0.2980262843906129, Accuracy: 0.91375\n",
            "Batch: 0, Loss: 0.297212681523516, Accuracy: 0.9136333333333333\n",
            "Batch: 10, Loss: 0.29560082238214114, Accuracy: 0.9150166666666667\n",
            "Batch: 20, Loss: 0.2949344184087522, Accuracy: 0.91585\n",
            "Batch: 30, Loss: 0.3006053699976519, Accuracy: 0.9131833333333333\n",
            "Batch: 40, Loss: 0.29657322825743626, Accuracy: 0.9139333333333334\n",
            "Batch: 50, Loss: 0.30147556187159874, Accuracy: 0.9120666666666667\n",
            "Batch: 60, Loss: 0.29516561170537053, Accuracy: 0.9142333333333333\n",
            "Batch: 70, Loss: 0.2955324709511476, Accuracy: 0.9155833333333333\n",
            "Batch: 80, Loss: 0.2972320628408265, Accuracy: 0.9134666666666666\n",
            "Batch: 90, Loss: 0.29863356248102974, Accuracy: 0.91325\n",
            "Batch: 100, Loss: 0.29660579766124184, Accuracy: 0.9149\n",
            "Batch: 110, Loss: 0.29757078803126763, Accuracy: 0.91435\n",
            "Batch: 120, Loss: 0.3009221708371101, Accuracy: 0.91415\n",
            "Batch: 130, Loss: 0.29429349034163377, Accuracy: 0.9149\n",
            "Batch: 140, Loss: 0.2977442161687848, Accuracy: 0.9141\n",
            "Batch: 150, Loss: 0.2982515381104533, Accuracy: 0.9142333333333333\n",
            "Batch: 160, Loss: 0.2945632055960896, Accuracy: 0.91565\n",
            "Batch: 170, Loss: 0.2952383492194003, Accuracy: 0.9167\n",
            "Batch: 180, Loss: 0.29492144141271287, Accuracy: 0.9156333333333333\n",
            "Batch: 190, Loss: 0.29287812201384444, Accuracy: 0.9159333333333334\n",
            "Batch: 200, Loss: 0.29554487584565214, Accuracy: 0.9151\n",
            "Batch: 210, Loss: 0.2949221686499998, Accuracy: 0.91605\n",
            "Batch: 220, Loss: 0.29274830771930715, Accuracy: 0.9162333333333333\n",
            "Batch: 230, Loss: 0.2926259190637808, Accuracy: 0.9162833333333333\n",
            "Epoch: 15, Loss: 0.2945314687089437, Accuracy: 0.9147\n",
            "Batch: 0, Loss: 0.2937563177505322, Accuracy: 0.91465\n",
            "Batch: 10, Loss: 0.2922095789125436, Accuracy: 0.9160166666666667\n",
            "Batch: 20, Loss: 0.29158143598279207, Accuracy: 0.9168166666666666\n",
            "Batch: 30, Loss: 0.2971880504070596, Accuracy: 0.9139666666666667\n",
            "Batch: 40, Loss: 0.2931833009507743, Accuracy: 0.9151\n",
            "Batch: 50, Loss: 0.2981363117119994, Accuracy: 0.9131833333333333\n",
            "Batch: 60, Loss: 0.29181094061246815, Accuracy: 0.91535\n",
            "Batch: 70, Loss: 0.29214478375011677, Accuracy: 0.9164833333333333\n",
            "Batch: 80, Loss: 0.29385391482598106, Accuracy: 0.9146833333333333\n",
            "Batch: 90, Loss: 0.29535538251952265, Accuracy: 0.9140166666666667\n",
            "Batch: 100, Loss: 0.29329448830250504, Accuracy: 0.9160166666666667\n",
            "Batch: 110, Loss: 0.2942437992026588, Accuracy: 0.9152166666666667\n",
            "Batch: 120, Loss: 0.2975071803059407, Accuracy: 0.9151666666666667\n",
            "Batch: 130, Loss: 0.29101696092875456, Accuracy: 0.9159666666666667\n",
            "Batch: 140, Loss: 0.2944297007148916, Accuracy: 0.9151833333333333\n",
            "Batch: 150, Loss: 0.2949651772113895, Accuracy: 0.91535\n",
            "Batch: 160, Loss: 0.29133086948201437, Accuracy: 0.9166333333333333\n",
            "Batch: 170, Loss: 0.2919667552581427, Accuracy: 0.9177833333333333\n",
            "Batch: 180, Loss: 0.2916333782158157, Accuracy: 0.9167\n",
            "Batch: 190, Loss: 0.28968142584158807, Accuracy: 0.9167833333333333\n",
            "Batch: 200, Loss: 0.29222169450325164, Accuracy: 0.9163\n",
            "Batch: 210, Loss: 0.2916206622109146, Accuracy: 0.9169833333333334\n",
            "Batch: 220, Loss: 0.2895696236869005, Accuracy: 0.9172333333333333\n",
            "Batch: 230, Loss: 0.28946826563516553, Accuracy: 0.9171333333333334\n",
            "Epoch: 16, Loss: 0.2912892987580295, Accuracy: 0.9157833333333333\n",
            "Batch: 0, Loss: 0.29054937083032767, Accuracy: 0.9153333333333333\n",
            "Batch: 10, Loss: 0.28906101947571744, Accuracy: 0.9170666666666667\n",
            "Batch: 20, Loss: 0.2884649757346, Accuracy: 0.9177166666666666\n",
            "Batch: 30, Loss: 0.2940071228503339, Accuracy: 0.9147\n",
            "Batch: 40, Loss: 0.29002653173048726, Accuracy: 0.9159833333333334\n",
            "Batch: 50, Loss: 0.29502152737183207, Accuracy: 0.91405\n",
            "Batch: 60, Loss: 0.2886869470008248, Accuracy: 0.91635\n",
            "Batch: 70, Loss: 0.28899286414777314, Accuracy: 0.9174666666666667\n",
            "Batch: 80, Loss: 0.29070585065903876, Accuracy: 0.9156\n",
            "Batch: 90, Loss: 0.2922913801426142, Accuracy: 0.9149666666666667\n",
            "Batch: 100, Loss: 0.29020263724982326, Accuracy: 0.91675\n",
            "Batch: 110, Loss: 0.29113565959909293, Accuracy: 0.9161166666666667\n",
            "Batch: 120, Loss: 0.2943099945955042, Accuracy: 0.9159666666666667\n",
            "Batch: 130, Loss: 0.2879567124654962, Accuracy: 0.9169\n",
            "Batch: 140, Loss: 0.29133037577143944, Accuracy: 0.9162333333333333\n",
            "Batch: 150, Loss: 0.29189169969571976, Accuracy: 0.9162666666666667\n",
            "Batch: 160, Loss: 0.28830352495488326, Accuracy: 0.9175166666666666\n",
            "Batch: 170, Loss: 0.2889047342688158, Accuracy: 0.9185833333333333\n",
            "Batch: 180, Loss: 0.28855554384297577, Accuracy: 0.9175333333333333\n",
            "Batch: 190, Loss: 0.28668615399604336, Accuracy: 0.91775\n",
            "Batch: 200, Loss: 0.28911257738559926, Accuracy: 0.9171333333333334\n",
            "Batch: 210, Loss: 0.2885290713784133, Accuracy: 0.9180666666666667\n",
            "Batch: 220, Loss: 0.2865893080916717, Accuracy: 0.9182666666666667\n",
            "Batch: 230, Loss: 0.28650237611597396, Accuracy: 0.9180666666666667\n",
            "Epoch: 17, Loss: 0.28824686367375196, Accuracy: 0.91675\n",
            "Batch: 0, Loss: 0.2875396752267383, Accuracy: 0.91625\n",
            "Batch: 10, Loss: 0.28610402132690443, Accuracy: 0.9178166666666666\n",
            "Batch: 20, Loss: 0.28553510470826055, Accuracy: 0.9184833333333333\n",
            "Batch: 30, Loss: 0.29101316744955724, Accuracy: 0.9155666666666666\n",
            "Batch: 40, Loss: 0.28705393373184895, Accuracy: 0.9169166666666667\n",
            "Batch: 50, Loss: 0.2920838484995897, Accuracy: 0.9149833333333334\n",
            "Batch: 60, Loss: 0.2857455301122133, Accuracy: 0.9173333333333333\n",
            "Batch: 70, Loss: 0.28602768940870105, Accuracy: 0.9184333333333333\n",
            "Batch: 80, Loss: 0.28773978612718343, Accuracy: 0.9166666666666666\n",
            "Batch: 90, Loss: 0.2893964112300136, Accuracy: 0.9158166666666666\n",
            "Batch: 100, Loss: 0.2872839685502538, Accuracy: 0.9174333333333333\n",
            "Batch: 110, Loss: 0.2882004501817784, Accuracy: 0.91695\n",
            "Batch: 120, Loss: 0.2912853596901898, Accuracy: 0.9167666666666666\n",
            "Batch: 130, Loss: 0.28506715525679716, Accuracy: 0.9177\n",
            "Batch: 140, Loss: 0.2884004561040698, Accuracy: 0.9171166666666667\n",
            "Batch: 150, Loss: 0.28898635138916307, Accuracy: 0.9170833333333334\n",
            "Batch: 160, Loss: 0.2854380307647057, Accuracy: 0.91845\n",
            "Batch: 170, Loss: 0.2860084400203593, Accuracy: 0.9195\n",
            "Batch: 180, Loss: 0.2856438050186409, Accuracy: 0.9181166666666667\n",
            "Batch: 190, Loss: 0.2838496417409667, Accuracy: 0.9187333333333333\n",
            "Batch: 200, Loss: 0.28617255139911024, Accuracy: 0.9176333333333333\n",
            "Batch: 210, Loss: 0.28560368342917, Accuracy: 0.91875\n",
            "Batch: 220, Loss: 0.2837655843483786, Accuracy: 0.91895\n",
            "Batch: 230, Loss: 0.28368765226915865, Accuracy: 0.91895\n",
            "Epoch: 18, Loss: 0.2853619424332909, Accuracy: 0.9174666666666667\n",
            "Batch: 0, Loss: 0.2846856722201657, Accuracy: 0.9171166666666667\n",
            "Batch: 10, Loss: 0.2832978837905203, Accuracy: 0.9186333333333333\n",
            "Batch: 20, Loss: 0.28275210952910074, Accuracy: 0.9192\n",
            "Batch: 30, Loss: 0.28816676976001737, Accuracy: 0.9165\n",
            "Batch: 40, Loss: 0.2842263993386125, Accuracy: 0.9178166666666666\n",
            "Batch: 50, Loss: 0.28928547782072905, Accuracy: 0.91585\n",
            "Batch: 60, Loss: 0.2829481765403219, Accuracy: 0.9183833333333333\n",
            "Batch: 70, Loss: 0.2832100215703717, Accuracy: 0.9191833333333334\n",
            "Batch: 80, Loss: 0.2849172514464437, Accuracy: 0.9175\n",
            "Batch: 90, Loss: 0.28663424895598544, Accuracy: 0.91645\n",
            "Batch: 100, Loss: 0.284501376520033, Accuracy: 0.9184333333333333\n",
            "Batch: 110, Loss: 0.2854013090197823, Accuracy: 0.9176666666666666\n",
            "Batch: 120, Loss: 0.2883968310515284, Accuracy: 0.9176833333333333\n",
            "Batch: 130, Loss: 0.2823116750282578, Accuracy: 0.9186\n",
            "Batch: 140, Loss: 0.28560326538525616, Accuracy: 0.9179\n",
            "Batch: 150, Loss: 0.2862131126010516, Accuracy: 0.9179833333333334\n",
            "Batch: 160, Loss: 0.2826996748711992, Accuracy: 0.9191166666666667\n",
            "Batch: 170, Loss: 0.2832425312199189, Accuracy: 0.92045\n",
            "Batch: 180, Loss: 0.2828625999348536, Accuracy: 0.91905\n",
            "Batch: 190, Loss: 0.2811375201316301, Accuracy: 0.9195\n",
            "Batch: 200, Loss: 0.2833653435509978, Accuracy: 0.9183\n",
            "Batch: 210, Loss: 0.28280924281672803, Accuracy: 0.9195833333333333\n",
            "Batch: 220, Loss: 0.28106468339910623, Accuracy: 0.91965\n",
            "Batch: 230, Loss: 0.28099124090901306, Accuracy: 0.9197333333333333\n",
            "Epoch: 19, Loss: 0.28260033217286135, Accuracy: 0.9182166666666667\n",
            "Batch: 0, Loss: 0.28195372782492023, Accuracy: 0.9178166666666666\n",
            "Batch: 10, Loss: 0.28060968528211927, Accuracy: 0.9195666666666666\n",
            "Batch: 20, Loss: 0.28008388420171315, Accuracy: 0.9199166666666667\n",
            "Batch: 30, Loss: 0.28543596743762173, Accuracy: 0.9173666666666667\n",
            "Batch: 40, Loss: 0.28151219592763743, Accuracy: 0.9184\n",
            "Batch: 50, Loss: 0.28659574352275435, Accuracy: 0.9167666666666666\n",
            "Batch: 60, Loss: 0.28026357278311215, Accuracy: 0.9192333333333333\n",
            "Batch: 70, Loss: 0.280507978013329, Accuracy: 0.9201333333333334\n",
            "Batch: 80, Loss: 0.2822069930823105, Accuracy: 0.9183166666666667\n",
            "Batch: 90, Loss: 0.28397536830091896, Accuracy: 0.9175833333333333\n",
            "Batch: 100, Loss: 0.28182467106795733, Accuracy: 0.9192166666666667\n",
            "Batch: 110, Loss: 0.28270818201951364, Accuracy: 0.9184\n",
            "Batch: 120, Loss: 0.28561462757300776, Accuracy: 0.9184833333333333\n",
            "Batch: 130, Loss: 0.2796604360561596, Accuracy: 0.9193\n",
            "Batch: 140, Loss: 0.28290898986722907, Accuracy: 0.9187166666666666\n",
            "Batch: 150, Loss: 0.28354257328013843, Accuracy: 0.9187666666666666\n",
            "Batch: 160, Loss: 0.28006012357907767, Accuracy: 0.9198166666666666\n",
            "Batch: 170, Loss: 0.28057812051009207, Accuracy: 0.9212333333333333\n",
            "Batch: 180, Loss: 0.28018285958105843, Accuracy: 0.9198333333333333\n",
            "Batch: 190, Loss: 0.27852171728024655, Accuracy: 0.9203333333333333\n",
            "Batch: 200, Loss: 0.2806613107470648, Accuracy: 0.9192666666666667\n",
            "Batch: 210, Loss: 0.28011692003898636, Accuracy: 0.9204333333333333\n",
            "Batch: 220, Loss: 0.27845893636192925, Accuracy: 0.9203833333333333\n",
            "Batch: 230, Loss: 0.2783862011678695, Accuracy: 0.9205166666666666\n",
            "Epoch: 20, Loss: 0.27993397976638046, Accuracy: 0.919\n",
            "Batch: 0, Loss: 0.2793162639093647, Accuracy: 0.9188\n",
            "Batch: 10, Loss: 0.2780124413743085, Accuracy: 0.92035\n",
            "Batch: 20, Loss: 0.2775041161384672, Accuracy: 0.9205833333333333\n",
            "Batch: 30, Loss: 0.2827944821288587, Accuracy: 0.91825\n",
            "Batch: 40, Loss: 0.2788852333350149, Accuracy: 0.9190666666666667\n",
            "Batch: 50, Loss: 0.28398940586238003, Accuracy: 0.9176166666666666\n",
            "Batch: 60, Loss: 0.2776659384840429, Accuracy: 0.9201\n",
            "Batch: 70, Loss: 0.2778953308322217, Accuracy: 0.9209\n",
            "Batch: 80, Loss: 0.27958329783115077, Accuracy: 0.9191666666666667\n",
            "Batch: 90, Loss: 0.2813954044313879, Accuracy: 0.9184166666666667\n",
            "Batch: 100, Loss: 0.2792289948954392, Accuracy: 0.92005\n",
            "Batch: 110, Loss: 0.28009625626908674, Accuracy: 0.9191333333333334\n",
            "Batch: 120, Loss: 0.28291412725769, Accuracy: 0.9194166666666667\n",
            "Batch: 130, Loss: 0.27708884047893534, Accuracy: 0.9200833333333334\n",
            "Batch: 140, Loss: 0.2802931048946353, Accuracy: 0.91945\n",
            "Batch: 150, Loss: 0.2809504415890979, Accuracy: 0.9194666666666667\n",
            "Batch: 160, Loss: 0.27749598168951434, Accuracy: 0.92065\n",
            "Batch: 170, Loss: 0.2779913318766817, Accuracy: 0.92195\n",
            "Batch: 180, Loss: 0.277580552312798, Accuracy: 0.9207\n",
            "Batch: 190, Loss: 0.27597905037092263, Accuracy: 0.9209666666666667\n",
            "Batch: 200, Loss: 0.2780359775492869, Accuracy: 0.91995\n",
            "Batch: 210, Loss: 0.27750288221093383, Accuracy: 0.9212166666666667\n",
            "Batch: 220, Loss: 0.2759254293187878, Accuracy: 0.92125\n",
            "Batch: 230, Loss: 0.27585021092375966, Accuracy: 0.9213166666666667\n",
            "Epoch: 21, Loss: 0.2773396558266075, Accuracy: 0.9196\n",
            "Batch: 0, Loss: 0.27675043671079314, Accuracy: 0.9195666666666666\n",
            "Batch: 10, Loss: 0.275483803309123, Accuracy: 0.9211\n",
            "Batch: 20, Loss: 0.2749910088780431, Accuracy: 0.92155\n",
            "Batch: 30, Loss: 0.2802204776751129, Accuracy: 0.91895\n",
            "Batch: 40, Loss: 0.27632384881006206, Accuracy: 0.9199\n",
            "Batch: 50, Loss: 0.28144546606495624, Accuracy: 0.9184666666666667\n",
            "Batch: 60, Loss: 0.27513384565672805, Accuracy: 0.9207833333333333\n",
            "Batch: 70, Loss: 0.2753502996293105, Accuracy: 0.9214833333333333\n",
            "Batch: 80, Loss: 0.2770248058422738, Accuracy: 0.91985\n",
            "Batch: 90, Loss: 0.27887406468154846, Accuracy: 0.9193333333333333\n",
            "Batch: 100, Loss: 0.27669369736267024, Accuracy: 0.9207666666666666\n",
            "Batch: 110, Loss: 0.2775448549243487, Accuracy: 0.9198166666666666\n",
            "Batch: 120, Loss: 0.280274798233126, Accuracy: 0.92\n",
            "Batch: 130, Loss: 0.27457643319958075, Accuracy: 0.921\n",
            "Batch: 140, Loss: 0.2777352583393532, Accuracy: 0.9204166666666667\n",
            "Batch: 150, Loss: 0.27841648361513394, Accuracy: 0.92025\n",
            "Batch: 160, Loss: 0.27498776820488063, Accuracy: 0.92145\n",
            "Batch: 170, Loss: 0.27546227285339747, Accuracy: 0.9225833333333333\n",
            "Batch: 180, Loss: 0.27503565152787474, Accuracy: 0.9214166666666667\n",
            "Batch: 190, Loss: 0.27349022132901873, Accuracy: 0.9216\n",
            "Batch: 200, Loss: 0.2754689897763998, Accuracy: 0.92075\n",
            "Batch: 210, Loss: 0.27494727417003856, Accuracy: 0.9220833333333334\n",
            "Batch: 220, Loss: 0.27344504289670113, Accuracy: 0.922\n",
            "Batch: 230, Loss: 0.27336464277540035, Accuracy: 0.9219833333333334\n",
            "Epoch: 22, Loss: 0.2747980021275442, Accuracy: 0.9203\n",
            "Batch: 0, Loss: 0.2742371908051933, Accuracy: 0.9203833333333333\n",
            "Batch: 10, Loss: 0.27300512765338913, Accuracy: 0.92195\n",
            "Batch: 20, Loss: 0.27252637236962235, Accuracy: 0.9223\n",
            "Batch: 30, Loss: 0.2776956771597294, Accuracy: 0.9198\n",
            "Batch: 40, Loss: 0.2738099440714045, Accuracy: 0.9206666666666666\n",
            "Batch: 50, Loss: 0.2789463194689768, Accuracy: 0.9189833333333334\n",
            "Batch: 60, Loss: 0.2726493716344075, Accuracy: 0.9216\n",
            "Batch: 70, Loss: 0.2728546841262326, Accuracy: 0.9222\n",
            "Batch: 80, Loss: 0.27451366024411766, Accuracy: 0.9206166666666666\n",
            "Batch: 90, Loss: 0.2763943508890936, Accuracy: 0.9199333333333334\n",
            "Batch: 100, Loss: 0.274201524375203, Accuracy: 0.9214666666666667\n",
            "Batch: 110, Loss: 0.27503664883700923, Accuracy: 0.9208\n",
            "Batch: 120, Loss: 0.2776794304266593, Accuracy: 0.92065\n",
            "Batch: 130, Loss: 0.2721061144429321, Accuracy: 0.9219333333333334\n",
            "Batch: 140, Loss: 0.2752184693064383, Accuracy: 0.9211\n",
            "Batch: 150, Loss: 0.275923761268411, Accuracy: 0.9210833333333334\n",
            "Batch: 160, Loss: 0.2725191792175584, Accuracy: 0.9222333333333333\n",
            "Batch: 170, Loss: 0.2729742939714374, Accuracy: 0.9234166666666667\n",
            "Batch: 180, Loss: 0.2725313950311195, Accuracy: 0.9222\n",
            "Batch: 190, Loss: 0.2710390925871437, Accuracy: 0.9224166666666667\n",
            "Batch: 200, Loss: 0.2729433565898363, Accuracy: 0.9216666666666666\n",
            "Batch: 210, Loss: 0.2724334837603819, Accuracy: 0.9228666666666666\n",
            "Batch: 220, Loss: 0.2710017592641126, Accuracy: 0.9227666666666666\n",
            "Batch: 230, Loss: 0.2709138969243057, Accuracy: 0.9228666666666666\n",
            "Epoch: 23, Loss: 0.27229283995219167, Accuracy: 0.9212833333333333\n",
            "Batch: 0, Loss: 0.27176057447267427, Accuracy: 0.9211333333333334\n",
            "Batch: 10, Loss: 0.27056080438302343, Accuracy: 0.9227\n",
            "Batch: 20, Loss: 0.27009496865384, Accuracy: 0.9228666666666666\n",
            "Batch: 30, Loss: 0.27520472780353405, Accuracy: 0.9207\n",
            "Batch: 40, Loss: 0.27132836415904066, Accuracy: 0.9215166666666667\n",
            "Batch: 50, Loss: 0.2764771473873432, Accuracy: 0.9196\n",
            "Batch: 60, Loss: 0.2701974846166324, Accuracy: 0.9221166666666667\n",
            "Batch: 70, Loss: 0.27039323406514704, Accuracy: 0.9232333333333334\n",
            "Batch: 80, Loss: 0.27203489159814714, Accuracy: 0.9213833333333333\n",
            "Batch: 90, Loss: 0.2739419969157035, Accuracy: 0.9205666666666666\n",
            "Batch: 100, Loss: 0.2717380301067599, Accuracy: 0.9224666666666667\n",
            "Batch: 110, Loss: 0.2725570881492372, Accuracy: 0.9217833333333333\n",
            "Batch: 120, Loss: 0.275113577770011, Accuracy: 0.9215833333333333\n",
            "Batch: 130, Loss: 0.2696635676228474, Accuracy: 0.9225833333333333\n",
            "Batch: 140, Loss: 0.27272854720360185, Accuracy: 0.9218166666666666\n",
            "Batch: 150, Loss: 0.2734580789707746, Accuracy: 0.9217333333333333\n",
            "Batch: 160, Loss: 0.2700765518627175, Accuracy: 0.9230333333333334\n",
            "Batch: 170, Loss: 0.27051344960526524, Accuracy: 0.92425\n",
            "Batch: 180, Loss: 0.27005374791853587, Accuracy: 0.92295\n",
            "Batch: 190, Loss: 0.26861215969151825, Accuracy: 0.9231333333333334\n",
            "Batch: 200, Loss: 0.2704448950154661, Accuracy: 0.9222166666666667\n",
            "Batch: 210, Loss: 0.2699476062067135, Accuracy: 0.9237166666666666\n",
            "Batch: 220, Loss: 0.2685821572464665, Accuracy: 0.9232833333333333\n",
            "Batch: 230, Loss: 0.26848491471526653, Accuracy: 0.9235166666666667\n",
            "Epoch: 24, Loss: 0.2698106629461434, Accuracy: 0.9220666666666667\n",
            "Batch: 0, Loss: 0.26930723935233764, Accuracy: 0.9218833333333334\n",
            "Batch: 10, Loss: 0.26813776700722797, Accuracy: 0.9234166666666667\n",
            "Batch: 20, Loss: 0.26768403709505156, Accuracy: 0.9238833333333333\n",
            "Batch: 30, Loss: 0.27273473888734967, Accuracy: 0.92135\n",
            "Batch: 40, Loss: 0.26886644350039496, Accuracy: 0.9223166666666667\n",
            "Batch: 50, Loss: 0.2740254762943703, Accuracy: 0.9204833333333333\n",
            "Batch: 60, Loss: 0.26776559354007995, Accuracy: 0.92305\n",
            "Batch: 70, Loss: 0.2679531869330064, Accuracy: 0.9239833333333334\n",
            "Batch: 80, Loss: 0.26957596812127804, Accuracy: 0.9221166666666667\n",
            "Batch: 90, Loss: 0.2715050572112371, Accuracy: 0.92125\n",
            "Batch: 100, Loss: 0.2692911463780942, Accuracy: 0.9234333333333333\n",
            "Batch: 110, Loss: 0.27009398828434, Accuracy: 0.9224166666666667\n",
            "Batch: 120, Loss: 0.27256514962412565, Accuracy: 0.9225\n",
            "Batch: 130, Loss: 0.26723683982462276, Accuracy: 0.9232666666666667\n",
            "Batch: 140, Loss: 0.27025366673200973, Accuracy: 0.9225833333333333\n",
            "Batch: 150, Loss: 0.2710075781048734, Accuracy: 0.9224166666666667\n",
            "Batch: 160, Loss: 0.2676484707699162, Accuracy: 0.9236333333333333\n",
            "Batch: 170, Loss: 0.2680681016450488, Accuracy: 0.9249666666666667\n",
            "Batch: 180, Loss: 0.2675910090089538, Accuracy: 0.9237833333333333\n",
            "Batch: 190, Loss: 0.2661981639465379, Accuracy: 0.9239333333333334\n",
            "Batch: 200, Loss: 0.2679618181438788, Accuracy: 0.92305\n",
            "Batch: 210, Loss: 0.26747804965717686, Accuracy: 0.92435\n",
            "Batch: 220, Loss: 0.26617504126765124, Accuracy: 0.9239666666666667\n",
            "Batch: 230, Loss: 0.2660668206409915, Accuracy: 0.9242\n",
            "Epoch: 25, Loss: 0.26734026189309384, Accuracy: 0.9229166666666667\n",
            "Batch: 0, Loss: 0.26686607162412607, Accuracy: 0.9226833333333333\n",
            "Batch: 10, Loss: 0.2657251324157664, Accuracy: 0.9242166666666667\n",
            "Batch: 20, Loss: 0.2652829472362518, Accuracy: 0.9247333333333333\n",
            "Batch: 30, Loss: 0.27027494187096995, Accuracy: 0.9222166666666667\n",
            "Batch: 40, Loss: 0.26641366888108836, Accuracy: 0.92305\n",
            "Batch: 50, Loss: 0.27158085585553865, Accuracy: 0.9212666666666667\n",
            "Batch: 60, Loss: 0.2653432157039805, Accuracy: 0.9237\n",
            "Batch: 70, Loss: 0.2655239260259706, Accuracy: 0.9245333333333333\n",
            "Batch: 80, Loss: 0.2671264643815983, Accuracy: 0.92285\n",
            "Batch: 90, Loss: 0.26907360283080295, Accuracy: 0.9219666666666667\n",
            "Batch: 100, Loss: 0.2668508654171187, Accuracy: 0.92415\n",
            "Batch: 110, Loss: 0.26763722552317476, Accuracy: 0.92325\n",
            "Batch: 120, Loss: 0.27002410929914505, Accuracy: 0.9232333333333334\n",
            "Batch: 130, Loss: 0.26481603194082176, Accuracy: 0.92415\n",
            "Batch: 140, Loss: 0.2677840546568891, Accuracy: 0.9232166666666667\n",
            "Batch: 150, Loss: 0.2685624371574595, Accuracy: 0.9229833333333334\n",
            "Batch: 160, Loss: 0.26522547681754666, Accuracy: 0.92425\n",
            "Batch: 170, Loss: 0.265628625659211, Accuracy: 0.9254833333333333\n",
            "Batch: 180, Loss: 0.26513351964847726, Accuracy: 0.9245166666666667\n",
            "Batch: 190, Loss: 0.26378780596593326, Accuracy: 0.9246666666666666\n",
            "Batch: 200, Loss: 0.2654844266170875, Accuracy: 0.9238\n",
            "Batch: 210, Loss: 0.2650152421437427, Accuracy: 0.9250166666666667\n",
            "Batch: 220, Loss: 0.26377116651858473, Accuracy: 0.92465\n",
            "Batch: 230, Loss: 0.2636506567408964, Accuracy: 0.9250166666666667\n",
            "Epoch: 26, Loss: 0.26487244480759486, Accuracy: 0.9237\n",
            "Batch: 0, Loss: 0.26442791818217454, Accuracy: 0.9234666666666667\n",
            "Batch: 10, Loss: 0.2633139342701712, Accuracy: 0.9249333333333334\n",
            "Batch: 20, Loss: 0.2628829433009709, Accuracy: 0.9253666666666667\n",
            "Batch: 30, Loss: 0.26781643799105265, Accuracy: 0.9229666666666667\n",
            "Batch: 40, Loss: 0.26396142577517273, Accuracy: 0.9237\n",
            "Batch: 50, Loss: 0.26913462277800654, Accuracy: 0.9221\n",
            "Batch: 60, Loss: 0.2629217299090141, Accuracy: 0.9243\n",
            "Batch: 70, Loss: 0.26309672595502825, Accuracy: 0.9251166666666667\n",
            "Batch: 80, Loss: 0.2646778156425467, Accuracy: 0.9237\n",
            "Batch: 90, Loss: 0.2666394948810021, Accuracy: 0.9227166666666666\n",
            "Batch: 100, Loss: 0.26440900491550723, Accuracy: 0.92485\n",
            "Batch: 110, Loss: 0.26517851111590834, Accuracy: 0.9239833333333334\n",
            "Batch: 120, Loss: 0.26748225021898087, Accuracy: 0.9238833333333333\n",
            "Batch: 130, Loss: 0.26239306848752003, Accuracy: 0.92485\n",
            "Batch: 140, Loss: 0.26531175758442394, Accuracy: 0.9239833333333334\n",
            "Batch: 150, Loss: 0.2661146480939899, Accuracy: 0.9238333333333333\n",
            "Batch: 160, Loss: 0.26279985008740014, Accuracy: 0.9249333333333334\n",
            "Batch: 170, Loss: 0.26318719123138296, Accuracy: 0.9261666666666667\n",
            "Batch: 180, Loss: 0.26267344608662957, Accuracy: 0.9251666666666667\n",
            "Batch: 190, Loss: 0.26137353256747503, Accuracy: 0.9252833333333333\n",
            "Batch: 200, Loss: 0.2630048751334288, Accuracy: 0.9244333333333333\n",
            "Batch: 210, Loss: 0.26255141208267974, Accuracy: 0.9256833333333333\n",
            "Batch: 220, Loss: 0.2613630336911585, Accuracy: 0.9256\n",
            "Batch: 230, Loss: 0.2612291838469311, Accuracy: 0.9257666666666666\n",
            "Epoch: 27, Loss: 0.2623998261815569, Accuracy: 0.9246833333333333\n",
            "Batch: 0, Loss: 0.26198538179065245, Accuracy: 0.9243333333333333\n",
            "Batch: 10, Loss: 0.2608969242680408, Accuracy: 0.9255666666666666\n",
            "Batch: 20, Loss: 0.26047695473649096, Accuracy: 0.92605\n",
            "Batch: 30, Loss: 0.2653520090883044, Accuracy: 0.9236833333333333\n",
            "Batch: 40, Loss: 0.26150280550538507, Accuracy: 0.92455\n",
            "Batch: 50, Loss: 0.2666797274641492, Accuracy: 0.9228833333333334\n",
            "Batch: 60, Loss: 0.26049419189538925, Accuracy: 0.9249833333333334\n",
            "Batch: 70, Loss: 0.2606645619140538, Accuracy: 0.9260333333333334\n",
            "Batch: 80, Loss: 0.26222313422688065, Accuracy: 0.9244666666666667\n",
            "Batch: 90, Loss: 0.26419621389217557, Accuracy: 0.92345\n",
            "Batch: 100, Loss: 0.26195903265660825, Accuracy: 0.9255666666666666\n",
            "Batch: 110, Loss: 0.2627112215782052, Accuracy: 0.9247\n",
            "Batch: 120, Loss: 0.2649330281783562, Accuracy: 0.9247\n",
            "Batch: 130, Loss: 0.25996152518229926, Accuracy: 0.9256333333333333\n",
            "Batch: 140, Loss: 0.26283046826395123, Accuracy: 0.92475\n",
            "Batch: 150, Loss: 0.26365784745336146, Accuracy: 0.9244166666666667\n",
            "Batch: 160, Loss: 0.2603654464187665, Accuracy: 0.9257666666666666\n",
            "Batch: 170, Loss: 0.2607375956157419, Accuracy: 0.9269\n",
            "Batch: 180, Loss: 0.26020461429348307, Accuracy: 0.9259666666666667\n",
            "Batch: 190, Loss: 0.2589493765315669, Accuracy: 0.9260333333333334\n",
            "Batch: 200, Loss: 0.26051699320577537, Accuracy: 0.9254333333333333\n",
            "Batch: 210, Loss: 0.2600804216604948, Accuracy: 0.9265166666666667\n",
            "Batch: 220, Loss: 0.25894473334808155, Accuracy: 0.9264833333333333\n",
            "Batch: 230, Loss: 0.25879673050895463, Accuracy: 0.9264333333333333\n",
            "Epoch: 28, Loss: 0.25991666556716314, Accuracy: 0.92545\n",
            "Batch: 0, Loss: 0.2595326655682693, Accuracy: 0.9253666666666667\n",
            "Batch: 10, Loss: 0.2584684219519584, Accuracy: 0.9262666666666667\n",
            "Batch: 20, Loss: 0.2580594534794202, Accuracy: 0.9269\n",
            "Batch: 30, Loss: 0.2628759736496537, Accuracy: 0.9247\n",
            "Batch: 40, Loss: 0.2590324569956409, Accuracy: 0.9253666666666667\n",
            "Batch: 50, Loss: 0.26421060631715804, Accuracy: 0.9238166666666666\n",
            "Batch: 60, Loss: 0.2580551940619496, Accuracy: 0.92575\n",
            "Batch: 70, Loss: 0.2582219643546569, Accuracy: 0.9265833333333333\n",
            "Batch: 80, Loss: 0.2597570696383323, Accuracy: 0.9250333333333334\n",
            "Batch: 90, Loss: 0.2617387284898998, Accuracy: 0.92425\n",
            "Batch: 100, Loss: 0.25949593287812645, Accuracy: 0.9262166666666667\n",
            "Batch: 110, Loss: 0.260230267872139, Accuracy: 0.92565\n",
            "Batch: 120, Loss: 0.2623714326008727, Accuracy: 0.9254833333333333\n",
            "Batch: 130, Loss: 0.2575164968903864, Accuracy: 0.9264166666666667\n",
            "Batch: 140, Loss: 0.26033539260909966, Accuracy: 0.9253333333333333\n",
            "Batch: 150, Loss: 0.26118718525277773, Accuracy: 0.9252\n",
            "Batch: 160, Loss: 0.2579175712107158, Accuracy: 0.9265166666666667\n",
            "Batch: 170, Loss: 0.2582751340868086, Accuracy: 0.92775\n",
            "Batch: 180, Loss: 0.2577223804301329, Accuracy: 0.9267666666666666\n",
            "Batch: 190, Loss: 0.2565108327033214, Accuracy: 0.9266666666666666\n",
            "Batch: 200, Loss: 0.25801614366737696, Accuracy: 0.9261833333333334\n",
            "Batch: 210, Loss: 0.2575976364413023, Accuracy: 0.9270166666666667\n",
            "Batch: 220, Loss: 0.2565118238303011, Accuracy: 0.9272833333333333\n",
            "Batch: 230, Loss: 0.2563490739678311, Accuracy: 0.92715\n",
            "Epoch: 29, Loss: 0.25741873921393776, Accuracy: 0.9261833333333334\n",
            "Batch: 0, Loss: 0.25706545067539727, Accuracy: 0.9263166666666667\n",
            "Batch: 10, Loss: 0.2560241972277763, Accuracy: 0.9269833333333334\n",
            "Batch: 20, Loss: 0.25562634214303664, Accuracy: 0.9276833333333333\n",
            "Batch: 30, Loss: 0.2603840733787836, Accuracy: 0.9253833333333333\n",
            "Batch: 40, Loss: 0.25654646965723016, Accuracy: 0.9262\n",
            "Batch: 50, Loss: 0.26172308555676627, Accuracy: 0.9243333333333333\n",
            "Batch: 60, Loss: 0.2556007542239329, Accuracy: 0.9267333333333333\n",
            "Batch: 70, Loss: 0.25576490356449766, Accuracy: 0.92745\n",
            "Batch: 80, Loss: 0.2572756971109873, Accuracy: 0.9257666666666666\n",
            "Batch: 90, Loss: 0.25926338933566323, Accuracy: 0.9250166666666667\n",
            "Batch: 100, Loss: 0.25701609925439667, Accuracy: 0.9270333333333334\n",
            "Batch: 110, Loss: 0.2577319889400126, Accuracy: 0.92645\n",
            "Batch: 120, Loss: 0.2597938820972494, Accuracy: 0.92635\n",
            "Batch: 130, Loss: 0.25505449095138744, Accuracy: 0.9273333333333333\n",
            "Batch: 140, Loss: 0.2578231421519096, Accuracy: 0.9259666666666667\n",
            "Batch: 150, Loss: 0.258699217348265, Accuracy: 0.92595\n",
            "Batch: 160, Loss: 0.25545287645962533, Accuracy: 0.9274333333333333\n",
            "Batch: 170, Loss: 0.25579649271307225, Accuracy: 0.92855\n",
            "Batch: 180, Loss: 0.25522352259207925, Accuracy: 0.92745\n",
            "Batch: 190, Loss: 0.2540547561292838, Accuracy: 0.9273333333333333\n",
            "Batch: 200, Loss: 0.2554991048358806, Accuracy: 0.92705\n",
            "Batch: 210, Loss: 0.2550998167401931, Accuracy: 0.928\n",
            "Batch: 220, Loss: 0.2540612288366834, Accuracy: 0.9280833333333334\n",
            "Batch: 230, Loss: 0.25388333957071835, Accuracy: 0.9279\n",
            "Epoch: 30, Loss: 0.25490323053078295, Accuracy: 0.9270166666666667\n",
            "Batch: 0, Loss: 0.25458079312965237, Accuracy: 0.9272666666666667\n",
            "Batch: 10, Loss: 0.2535613717526468, Accuracy: 0.9276666666666666\n",
            "Batch: 20, Loss: 0.25317485939665574, Accuracy: 0.92835\n",
            "Batch: 30, Loss: 0.25787337742764305, Accuracy: 0.9262666666666667\n",
            "Batch: 40, Loss: 0.2540422748124384, Accuracy: 0.9269666666666667\n",
            "Batch: 50, Loss: 0.2592143039011037, Accuracy: 0.925\n",
            "Batch: 60, Loss: 0.2531282198998234, Accuracy: 0.9276166666666666\n",
            "Batch: 70, Loss: 0.2532906904285669, Accuracy: 0.9278833333333333\n",
            "Batch: 80, Loss: 0.25477642112132665, Accuracy: 0.9266166666666666\n",
            "Batch: 90, Loss: 0.25676783595072505, Accuracy: 0.9259833333333334\n",
            "Batch: 100, Loss: 0.25451724119990166, Accuracy: 0.9277333333333333\n",
            "Batch: 110, Loss: 0.2552140568669626, Accuracy: 0.927\n",
            "Batch: 120, Loss: 0.257198131270791, Accuracy: 0.9270333333333334\n",
            "Batch: 130, Loss: 0.2525733325402454, Accuracy: 0.9281\n",
            "Batch: 140, Loss: 0.2552916384013694, Accuracy: 0.9267666666666666\n",
            "Batch: 150, Loss: 0.2561918086686386, Accuracy: 0.9267666666666666\n",
            "Batch: 160, Loss: 0.2529692687059522, Accuracy: 0.9283\n",
            "Batch: 170, Loss: 0.25329965102070073, Accuracy: 0.92935\n",
            "Batch: 180, Loss: 0.25270614122448554, Accuracy: 0.9280833333333334\n",
            "Batch: 190, Loss: 0.2515792696364729, Accuracy: 0.9282666666666667\n",
            "Batch: 200, Loss: 0.2529639640932765, Accuracy: 0.9279333333333334\n",
            "Batch: 210, Loss: 0.2525850180516446, Accuracy: 0.9286833333333333\n",
            "Batch: 220, Loss: 0.2515911426178197, Accuracy: 0.92915\n",
            "Batch: 230, Loss: 0.25139790673047363, Accuracy: 0.9288833333333333\n",
            "Epoch: 31, Loss: 0.2523686269118746, Accuracy: 0.92775\n",
            "Batch: 0, Loss: 0.25207702743754246, Accuracy: 0.9279833333333334\n",
            "Batch: 10, Loss: 0.2510783270498857, Accuracy: 0.9286333333333333\n",
            "Batch: 20, Loss: 0.25070349058789926, Accuracy: 0.9290166666666667\n",
            "Batch: 30, Loss: 0.2553421929698657, Accuracy: 0.9269833333333334\n",
            "Batch: 40, Loss: 0.2515185536157413, Accuracy: 0.9277\n",
            "Batch: 50, Loss: 0.25668264263531204, Accuracy: 0.9257666666666666\n",
            "Batch: 60, Loss: 0.2506361764024488, Accuracy: 0.9283166666666667\n",
            "Batch: 70, Loss: 0.2507978814830041, Accuracy: 0.9286833333333333\n",
            "Batch: 80, Loss: 0.2522578822842116, Accuracy: 0.9273333333333333\n",
            "Batch: 90, Loss: 0.2542509057641785, Accuracy: 0.92665\n",
            "Batch: 100, Loss: 0.2519982921018657, Accuracy: 0.9285\n",
            "Batch: 110, Loss: 0.2526753828309744, Accuracy: 0.9279\n",
            "Batch: 120, Loss: 0.2545831776225785, Accuracy: 0.92755\n",
            "Batch: 130, Loss: 0.2500720706179828, Accuracy: 0.9289\n",
            "Batch: 140, Loss: 0.25274001760473247, Accuracy: 0.9277\n",
            "Batch: 150, Loss: 0.253664036689169, Accuracy: 0.9277333333333333\n",
            "Batch: 160, Loss: 0.2504658175139813, Accuracy: 0.9290833333333334\n",
            "Batch: 170, Loss: 0.2507837840419668, Accuracy: 0.9301\n",
            "Batch: 180, Loss: 0.2501695577028675, Accuracy: 0.9290666666666667\n",
            "Batch: 190, Loss: 0.24908367034318477, Accuracy: 0.92905\n",
            "Batch: 200, Loss: 0.25041001278327374, Accuracy: 0.9287\n",
            "Batch: 210, Loss: 0.25005248999375473, Accuracy: 0.9296333333333333\n",
            "Batch: 220, Loss: 0.24910093289785615, Accuracy: 0.9296166666666666\n",
            "Batch: 230, Loss: 0.2488923116962418, Accuracy: 0.9296833333333333\n",
            "Epoch: 32, Loss: 0.24981461273708364, Accuracy: 0.9287333333333333\n",
            "Batch: 0, Loss: 0.24955366696265277, Accuracy: 0.9286833333333333\n",
            "Batch: 10, Loss: 0.24857460937994438, Accuracy: 0.92935\n",
            "Batch: 20, Loss: 0.24821187389100938, Accuracy: 0.9297666666666666\n",
            "Batch: 30, Loss: 0.25278997284466187, Accuracy: 0.9278666666666666\n",
            "Batch: 40, Loss: 0.24897514081943525, Accuracy: 0.9286\n",
            "Batch: 50, Loss: 0.2541276531577086, Accuracy: 0.92645\n",
            "Batch: 60, Loss: 0.24812434943155282, Accuracy: 0.9291\n",
            "Batch: 70, Loss: 0.2482861788465219, Accuracy: 0.92965\n",
            "Batch: 80, Loss: 0.24971985854417272, Accuracy: 0.92805\n",
            "Batch: 90, Loss: 0.25171253706584307, Accuracy: 0.9275166666666667\n",
            "Batch: 100, Loss: 0.24945931060542956, Accuracy: 0.9292666666666667\n",
            "Batch: 110, Loss: 0.25011601548894474, Accuracy: 0.9288666666666666\n",
            "Batch: 120, Loss: 0.25194916003532564, Accuracy: 0.9283333333333333\n",
            "Batch: 130, Loss: 0.24755087568230424, Accuracy: 0.9297\n",
            "Batch: 140, Loss: 0.25016852717771254, Accuracy: 0.9284\n",
            "Batch: 150, Loss: 0.2511160870921364, Accuracy: 0.9287\n",
            "Batch: 160, Loss: 0.24794265671466903, Accuracy: 0.9296\n",
            "Batch: 170, Loss: 0.24824915594489733, Accuracy: 0.9307666666666666\n",
            "Batch: 180, Loss: 0.24761420337546178, Accuracy: 0.9299833333333334\n",
            "Batch: 190, Loss: 0.24656832735979248, Accuracy: 0.9298\n",
            "Batch: 200, Loss: 0.24783763507417236, Accuracy: 0.9295833333333333\n",
            "Batch: 210, Loss: 0.24750256613908989, Accuracy: 0.9304\n",
            "Batch: 220, Loss: 0.24659103444855246, Accuracy: 0.9303833333333333\n",
            "Batch: 230, Loss: 0.24636714026103904, Accuracy: 0.93045\n",
            "Epoch: 33, Loss: 0.24724195138151353, Accuracy: 0.92985\n",
            "Batch: 0, Loss: 0.24701129387915116, Accuracy: 0.9294\n",
            "Batch: 10, Loss: 0.24605082427337768, Accuracy: 0.9301833333333334\n",
            "Batch: 20, Loss: 0.24570069516439563, Accuracy: 0.9304666666666667\n",
            "Batch: 30, Loss: 0.2502172137313527, Accuracy: 0.9286666666666666\n",
            "Batch: 40, Loss: 0.24641291636018356, Accuracy: 0.9295666666666667\n",
            "Batch: 50, Loss: 0.2515499742819437, Accuracy: 0.9272333333333334\n",
            "Batch: 60, Loss: 0.24559349596900104, Accuracy: 0.92995\n",
            "Batch: 70, Loss: 0.2457563187809689, Accuracy: 0.9304833333333333\n",
            "Batch: 80, Loss: 0.24716315470931466, Accuracy: 0.9289833333333334\n",
            "Batch: 90, Loss: 0.24915366050527096, Accuracy: 0.92835\n",
            "Batch: 100, Loss: 0.2469013692180653, Accuracy: 0.9299333333333333\n",
            "Batch: 110, Loss: 0.2475370265518549, Accuracy: 0.92955\n",
            "Batch: 120, Loss: 0.24929724359606067, Accuracy: 0.9292333333333334\n",
            "Batch: 130, Loss: 0.24501092388918197, Accuracy: 0.9305833333333333\n",
            "Batch: 140, Loss: 0.24757840850359505, Accuracy: 0.9291333333333334\n",
            "Batch: 150, Loss: 0.24854913672728907, Accuracy: 0.9294666666666667\n",
            "Batch: 160, Loss: 0.24540087380403966, Accuracy: 0.9307333333333333\n",
            "Batch: 170, Loss: 0.24569700070568484, Accuracy: 0.9313333333333333\n",
            "Batch: 180, Loss: 0.24504149474866918, Accuracy: 0.9308166666666666\n",
            "Batch: 190, Loss: 0.2440345662373837, Accuracy: 0.9307333333333333\n",
            "Batch: 200, Loss: 0.24524818659960335, Accuracy: 0.9303833333333333\n",
            "Batch: 210, Loss: 0.24493654055543174, Accuracy: 0.9311\n",
            "Batch: 220, Loss: 0.24406282950728755, Accuracy: 0.93115\n",
            "Batch: 230, Loss: 0.24382390686257124, Accuracy: 0.9312166666666667\n",
            "Epoch: 34, Loss: 0.24465235263268256, Accuracy: 0.93085\n",
            "Batch: 0, Loss: 0.2444514349640329, Accuracy: 0.9301833333333334\n",
            "Batch: 10, Loss: 0.2435085169857966, Accuracy: 0.931\n",
            "Batch: 20, Loss: 0.24317156804773032, Accuracy: 0.9313833333333333\n",
            "Batch: 30, Loss: 0.2476253414525767, Accuracy: 0.9295833333333333\n",
            "Batch: 40, Loss: 0.24383368038006778, Accuracy: 0.9304\n",
            "Batch: 50, Loss: 0.2489512341853787, Accuracy: 0.9281166666666667\n",
            "Batch: 60, Loss: 0.2430452807230795, Accuracy: 0.9307333333333333\n",
            "Batch: 70, Loss: 0.24320994614105362, Accuracy: 0.9311666666666667\n",
            "Batch: 80, Loss: 0.24458947781389928, Accuracy: 0.9299\n",
            "Batch: 90, Loss: 0.24657607701269343, Accuracy: 0.929\n",
            "Batch: 100, Loss: 0.244326427930942, Accuracy: 0.9307333333333333\n",
            "Batch: 110, Loss: 0.24494038166480062, Accuracy: 0.9302833333333334\n",
            "Batch: 120, Loss: 0.24662948904181808, Accuracy: 0.9302666666666667\n",
            "Batch: 130, Loss: 0.24245426576895882, Accuracy: 0.9315\n",
            "Batch: 140, Loss: 0.2449717644731645, Accuracy: 0.9299833333333334\n",
            "Batch: 150, Loss: 0.24596522235591653, Accuracy: 0.9303\n",
            "Batch: 160, Loss: 0.24284238619615792, Accuracy: 0.9313833333333333\n",
            "Batch: 170, Loss: 0.243129388700126, Accuracy: 0.9320833333333334\n",
            "Batch: 180, Loss: 0.2424536940196832, Accuracy: 0.93155\n",
            "Batch: 190, Loss: 0.24148453912138057, Accuracy: 0.9317\n",
            "Batch: 200, Loss: 0.2426438618144716, Accuracy: 0.93125\n",
            "Batch: 210, Loss: 0.2423565303987222, Accuracy: 0.9319666666666667\n",
            "Batch: 220, Loss: 0.24151851452068965, Accuracy: 0.9319666666666667\n",
            "Batch: 230, Loss: 0.24126491987214213, Accuracy: 0.93215\n",
            "Epoch: 35, Loss: 0.24204832555245323, Accuracy: 0.9317666666666666\n",
            "Batch: 0, Loss: 0.2418764229147369, Accuracy: 0.9313333333333333\n",
            "Batch: 10, Loss: 0.2409500385030398, Accuracy: 0.9317666666666666\n",
            "Batch: 20, Loss: 0.24062689917575303, Accuracy: 0.9321166666666667\n",
            "Batch: 30, Loss: 0.2450165830686689, Accuracy: 0.93055\n",
            "Batch: 40, Loss: 0.24124001132401482, Accuracy: 0.9313\n",
            "Batch: 50, Loss: 0.24633393456351776, Accuracy: 0.9288833333333333\n",
            "Batch: 60, Loss: 0.24048213866484625, Accuracy: 0.9315166666666667\n",
            "Batch: 70, Loss: 0.24064947532012743, Accuracy: 0.9320833333333334\n",
            "Batch: 80, Loss: 0.24200129904582984, Accuracy: 0.9307\n",
            "Batch: 90, Loss: 0.2439823230564314, Accuracy: 0.92995\n",
            "Batch: 100, Loss: 0.24173719379709618, Accuracy: 0.9315\n",
            "Batch: 110, Loss: 0.24232879784580977, Accuracy: 0.9309833333333334\n",
            "Batch: 120, Loss: 0.2439487083625403, Accuracy: 0.9312\n",
            "Batch: 130, Loss: 0.23988368115667047, Accuracy: 0.9323333333333333\n",
            "Batch: 140, Loss: 0.24235141351313416, Accuracy: 0.9308333333333333\n",
            "Batch: 150, Loss: 0.2433670967577513, Accuracy: 0.9309333333333333\n",
            "Batch: 160, Loss: 0.2402698059888054, Accuracy: 0.9322166666666667\n",
            "Batch: 170, Loss: 0.24054908116886242, Accuracy: 0.9327\n",
            "Batch: 180, Loss: 0.23985375730239122, Accuracy: 0.9323333333333333\n",
            "Batch: 190, Loss: 0.2389210825887935, Accuracy: 0.93245\n",
            "Batch: 200, Loss: 0.2400275516098892, Accuracy: 0.9321166666666667\n",
            "Batch: 210, Loss: 0.23976532697908254, Accuracy: 0.93265\n",
            "Batch: 220, Loss: 0.23896095554419106, Accuracy: 0.9325833333333333\n",
            "Batch: 230, Loss: 0.23869313573888049, Accuracy: 0.9328333333333333\n",
            "Epoch: 36, Loss: 0.23943302002929226, Accuracy: 0.9324333333333333\n",
            "Batch: 0, Loss: 0.23928924588035846, Accuracy: 0.9320333333333334\n",
            "Batch: 10, Loss: 0.23837839963599577, Accuracy: 0.9324333333333333\n",
            "Batch: 20, Loss: 0.2380697412757644, Accuracy: 0.9327833333333333\n",
            "Batch: 30, Loss: 0.24239382798701284, Accuracy: 0.93125\n",
            "Batch: 40, Loss: 0.2386351104674354, Accuracy: 0.9320833333333334\n",
            "Batch: 50, Loss: 0.24370131696685282, Accuracy: 0.9294166666666667\n",
            "Batch: 60, Loss: 0.23790712691264382, Accuracy: 0.9325166666666667\n",
            "Batch: 70, Loss: 0.23807794103576088, Accuracy: 0.9328333333333333\n",
            "Batch: 80, Loss: 0.23940170560576657, Accuracy: 0.9313166666666667\n",
            "Batch: 90, Loss: 0.24137552659662545, Accuracy: 0.9307666666666666\n",
            "Batch: 100, Loss: 0.23913697004028278, Accuracy: 0.9323\n",
            "Batch: 110, Loss: 0.23970559124318327, Accuracy: 0.9317166666666666\n",
            "Batch: 120, Loss: 0.24125831064369618, Accuracy: 0.93195\n",
            "Batch: 130, Loss: 0.23730252462454574, Accuracy: 0.9330666666666667\n",
            "Batch: 140, Loss: 0.23972073448951609, Accuracy: 0.9316833333333333\n",
            "Batch: 150, Loss: 0.24075807621000644, Accuracy: 0.93175\n",
            "Batch: 160, Loss: 0.23768629712430528, Accuracy: 0.9330333333333334\n",
            "Batch: 170, Loss: 0.2379593768726084, Accuracy: 0.9334666666666667\n",
            "Batch: 180, Loss: 0.2372451752530433, Accuracy: 0.9330833333333334\n",
            "Batch: 190, Loss: 0.2363475674342058, Accuracy: 0.9333\n",
            "Batch: 200, Loss: 0.2374026945072906, Accuracy: 0.9328666666666666\n",
            "Batch: 210, Loss: 0.2371662399961825, Accuracy: 0.93345\n",
            "Batch: 220, Loss: 0.23639353670388205, Accuracy: 0.9334\n",
            "Batch: 230, Loss: 0.23611200673571128, Accuracy: 0.9335333333333333\n",
            "Epoch: 37, Loss: 0.2368100626478671, Accuracy: 0.9331166666666667\n",
            "Batch: 0, Loss: 0.236693390133101, Accuracy: 0.9328166666666666\n",
            "Batch: 10, Loss: 0.23579711787430685, Accuracy: 0.9331166666666667\n",
            "Batch: 20, Loss: 0.2355036390294803, Accuracy: 0.9334833333333333\n",
            "Batch: 30, Loss: 0.23976048213281023, Accuracy: 0.9322166666666667\n",
            "Batch: 40, Loss: 0.23602263904018475, Accuracy: 0.9328833333333333\n",
            "Batch: 50, Loss: 0.2410572133521605, Accuracy: 0.93025\n",
            "Batch: 60, Loss: 0.2353237710894491, Accuracy: 0.9333333333333333\n",
            "Batch: 70, Loss: 0.23549884415345543, Accuracy: 0.9334333333333333\n",
            "Batch: 80, Loss: 0.23679424762469703, Accuracy: 0.9320666666666667\n",
            "Batch: 90, Loss: 0.23875925872541567, Accuracy: 0.9316666666666666\n",
            "Batch: 100, Loss: 0.23652950004583165, Accuracy: 0.9329833333333334\n",
            "Batch: 110, Loss: 0.23707452061953072, Accuracy: 0.9324666666666667\n",
            "Batch: 120, Loss: 0.2385621438413997, Accuracy: 0.9325166666666667\n",
            "Batch: 130, Loss: 0.23471456737608576, Accuracy: 0.9338\n",
            "Batch: 140, Loss: 0.23708350852896173, Accuracy: 0.93245\n",
            "Batch: 150, Loss: 0.238141884907867, Accuracy: 0.9324666666666667\n",
            "Batch: 160, Loss: 0.2350954301301393, Accuracy: 0.93385\n",
            "Batch: 170, Loss: 0.23536395670658927, Accuracy: 0.9343333333333333\n",
            "Batch: 180, Loss: 0.23463181218997306, Accuracy: 0.9339\n",
            "Batch: 190, Loss: 0.2337677460563463, Accuracy: 0.9340666666666667\n",
            "Batch: 200, Loss: 0.23477312564722524, Accuracy: 0.93365\n",
            "Batch: 210, Loss: 0.2345629409616916, Accuracy: 0.9342\n",
            "Batch: 220, Loss: 0.23382000729973623, Accuracy: 0.9342333333333334\n",
            "Batch: 230, Loss: 0.23352532821729546, Accuracy: 0.9342666666666667\n",
            "Epoch: 38, Loss: 0.2341833938372312, Accuracy: 0.93375\n",
            "Batch: 0, Loss: 0.2340926821294955, Accuracy: 0.9336\n",
            "Batch: 10, Loss: 0.2332100628945096, Accuracy: 0.9337833333333333\n",
            "Batch: 20, Loss: 0.2329324737903782, Accuracy: 0.9344\n",
            "Batch: 30, Loss: 0.23712032028396168, Accuracy: 0.9328666666666666\n",
            "Batch: 40, Loss: 0.23340655568509258, Accuracy: 0.9338\n",
            "Batch: 50, Loss: 0.23840588469044346, Accuracy: 0.9310833333333334\n",
            "Batch: 60, Loss: 0.23273591223790333, Accuracy: 0.9343166666666667\n",
            "Batch: 70, Loss: 0.23291599865040383, Accuracy: 0.9342166666666667\n",
            "Batch: 80, Loss: 0.23418278611000826, Accuracy: 0.93285\n",
            "Batch: 90, Loss: 0.23613738676560753, Accuracy: 0.9324666666666667\n",
            "Batch: 100, Loss: 0.2339188124522402, Accuracy: 0.9337333333333333\n",
            "Batch: 110, Loss: 0.2344396327312901, Accuracy: 0.93335\n",
            "Batch: 120, Loss: 0.23586433882492236, Accuracy: 0.9334833333333333\n",
            "Batch: 130, Loss: 0.23212384220145635, Accuracy: 0.9346\n",
            "Batch: 140, Loss: 0.23444376443808915, Accuracy: 0.93325\n",
            "Batch: 150, Loss: 0.23552250256863005, Accuracy: 0.9330166666666667\n",
            "Batch: 160, Loss: 0.23250104002503716, Accuracy: 0.9345166666666667\n",
            "Batch: 170, Loss: 0.23276673258481062, Accuracy: 0.9351\n",
            "Batch: 180, Loss: 0.2320177502348102, Accuracy: 0.9347\n",
            "Batch: 190, Loss: 0.23118560360207455, Accuracy: 0.9347333333333333\n",
            "Batch: 200, Loss: 0.23214292800470263, Accuracy: 0.9346666666666666\n",
            "Batch: 210, Loss: 0.2319593122323397, Accuracy: 0.9348\n",
            "Batch: 220, Loss: 0.231244333456009, Accuracy: 0.9352833333333334\n",
            "Batch: 230, Loss: 0.23093709160263026, Accuracy: 0.93505\n",
            "Epoch: 39, Loss: 0.231557113513388, Accuracy: 0.9345166666666667\n",
            "Batch: 0, Loss: 0.2314911366273811, Accuracy: 0.9344\n",
            "Batch: 10, Loss: 0.2306213069942744, Accuracy: 0.9346666666666666\n",
            "Batch: 20, Loss: 0.23036031359769354, Accuracy: 0.9354\n",
            "Batch: 30, Loss: 0.23447734206489299, Accuracy: 0.9337166666666666\n",
            "Batch: 40, Loss: 0.230790962255913, Accuracy: 0.9346666666666666\n",
            "Batch: 50, Loss: 0.23575185324369724, Accuracy: 0.9320666666666667\n",
            "Batch: 60, Loss: 0.23014756051940902, Accuracy: 0.9348333333333333\n",
            "Batch: 70, Loss: 0.230333385868784, Accuracy: 0.9349333333333333\n",
            "Batch: 80, Loss: 0.23157134792829398, Accuracy: 0.93375\n",
            "Batch: 90, Loss: 0.23351393463816233, Accuracy: 0.9332166666666667\n",
            "Batch: 100, Loss: 0.23130907361965025, Accuracy: 0.9345\n",
            "Batch: 110, Loss: 0.23180511575541296, Accuracy: 0.9341833333333334\n",
            "Batch: 120, Loss: 0.2331691618273312, Accuracy: 0.9341\n",
            "Batch: 130, Loss: 0.22953449785480332, Accuracy: 0.9353333333333333\n",
            "Batch: 140, Loss: 0.23180563414176975, Accuracy: 0.9341\n",
            "Batch: 150, Loss: 0.23290402135821722, Accuracy: 0.9338\n",
            "Batch: 160, Loss: 0.22990709265179862, Accuracy: 0.9353166666666667\n",
            "Batch: 170, Loss: 0.2301717066634781, Accuracy: 0.9358333333333333\n",
            "Batch: 180, Loss: 0.22940714464578857, Accuracy: 0.9353333333333333\n",
            "Batch: 190, Loss: 0.22860521878765983, Accuracy: 0.93555\n",
            "Batch: 200, Loss: 0.22951629015432898, Accuracy: 0.9355333333333333\n",
            "Batch: 210, Loss: 0.22935930772103247, Accuracy: 0.9355833333333333\n",
            "Batch: 220, Loss: 0.22867055989025975, Accuracy: 0.9359666666666666\n",
            "Batch: 230, Loss: 0.22835134889126008, Accuracy: 0.9359166666666666\n",
            "Epoch: 40, Loss: 0.22893534173411403, Accuracy: 0.9353833333333333\n",
            "Batch: 0, Loss: 0.22889281715182544, Accuracy: 0.9349\n",
            "Batch: 10, Loss: 0.22803498640514724, Accuracy: 0.9355666666666667\n",
            "Batch: 20, Loss: 0.22779127456414774, Accuracy: 0.9360666666666667\n",
            "Batch: 30, Loss: 0.2318356369551147, Accuracy: 0.9345833333333333\n",
            "Batch: 40, Loss: 0.2281799650904464, Accuracy: 0.9355\n",
            "Batch: 50, Loss: 0.2330997358978868, Accuracy: 0.9327333333333333\n",
            "Batch: 60, Loss: 0.2275627614140339, Accuracy: 0.9359\n",
            "Batch: 70, Loss: 0.2277550215873986, Accuracy: 0.9357833333333333\n",
            "Batch: 80, Loss: 0.22896399325742783, Accuracy: 0.9345\n",
            "Batch: 90, Loss: 0.230892955769836, Accuracy: 0.9338333333333333\n",
            "Batch: 100, Loss: 0.22870445317832877, Accuracy: 0.9352666666666667\n",
            "Batch: 110, Loss: 0.22917516629146026, Accuracy: 0.935\n",
            "Batch: 120, Loss: 0.23048088063603037, Accuracy: 0.93485\n",
            "Batch: 130, Loss: 0.22695066833767039, Accuracy: 0.9361333333333334\n",
            "Batch: 140, Loss: 0.22917322362116943, Accuracy: 0.93495\n",
            "Batch: 150, Loss: 0.23029051755897056, Accuracy: 0.9345833333333333\n",
            "Batch: 160, Loss: 0.22731756389422528, Accuracy: 0.9360333333333334\n",
            "Batch: 170, Loss: 0.2275828461362352, Accuracy: 0.9367166666666666\n",
            "Batch: 180, Loss: 0.22680409559139686, Accuracy: 0.93625\n",
            "Batch: 190, Loss: 0.22603063952466454, Accuracy: 0.9362666666666667\n",
            "Batch: 200, Loss: 0.22689737480190517, Accuracy: 0.93605\n",
            "Batch: 210, Loss: 0.2267668304237716, Accuracy: 0.9363666666666667\n",
            "Batch: 220, Loss: 0.22610268660756816, Accuracy: 0.9365666666666667\n",
            "Batch: 230, Loss: 0.22577209358936942, Accuracy: 0.93655\n",
            "Epoch: 41, Loss: 0.22632209946766074, Accuracy: 0.9363\n",
            "Batch: 0, Loss: 0.22630171410589525, Accuracy: 0.9356166666666667\n",
            "Batch: 10, Loss: 0.22545517859581096, Accuracy: 0.93665\n",
            "Batch: 20, Loss: 0.22522939881072238, Accuracy: 0.9369166666666666\n",
            "Batch: 30, Loss: 0.22919926310003855, Accuracy: 0.9355\n",
            "Batch: 40, Loss: 0.2255775572046017, Accuracy: 0.9361\n",
            "Batch: 50, Loss: 0.23045408738777112, Accuracy: 0.9335\n",
            "Batch: 60, Loss: 0.22498547914947953, Accuracy: 0.93665\n",
            "Batch: 70, Loss: 0.22518484036002642, Accuracy: 0.9365333333333333\n",
            "Batch: 80, Loss: 0.2263646999442868, Accuracy: 0.93535\n",
            "Batch: 90, Loss: 0.22827842285437133, Accuracy: 0.93465\n",
            "Batch: 100, Loss: 0.22610900734143674, Accuracy: 0.9360666666666667\n",
            "Batch: 110, Loss: 0.22655387440246763, Accuracy: 0.9357666666666666\n",
            "Batch: 120, Loss: 0.22780364866775094, Accuracy: 0.9359\n",
            "Batch: 130, Loss: 0.22437636129452418, Accuracy: 0.9368666666666666\n",
            "Batch: 140, Loss: 0.22655050345106603, Accuracy: 0.9354166666666667\n",
            "Batch: 150, Loss: 0.2276859422134276, Accuracy: 0.93545\n",
            "Batch: 160, Loss: 0.22473633518344358, Accuracy: 0.9369\n",
            "Batch: 170, Loss: 0.2250039775862495, Accuracy: 0.9374\n",
            "Batch: 180, Loss: 0.2242125403315813, Accuracy: 0.93705\n",
            "Batch: 190, Loss: 0.22346577730155828, Accuracy: 0.9369333333333333\n",
            "Batch: 200, Loss: 0.22429020229890967, Accuracy: 0.9369166666666666\n",
            "Batch: 210, Loss: 0.22418563056442264, Accuracy: 0.9371666666666667\n",
            "Batch: 220, Loss: 0.22354456432333755, Accuracy: 0.93725\n",
            "Batch: 230, Loss: 0.2232031616122542, Accuracy: 0.9373\n",
            "Epoch: 42, Loss: 0.22372121272127715, Accuracy: 0.9370333333333334\n",
            "Batch: 0, Loss: 0.2237216443689759, Accuracy: 0.9365666666666667\n",
            "Batch: 10, Loss: 0.22288579945441866, Accuracy: 0.9372333333333334\n",
            "Batch: 20, Loss: 0.22267855282780802, Accuracy: 0.9376166666666667\n",
            "Batch: 30, Loss: 0.22657214378093052, Accuracy: 0.9361333333333334\n",
            "Batch: 40, Loss: 0.22298752470069763, Accuracy: 0.9369666666666666\n",
            "Batch: 50, Loss: 0.22781926269123629, Accuracy: 0.9344333333333333\n",
            "Batch: 60, Loss: 0.2224195007562348, Accuracy: 0.9375166666666667\n",
            "Batch: 70, Loss: 0.22262660020738664, Accuracy: 0.9373\n",
            "Batch: 80, Loss: 0.22377726793590144, Accuracy: 0.9361166666666667\n",
            "Batch: 90, Loss: 0.2256741375192861, Accuracy: 0.9356\n",
            "Batch: 100, Loss: 0.2235265833438784, Accuracy: 0.93675\n",
            "Batch: 110, Loss: 0.22394512977954395, Accuracy: 0.9366666666666666\n",
            "Batch: 120, Loss: 0.22514140970243335, Accuracy: 0.93645\n",
            "Batch: 130, Loss: 0.22181536821947428, Accuracy: 0.9377333333333333\n",
            "Batch: 140, Loss: 0.22394122143185666, Accuracy: 0.9361333333333334\n",
            "Batch: 150, Loss: 0.22509403346285037, Accuracy: 0.9360833333333334\n",
            "Batch: 160, Loss: 0.2221671075566329, Accuracy: 0.9374666666666667\n",
            "Batch: 170, Loss: 0.22243870337388172, Accuracy: 0.938\n",
            "Batch: 180, Loss: 0.22163616828185262, Accuracy: 0.9376666666666666\n",
            "Batch: 190, Loss: 0.2209143228452285, Accuracy: 0.9375833333333333\n",
            "Batch: 200, Loss: 0.22169855324786975, Accuracy: 0.9377833333333333\n",
            "Batch: 210, Loss: 0.22161922655281413, Accuracy: 0.9379666666666666\n",
            "Batch: 220, Loss: 0.22099981126673962, Accuracy: 0.93785\n",
            "Batch: 230, Loss: 0.2206481541687575, Accuracy: 0.9383\n",
            "Epoch: 43, Loss: 0.22113624125510817, Accuracy: 0.93775\n",
            "Batch: 0, Loss: 0.22115617447676025, Accuracy: 0.9372833333333334\n",
            "Batch: 10, Loss: 0.2203305227291219, Accuracy: 0.9381\n",
            "Batch: 20, Loss: 0.2201423485736702, Accuracy: 0.9382666666666667\n",
            "Batch: 30, Loss: 0.22395798417160293, Accuracy: 0.937\n",
            "Batch: 40, Loss: 0.22041337840249603, Accuracy: 0.9380666666666667\n",
            "Batch: 50, Loss: 0.22519930665133675, Accuracy: 0.93535\n",
            "Batch: 60, Loss: 0.21986836257840528, Accuracy: 0.9382666666666667\n",
            "Batch: 70, Loss: 0.22008380924171117, Accuracy: 0.9379833333333333\n",
            "Batch: 80, Loss: 0.22120524551037982, Accuracy: 0.937\n",
            "Batch: 90, Loss: 0.22308366147089595, Accuracy: 0.9362833333333334\n",
            "Batch: 100, Loss: 0.22096074683995098, Accuracy: 0.9375166666666667\n",
            "Batch: 110, Loss: 0.22135255053016323, Accuracy: 0.93745\n",
            "Batch: 120, Loss: 0.2224978246296485, Accuracy: 0.93725\n",
            "Batch: 130, Loss: 0.21927119755456825, Accuracy: 0.93855\n",
            "Batch: 140, Loss: 0.2213488381607109, Accuracy: 0.9369333333333333\n",
            "Batch: 150, Loss: 0.22251825159559233, Accuracy: 0.9369166666666666\n",
            "Batch: 160, Loss: 0.21961333537155087, Accuracy: 0.93825\n",
            "Batch: 170, Loss: 0.21989034090306284, Accuracy: 0.9387666666666666\n",
            "Batch: 180, Loss: 0.21907835983041749, Accuracy: 0.93845\n",
            "Batch: 190, Loss: 0.21837968401917887, Accuracy: 0.9384\n",
            "Batch: 200, Loss: 0.21912589367401492, Accuracy: 0.9384333333333333\n",
            "Batch: 210, Loss: 0.21907084920499745, Accuracy: 0.9388666666666666\n",
            "Batch: 220, Loss: 0.2184717527002555, Accuracy: 0.9386833333333333\n",
            "Batch: 230, Loss: 0.21811038295700486, Accuracy: 0.9391333333333334\n",
            "Epoch: 44, Loss: 0.21857043117040714, Accuracy: 0.9384\n",
            "Batch: 0, Loss: 0.218608567605733, Accuracy: 0.9381333333333334\n",
            "Batch: 10, Loss: 0.21779272241237546, Accuracy: 0.9388166666666666\n",
            "Batch: 20, Loss: 0.21762408789587204, Accuracy: 0.9391\n",
            "Batch: 30, Loss: 0.2213602095745647, Accuracy: 0.9377833333333333\n",
            "Batch: 40, Loss: 0.21785830961281089, Accuracy: 0.93875\n",
            "Batch: 50, Loss: 0.22259787588314786, Accuracy: 0.9360166666666667\n",
            "Batch: 60, Loss: 0.21733529938542334, Accuracy: 0.9389833333333333\n",
            "Batch: 70, Loss: 0.21755967426117445, Accuracy: 0.9388\n",
            "Batch: 80, Loss: 0.21865187750890241, Accuracy: 0.9378833333333333\n",
            "Batch: 90, Loss: 0.22051026909738441, Accuracy: 0.9373166666666667\n",
            "Batch: 100, Loss: 0.21841473244984555, Accuracy: 0.9384\n",
            "Batch: 110, Loss: 0.2187794344292944, Accuracy: 0.93825\n",
            "Batch: 120, Loss: 0.21987622017421632, Accuracy: 0.938\n",
            "Batch: 130, Loss: 0.2167470301431001, Accuracy: 0.9392833333333334\n",
            "Batch: 140, Loss: 0.21877648482784195, Accuracy: 0.93765\n",
            "Batch: 150, Loss: 0.21996173611899952, Accuracy: 0.9376833333333333\n",
            "Batch: 160, Loss: 0.21707817962769102, Accuracy: 0.9391333333333334\n",
            "Batch: 170, Loss: 0.21736188398407982, Accuracy: 0.9395666666666667\n",
            "Batch: 180, Loss: 0.21654214815613648, Accuracy: 0.93905\n",
            "Batch: 190, Loss: 0.21586494533621536, Accuracy: 0.9393333333333334\n",
            "Batch: 200, Loss: 0.21657532477607377, Accuracy: 0.93905\n",
            "Batch: 210, Loss: 0.21654340795532168, Accuracy: 0.9394833333333333\n",
            "Batch: 220, Loss: 0.21596338297021903, Accuracy: 0.9396\n",
            "Batch: 230, Loss: 0.21559283638960444, Accuracy: 0.9398166666666666\n",
            "Epoch: 45, Loss: 0.21602668902568212, Accuracy: 0.9390333333333334\n",
            "Batch: 0, Loss: 0.21608175280142014, Accuracy: 0.9388166666666666\n",
            "Batch: 10, Loss: 0.2152754370423476, Accuracy: 0.9396333333333333\n",
            "Batch: 20, Loss: 0.21512672914579978, Accuracy: 0.9399166666666666\n",
            "Batch: 30, Loss: 0.21878192482359504, Accuracy: 0.9384833333333333\n",
            "Batch: 40, Loss: 0.21532516719109956, Accuracy: 0.9394666666666667\n",
            "Batch: 50, Loss: 0.22001819390494298, Accuracy: 0.9368166666666666\n",
            "Batch: 60, Loss: 0.21482321460499584, Accuracy: 0.9396\n",
            "Batch: 70, Loss: 0.2150570699043252, Accuracy: 0.9398\n",
            "Batch: 80, Loss: 0.21612007428855018, Accuracy: 0.9387333333333333\n",
            "Batch: 90, Loss: 0.21795691997119773, Accuracy: 0.9380833333333334\n",
            "Batch: 100, Loss: 0.21589141603119893, Accuracy: 0.9392333333333334\n",
            "Batch: 110, Loss: 0.21622873092222997, Accuracy: 0.9390166666666667\n",
            "Batch: 120, Loss: 0.21727955828968976, Accuracy: 0.93865\n",
            "Batch: 130, Loss: 0.21424569504361135, Accuracy: 0.9399833333333333\n",
            "Batch: 140, Loss: 0.2162269411803519, Accuracy: 0.9385833333333333\n",
            "Batch: 150, Loss: 0.21742728269866932, Accuracy: 0.9383833333333333\n",
            "Batch: 160, Loss: 0.21456447973660545, Accuracy: 0.9398333333333333\n",
            "Batch: 170, Loss: 0.2148559840685428, Accuracy: 0.9402166666666667\n",
            "Batch: 180, Loss: 0.2140302018017781, Accuracy: 0.9398\n",
            "Batch: 190, Loss: 0.21337284704606588, Accuracy: 0.9402166666666667\n",
            "Batch: 200, Loss: 0.21404955708033233, Accuracy: 0.9395833333333333\n",
            "Batch: 210, Loss: 0.21403947631596118, Accuracy: 0.9399833333333333\n",
            "Batch: 220, Loss: 0.21347734826053122, Accuracy: 0.94025\n",
            "Batch: 230, Loss: 0.21309816423760383, Accuracy: 0.9404666666666667\n",
            "Epoch: 46, Loss: 0.21350757397467238, Accuracy: 0.9398833333333333\n",
            "Batch: 0, Loss: 0.21357831343386635, Accuracy: 0.93955\n",
            "Batch: 10, Loss: 0.2127813534043666, Accuracy: 0.94035\n",
            "Batch: 20, Loss: 0.21265287337624705, Accuracy: 0.9405833333333333\n",
            "Batch: 30, Loss: 0.2162258931325418, Accuracy: 0.93915\n",
            "Batch: 40, Loss: 0.21281645206152722, Accuracy: 0.9401166666666667\n",
            "Batch: 50, Loss: 0.2174630363896695, Accuracy: 0.9375833333333333\n",
            "Batch: 60, Loss: 0.2123346688580617, Accuracy: 0.9402666666666667\n",
            "Batch: 70, Loss: 0.2125785257618056, Accuracy: 0.9405833333333333\n",
            "Batch: 80, Loss: 0.21361239885637423, Accuracy: 0.9396166666666667\n",
            "Batch: 90, Loss: 0.21542624842920707, Accuracy: 0.9390166666666667\n",
            "Batch: 100, Loss: 0.21339330587356983, Accuracy: 0.9400666666666667\n",
            "Batch: 110, Loss: 0.21370303094782467, Accuracy: 0.9398833333333333\n",
            "Batch: 120, Loss: 0.214710423834744, Accuracy: 0.9395333333333333\n",
            "Batch: 130, Loss: 0.21176966260287558, Accuracy: 0.9407\n",
            "Batch: 140, Loss: 0.21370263058492464, Accuracy: 0.9393166666666667\n",
            "Batch: 150, Loss: 0.21491733677750963, Accuracy: 0.9392333333333334\n",
            "Batch: 160, Loss: 0.2120747416106963, Accuracy: 0.94045\n",
            "Batch: 170, Loss: 0.21237494806223203, Accuracy: 0.9410833333333334\n",
            "Batch: 180, Loss: 0.21154482459030477, Accuracy: 0.9405\n",
            "Batch: 190, Loss: 0.21090578069639793, Accuracy: 0.9409833333333333\n",
            "Batch: 200, Loss: 0.2115509064537523, Accuracy: 0.9404\n",
            "Batch: 210, Loss: 0.2115612928339976, Accuracy: 0.9405666666666667\n",
            "Batch: 220, Loss: 0.21101594673419782, Accuracy: 0.941\n",
            "Batch: 230, Loss: 0.21062867722775583, Accuracy: 0.9410166666666666\n",
            "Epoch: 47, Loss: 0.2110153038354717, Accuracy: 0.9406166666666667\n",
            "Batch: 0, Loss: 0.21110049094482933, Accuracy: 0.94045\n",
            "Batch: 10, Loss: 0.2103128060940709, Accuracy: 0.94095\n",
            "Batch: 20, Loss: 0.21020476649438272, Accuracy: 0.9413\n",
            "Batch: 30, Loss: 0.2136945315430296, Accuracy: 0.9399\n",
            "Batch: 40, Loss: 0.21033432486514364, Accuracy: 0.94085\n",
            "Batch: 50, Loss: 0.21493474057275538, Accuracy: 0.9383166666666667\n",
            "Batch: 60, Loss: 0.20987188312791122, Accuracy: 0.9408666666666666\n",
            "Batch: 70, Loss: 0.21012622806100972, Accuracy: 0.94115\n",
            "Batch: 80, Loss: 0.2111310687921751, Accuracy: 0.9405166666666667\n",
            "Batch: 90, Loss: 0.21292056662395675, Accuracy: 0.9397833333333333\n",
            "Batch: 100, Loss: 0.21092254908691657, Accuracy: 0.9408666666666666\n",
            "Batch: 110, Loss: 0.21120457093774903, Accuracy: 0.9404666666666667\n",
            "Batch: 120, Loss: 0.21217102738731838, Accuracy: 0.94035\n",
            "Batch: 130, Loss: 0.20932105108219617, Accuracy: 0.9415\n",
            "Batch: 140, Loss: 0.2112056285385098, Accuracy: 0.9402166666666667\n",
            "Batch: 150, Loss: 0.2124340002016161, Accuracy: 0.9399\n",
            "Batch: 160, Loss: 0.20961113923165395, Accuracy: 0.9412666666666667\n",
            "Batch: 170, Loss: 0.20992074886395354, Accuracy: 0.9416166666666667\n",
            "Batch: 180, Loss: 0.20908796881431854, Accuracy: 0.9412833333333334\n",
            "Batch: 190, Loss: 0.2084657975029721, Accuracy: 0.9415666666666667\n",
            "Batch: 200, Loss: 0.2090813075876225, Accuracy: 0.9412666666666667\n",
            "Batch: 210, Loss: 0.20911077340060027, Accuracy: 0.9410833333333334\n",
            "Batch: 220, Loss: 0.2085811417873792, Accuracy: 0.94165\n",
            "Batch: 230, Loss: 0.20818635783384518, Accuracy: 0.94175\n",
            "Epoch: 48, Loss: 0.20855177098365524, Accuracy: 0.9410833333333334\n",
            "Batch: 0, Loss: 0.2086501996648733, Accuracy: 0.9411\n",
            "Batch: 10, Loss: 0.20787178899436354, Accuracy: 0.9418666666666666\n",
            "Batch: 20, Loss: 0.20778431332118802, Accuracy: 0.9419333333333333\n",
            "Batch: 30, Loss: 0.21118991942937201, Accuracy: 0.9406333333333333\n",
            "Batch: 40, Loss: 0.20788062268841132, Accuracy: 0.9415666666666667\n",
            "Batch: 50, Loss: 0.21243523169130518, Accuracy: 0.9393833333333333\n",
            "Batch: 60, Loss: 0.20743675263296396, Accuracy: 0.9417833333333333\n",
            "Batch: 70, Loss: 0.20770203225650777, Accuracy: 0.94175\n",
            "Batch: 80, Loss: 0.20867796923027188, Accuracy: 0.94135\n",
            "Batch: 90, Loss: 0.2104418772242158, Accuracy: 0.9402833333333334\n",
            "Batch: 100, Loss: 0.20848094910820364, Accuracy: 0.9414\n",
            "Batch: 110, Loss: 0.20873524719694722, Accuracy: 0.9412666666666667\n",
            "Batch: 120, Loss: 0.20966321968617996, Accuracy: 0.94105\n",
            "Batch: 130, Loss: 0.20690164306689066, Accuracy: 0.9419666666666666\n",
            "Batch: 140, Loss: 0.2087376808611032, Accuracy: 0.9407333333333333\n",
            "Batch: 150, Loss: 0.20997904721143745, Accuracy: 0.9405833333333333\n",
            "Batch: 160, Loss: 0.2071755265232709, Accuracy: 0.9419166666666666\n",
            "Batch: 170, Loss: 0.2074950447612841, Accuracy: 0.9424166666666667\n",
            "Batch: 180, Loss: 0.20666125755465697, Accuracy: 0.9420666666666667\n",
            "Batch: 190, Loss: 0.20605462582771436, Accuracy: 0.9422666666666667\n",
            "Batch: 200, Loss: 0.20664233971601445, Accuracy: 0.9422\n",
            "Batch: 210, Loss: 0.20668953096995604, Accuracy: 0.9417166666666666\n",
            "Batch: 220, Loss: 0.20617458394944568, Accuracy: 0.9423\n",
            "Batch: 230, Loss: 0.20577287871368966, Accuracy: 0.9423333333333334\n",
            "Epoch: 49, Loss: 0.20611856439928028, Accuracy: 0.9420333333333333\n",
            "Batch: 0, Loss: 0.20622904876373205, Accuracy: 0.9418166666666666\n",
            "Batch: 10, Loss: 0.2054599748884904, Accuracy: 0.9423333333333334\n",
            "Batch: 20, Loss: 0.20539309966047997, Accuracy: 0.9425\n",
            "Batch: 30, Loss: 0.20871381632977196, Accuracy: 0.94145\n",
            "Batch: 40, Loss: 0.20545688143230353, Accuracy: 0.9421833333333334\n",
            "Batch: 50, Loss: 0.20996605968874338, Accuracy: 0.9401833333333334\n",
            "Batch: 60, Loss: 0.20503086773657578, Accuracy: 0.9424666666666667\n",
            "Batch: 70, Loss: 0.20530748304488797, Accuracy: 0.9423666666666667\n",
            "Batch: 80, Loss: 0.20625467332870695, Accuracy: 0.9418166666666666\n",
            "Batch: 90, Loss: 0.20799189224001705, Accuracy: 0.94115\n",
            "Batch: 100, Loss: 0.20606999045750088, Accuracy: 0.942\n",
            "Batch: 110, Loss: 0.20629663719451283, Accuracy: 0.94195\n",
            "Batch: 120, Loss: 0.2071885142292026, Accuracy: 0.9416833333333333\n",
            "Batch: 130, Loss: 0.2045129082623414, Accuracy: 0.9427\n",
            "Batch: 140, Loss: 0.20630022810584173, Accuracy: 0.9415\n",
            "Batch: 150, Loss: 0.20755394656614254, Accuracy: 0.9414833333333333\n",
            "Batch: 160, Loss: 0.20476945640910044, Accuracy: 0.9425666666666667\n",
            "Batch: 170, Loss: 0.20509920423580544, Accuracy: 0.94305\n",
            "Batch: 180, Loss: 0.2042660124136964, Accuracy: 0.9426666666666667\n",
            "Batch: 190, Loss: 0.20367369444930922, Accuracy: 0.9428\n",
            "Batch: 200, Loss: 0.2042352595219528, Accuracy: 0.9428\n",
            "Batch: 210, Loss: 0.20429889938542353, Accuracy: 0.9423166666666667\n",
            "Batch: 220, Loss: 0.20379763749146768, Accuracy: 0.9430833333333334\n",
            "Batch: 230, Loss: 0.20338962579174583, Accuracy: 0.9431333333333334\n",
            "Epoch: 50, Loss: 0.20371699490583103, Accuracy: 0.9426666666666667\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 512\n",
        "output_size = 10\n",
        "batch_size = 256\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.weights1 = np.random.randn(self.input_dim, self.hidden_dim) / np.sqrt(self.input_dim)\n",
        "        self.weights2 = np.random.randn(self.hidden_dim, self.output_dim) / np.sqrt(self.hidden_dim)\n",
        "\n",
        "        self.bias1 = np.zeros((1, self.hidden_dim))\n",
        "        self.bias2 = np.zeros((1, self.output_dim))\n",
        "\n",
        "    def forward(self, X, bs):\n",
        "        self.batch_size = bs\n",
        "\n",
        "        self.hidden_layer = np.dot(X, self.weights1) + self.bias1\n",
        "        self.hidden_activation = self.sigmoid(self.hidden_layer)\n",
        "        self.output_layer = np.dot(self.hidden_activation, self.weights2) + self.bias2\n",
        "        self.predicted_output = self.softmax(self.output_layer)\n",
        "\n",
        "    def backward(self, X, y, learning_rate):\n",
        "        error = self.predicted_output - y\n",
        "\n",
        "        d_output = error\n",
        "        d_hidden = np.dot(d_output, self.weights2.T) * self.sigmoid_derivative(self.hidden_activation)\n",
        "\n",
        "        self.weights2 -= learning_rate * np.dot(self.hidden_activation.T, d_output) / self.batch_size\n",
        "        self.bias2 -= learning_rate * np.sum(d_output, axis=0, keepdims=True) / self.batch_size\n",
        "        self.weights1 -= learning_rate * np.dot(X.T, d_hidden) / self.batch_size\n",
        "        self.bias1 -= learning_rate * np.sum(d_hidden, axis=0, keepdims=True) / self.batch_size\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exp_scores = np.exp(x)\n",
        "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "(X_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(-1, input_size) / 255.0\n",
        "\n",
        "mlp = MLP(input_size, hidden_size, output_size)\n",
        "\n",
        "learning_rate = 0.1\n",
        "epochs = 50\n",
        "\n",
        "num_batches = X_train.shape[0] // batch_size\n",
        "\n",
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "def calculate_accuracy(y_actual, d):\n",
        "    correct_predictions = np.sum(np.argmax(d, axis=1) == y_actual)\n",
        "    total_predictions = y_actual.shape[0]\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return accuracy\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch in range(num_batches):\n",
        "        start_idx = batch * batch_size\n",
        "        end_idx = (batch + 1) * batch_size\n",
        "\n",
        "        batch_X = X_train[start_idx:end_idx]\n",
        "        batch_y = np.zeros((batch_size, output_size))\n",
        "        batch_y[np.arange(batch_size), y_train[start_idx:end_idx]] = 1\n",
        "\n",
        "        mlp.forward(batch_X, batch_size)\n",
        "        mlp.backward(batch_X, batch_y, learning_rate)\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            mlp.forward(X_train, batch_size)\n",
        "            d = mlp.predicted_output\n",
        "            y_actual = y_train\n",
        "\n",
        "            loss = -np.mean(np.log(d[np.arange(X_train.shape[0]), y_actual]))\n",
        "            accuracy = calculate_accuracy(y_actual, d)\n",
        "\n",
        "            print(f\"Batch: {batch}, Loss: {loss}, Accuracy: {accuracy}\")\n",
        "\n",
        "    mlp.forward(X_train, batch_size)\n",
        "    d = mlp.predicted_output\n",
        "    y_actual = y_train\n",
        "\n",
        "    loss = -np.mean(np.log(d[np.arange(X_train.shape[0]), y_actual]))\n",
        "    accuracy = calculate_accuracy(y_actual, d)\n",
        "\n",
        "    print(f\"Epoch: {epoch + 1}, Loss: {loss}, Accuracy: {accuracy}\")\n",
        "\n",
        "    losses.append(loss)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(epochs), losses)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Epochs vs Loss')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(epochs), accuracies)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Epochs vs Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nh78dbIZgFK2",
        "outputId": "308d73d3-303b-4361-a60d-8e31e265da0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch: 0, Loss: 2.109932362576725, Accuracy: 0.07571666666666667\n",
            "Batch: 10, Loss: 2.095314648939039, Accuracy: 0.08006666666666666\n",
            "Batch: 20, Loss: 2.0548158020705865, Accuracy: 0.0961\n",
            "Batch: 30, Loss: 2.004171069663767, Accuracy: 0.11585\n",
            "Batch: 40, Loss: 1.9573085172319642, Accuracy: 0.13361666666666666\n",
            "Batch: 50, Loss: 1.9202807080945232, Accuracy: 0.14771666666666666\n",
            "Batch: 60, Loss: 1.8788568053746983, Accuracy: 0.1638\n",
            "Batch: 70, Loss: 1.8318688510499386, Accuracy: 0.18196666666666667\n",
            "Batch: 80, Loss: 1.799249485103504, Accuracy: 0.1946\n",
            "Batch: 90, Loss: 1.757447032208229, Accuracy: 0.21256666666666665\n",
            "Batch: 100, Loss: 1.7209268836603742, Accuracy: 0.22661666666666666\n",
            "Batch: 110, Loss: 1.6892414313798625, Accuracy: 0.23935\n",
            "Batch: 120, Loss: 1.6530533689432299, Accuracy: 0.2543\n",
            "Batch: 130, Loss: 1.6229769280716104, Accuracy: 0.26665\n",
            "Batch: 140, Loss: 1.5869711286899504, Accuracy: 0.28096666666666664\n",
            "Batch: 150, Loss: 1.5537752348770582, Accuracy: 0.29473333333333335\n",
            "Batch: 160, Loss: 1.5156152463230135, Accuracy: 0.3100333333333333\n",
            "Batch: 170, Loss: 1.4878602989711065, Accuracy: 0.32156666666666667\n",
            "Batch: 180, Loss: 1.4583283749180491, Accuracy: 0.3335166666666667\n",
            "Batch: 190, Loss: 1.431274399556763, Accuracy: 0.34528333333333333\n",
            "Batch: 200, Loss: 1.4061089153248694, Accuracy: 0.3560333333333333\n",
            "Batch: 210, Loss: 1.3680607319040436, Accuracy: 0.37173333333333336\n",
            "Batch: 220, Loss: 1.3459670179915342, Accuracy: 0.3805\n",
            "Batch: 230, Loss: 1.3196255270927038, Accuracy: 0.39143333333333336\n",
            "Batch: 240, Loss: 1.29311615856059, Accuracy: 0.40271666666666667\n",
            "Batch: 250, Loss: 1.277870993737964, Accuracy: 0.4090666666666667\n",
            "Batch: 260, Loss: 1.2544206603048957, Accuracy: 0.4193\n",
            "Batch: 270, Loss: 1.2263608068935807, Accuracy: 0.43146666666666667\n",
            "Batch: 280, Loss: 1.2018081400111615, Accuracy: 0.44258333333333333\n",
            "Batch: 290, Loss: 1.188307962485456, Accuracy: 0.44838333333333336\n",
            "Batch: 300, Loss: 1.163641464884429, Accuracy: 0.4596\n",
            "Batch: 310, Loss: 1.1492220391870591, Accuracy: 0.4656\n",
            "Batch: 320, Loss: 1.134965312377536, Accuracy: 0.47128333333333333\n",
            "Batch: 330, Loss: 1.1063404066272275, Accuracy: 0.4857666666666667\n",
            "Batch: 340, Loss: 1.0937822768633982, Accuracy: 0.4902\n",
            "Batch: 350, Loss: 1.0810098374534893, Accuracy: 0.4957166666666667\n",
            "Batch: 360, Loss: 1.0661261989707111, Accuracy: 0.50265\n",
            "Batch: 370, Loss: 1.0545077993391494, Accuracy: 0.5082\n",
            "Batch: 380, Loss: 1.039242878601435, Accuracy: 0.5153166666666666\n",
            "Batch: 390, Loss: 1.027293250286148, Accuracy: 0.5195\n",
            "Batch: 400, Loss: 1.0215068411768482, Accuracy: 0.5215333333333333\n",
            "Batch: 410, Loss: 1.0115140976838348, Accuracy: 0.5256\n",
            "Batch: 420, Loss: 1.0035389246748607, Accuracy: 0.5289333333333334\n",
            "Batch: 430, Loss: 0.9928267560718055, Accuracy: 0.5333666666666667\n",
            "Batch: 440, Loss: 0.9768064070908079, Accuracy: 0.54095\n",
            "Batch: 450, Loss: 0.9646524646040698, Accuracy: 0.5466166666666666\n",
            "Batch: 460, Loss: 0.9522445079393235, Accuracy: 0.5522833333333333\n",
            "Batch: 470, Loss: 0.9404922189465693, Accuracy: 0.5575166666666667\n",
            "Batch: 480, Loss: 0.931460009775292, Accuracy: 0.56195\n",
            "Batch: 490, Loss: 0.920774521551437, Accuracy: 0.5664333333333333\n",
            "Batch: 500, Loss: 0.914035619742238, Accuracy: 0.5695833333333333\n",
            "Batch: 510, Loss: 0.8975520320609647, Accuracy: 0.57735\n",
            "Batch: 520, Loss: 0.8878059437753868, Accuracy: 0.58175\n",
            "Batch: 530, Loss: 0.8791743565206478, Accuracy: 0.5860333333333333\n",
            "Batch: 540, Loss: 0.8689854063607279, Accuracy: 0.5895166666666667\n",
            "Batch: 550, Loss: 0.862065151992509, Accuracy: 0.5922833333333334\n",
            "Batch: 560, Loss: 0.8542678100967904, Accuracy: 0.59555\n",
            "Batch: 570, Loss: 0.8482824088637922, Accuracy: 0.5975166666666667\n",
            "Batch: 580, Loss: 0.8435631315489748, Accuracy: 0.6003666666666667\n",
            "Batch: 590, Loss: 0.8327717923519137, Accuracy: 0.6051666666666666\n",
            "Batch: 600, Loss: 0.8253638789544854, Accuracy: 0.6092833333333333\n",
            "Batch: 610, Loss: 0.8200978309696894, Accuracy: 0.6119\n",
            "Batch: 620, Loss: 0.8096969761880279, Accuracy: 0.6159833333333333\n",
            "Batch: 630, Loss: 0.8044003129140966, Accuracy: 0.61875\n",
            "Batch: 640, Loss: 0.7968211313326746, Accuracy: 0.6215833333333334\n",
            "Batch: 650, Loss: 0.7883382028145955, Accuracy: 0.6258333333333334\n",
            "Batch: 660, Loss: 0.7825200575740517, Accuracy: 0.6292833333333333\n",
            "Batch: 670, Loss: 0.7772166246785996, Accuracy: 0.6307333333333334\n",
            "Batch: 680, Loss: 0.7758775902391586, Accuracy: 0.6309166666666667\n",
            "Batch: 690, Loss: 0.7679031817192158, Accuracy: 0.6349833333333333\n",
            "Batch: 700, Loss: 0.7607782913597386, Accuracy: 0.6376166666666667\n",
            "Batch: 710, Loss: 0.7586120583093434, Accuracy: 0.6383\n",
            "Batch: 720, Loss: 0.7538825684093657, Accuracy: 0.6403666666666666\n",
            "Batch: 730, Loss: 0.7498541052427297, Accuracy: 0.6421666666666667\n",
            "Batch: 740, Loss: 0.745163137745739, Accuracy: 0.6433833333333333\n",
            "Batch: 750, Loss: 0.7400524067853596, Accuracy: 0.64645\n",
            "Batch: 760, Loss: 0.735181113018766, Accuracy: 0.6482166666666667\n",
            "Batch: 770, Loss: 0.7290401815539403, Accuracy: 0.6507333333333334\n",
            "Batch: 780, Loss: 0.7226632076866704, Accuracy: 0.6544333333333333\n",
            "Batch: 790, Loss: 0.7186686979871257, Accuracy: 0.6561166666666667\n",
            "Batch: 800, Loss: 0.7121296963696044, Accuracy: 0.6595333333333333\n",
            "Batch: 810, Loss: 0.7079123380402326, Accuracy: 0.6612\n",
            "Batch: 820, Loss: 0.7018045210755149, Accuracy: 0.6637833333333333\n",
            "Batch: 830, Loss: 0.6977555460316596, Accuracy: 0.6659333333333334\n",
            "Batch: 840, Loss: 0.6963287886965082, Accuracy: 0.6669166666666667\n",
            "Batch: 850, Loss: 0.6945744546434879, Accuracy: 0.6670833333333334\n",
            "Batch: 860, Loss: 0.6864389444810396, Accuracy: 0.6712833333333333\n",
            "Batch: 870, Loss: 0.6845414699226761, Accuracy: 0.67235\n",
            "Batch: 880, Loss: 0.6814115788052432, Accuracy: 0.6730166666666667\n",
            "Batch: 890, Loss: 0.6810177718856392, Accuracy: 0.6731333333333334\n",
            "Batch: 900, Loss: 0.6775499503875616, Accuracy: 0.6748833333333333\n",
            "Batch: 910, Loss: 0.6709702894875285, Accuracy: 0.6776833333333333\n",
            "Batch: 920, Loss: 0.6683839402443496, Accuracy: 0.6786666666666666\n",
            "Batch: 930, Loss: 0.6691305491124663, Accuracy: 0.67835\n",
            "Epoch: 1, Loss: 0.6631102191030329, Accuracy: 0.6820166666666667\n",
            "Batch: 0, Loss: 0.6622285300004165, Accuracy: 0.6824166666666667\n",
            "Batch: 10, Loss: 0.6570196107963285, Accuracy: 0.6840833333333334\n",
            "Batch: 20, Loss: 0.6504305491248805, Accuracy: 0.6882166666666667\n",
            "Batch: 30, Loss: 0.6471758312288338, Accuracy: 0.6889333333333333\n",
            "Batch: 40, Loss: 0.6443642085427074, Accuracy: 0.6908666666666666\n",
            "Batch: 50, Loss: 0.6420650884130259, Accuracy: 0.6925833333333333\n",
            "Batch: 60, Loss: 0.6385862058308347, Accuracy: 0.6939\n",
            "Batch: 70, Loss: 0.6354892193160165, Accuracy: 0.6956666666666667\n",
            "Batch: 80, Loss: 0.6337943463584914, Accuracy: 0.6962666666666667\n",
            "Batch: 90, Loss: 0.6275904280647369, Accuracy: 0.6990166666666666\n",
            "Batch: 100, Loss: 0.6249408256290557, Accuracy: 0.6992166666666667\n",
            "Batch: 110, Loss: 0.6219485388257278, Accuracy: 0.70115\n",
            "Batch: 120, Loss: 0.6196307743118776, Accuracy: 0.70215\n",
            "Batch: 130, Loss: 0.6167870721125441, Accuracy: 0.7034333333333334\n",
            "Batch: 140, Loss: 0.6130126823264174, Accuracy: 0.7056333333333333\n",
            "Batch: 150, Loss: 0.6101992439862522, Accuracy: 0.7069166666666666\n",
            "Batch: 160, Loss: 0.6062861647607476, Accuracy: 0.7088\n",
            "Batch: 170, Loss: 0.602819557968835, Accuracy: 0.7101333333333333\n",
            "Batch: 180, Loss: 0.6017815700003422, Accuracy: 0.7101166666666666\n",
            "Batch: 190, Loss: 0.6000737494194355, Accuracy: 0.71165\n",
            "Batch: 200, Loss: 0.5981429745934174, Accuracy: 0.7124333333333334\n",
            "Batch: 210, Loss: 0.594973499180298, Accuracy: 0.7142666666666667\n",
            "Batch: 220, Loss: 0.5943669195291444, Accuracy: 0.7139166666666666\n",
            "Batch: 230, Loss: 0.5928625174523472, Accuracy: 0.71485\n",
            "Batch: 240, Loss: 0.5891101671008563, Accuracy: 0.7167166666666667\n",
            "Batch: 250, Loss: 0.587818936534545, Accuracy: 0.7172833333333334\n",
            "Batch: 260, Loss: 0.5843250802039021, Accuracy: 0.7185333333333334\n",
            "Batch: 270, Loss: 0.5806988284850941, Accuracy: 0.7199833333333333\n",
            "Batch: 280, Loss: 0.576953626239925, Accuracy: 0.7222333333333333\n",
            "Batch: 290, Loss: 0.575169740708615, Accuracy: 0.723\n",
            "Batch: 300, Loss: 0.5725631261781092, Accuracy: 0.72435\n",
            "Batch: 310, Loss: 0.5709012891626701, Accuracy: 0.7251666666666666\n",
            "Batch: 320, Loss: 0.570218563358039, Accuracy: 0.7257166666666667\n",
            "Batch: 330, Loss: 0.5666334187812428, Accuracy: 0.7270333333333333\n",
            "Batch: 340, Loss: 0.5658503392244016, Accuracy: 0.7274666666666667\n",
            "Batch: 350, Loss: 0.5633999459347004, Accuracy: 0.7282833333333333\n",
            "Batch: 360, Loss: 0.5598236644610405, Accuracy: 0.7304333333333334\n",
            "Batch: 370, Loss: 0.5561211582376279, Accuracy: 0.7316833333333334\n",
            "Batch: 380, Loss: 0.5544135417856126, Accuracy: 0.7323833333333334\n",
            "Batch: 390, Loss: 0.5539838605190202, Accuracy: 0.7325\n",
            "Batch: 400, Loss: 0.5541179759400473, Accuracy: 0.7329833333333333\n",
            "Batch: 410, Loss: 0.5512268907101561, Accuracy: 0.734\n",
            "Batch: 420, Loss: 0.5497970867349913, Accuracy: 0.7341\n",
            "Batch: 430, Loss: 0.548422469589809, Accuracy: 0.7343333333333333\n",
            "Batch: 440, Loss: 0.5452978074474853, Accuracy: 0.7356\n",
            "Batch: 450, Loss: 0.5427851932756796, Accuracy: 0.7373166666666666\n",
            "Batch: 460, Loss: 0.541022102307569, Accuracy: 0.7373666666666666\n",
            "Batch: 470, Loss: 0.5351761190772382, Accuracy: 0.7403166666666666\n",
            "Batch: 480, Loss: 0.5331977242144628, Accuracy: 0.7412\n",
            "Batch: 490, Loss: 0.5321746746142574, Accuracy: 0.7417\n",
            "Batch: 500, Loss: 0.5309043815399461, Accuracy: 0.7425166666666667\n",
            "Batch: 510, Loss: 0.5269051452799212, Accuracy: 0.74435\n",
            "Batch: 520, Loss: 0.5248215732589293, Accuracy: 0.7446666666666667\n",
            "Batch: 530, Loss: 0.5219218653020626, Accuracy: 0.7467833333333334\n",
            "Batch: 540, Loss: 0.520966825335598, Accuracy: 0.7469666666666667\n",
            "Batch: 550, Loss: 0.5197349776784513, Accuracy: 0.7480333333333333\n",
            "Batch: 560, Loss: 0.518602424309867, Accuracy: 0.7491333333333333\n",
            "Batch: 570, Loss: 0.5159129223767741, Accuracy: 0.7504666666666666\n",
            "Batch: 580, Loss: 0.5150113228786575, Accuracy: 0.7507166666666667\n",
            "Batch: 590, Loss: 0.5132309766586037, Accuracy: 0.7511166666666667\n",
            "Batch: 600, Loss: 0.5115410478284184, Accuracy: 0.7514666666666666\n",
            "Batch: 610, Loss: 0.509891649096083, Accuracy: 0.7526666666666667\n",
            "Batch: 620, Loss: 0.5080758995455907, Accuracy: 0.7537166666666667\n",
            "Batch: 630, Loss: 0.506609627413748, Accuracy: 0.7541333333333333\n",
            "Batch: 640, Loss: 0.5055864204228887, Accuracy: 0.7546833333333334\n",
            "Batch: 650, Loss: 0.5047005967565956, Accuracy: 0.7556833333333334\n",
            "Batch: 660, Loss: 0.501554435838066, Accuracy: 0.7563833333333333\n",
            "Batch: 670, Loss: 0.5007439937423511, Accuracy: 0.7571166666666667\n",
            "Batch: 680, Loss: 0.5006373618930464, Accuracy: 0.7572833333333333\n",
            "Batch: 690, Loss: 0.4989879112667572, Accuracy: 0.7579666666666667\n",
            "Batch: 700, Loss: 0.4969111731675007, Accuracy: 0.7583166666666666\n",
            "Batch: 710, Loss: 0.49653140643409616, Accuracy: 0.7585\n",
            "Batch: 720, Loss: 0.496455096086185, Accuracy: 0.7590666666666667\n",
            "Batch: 730, Loss: 0.4953691467927953, Accuracy: 0.7589166666666667\n",
            "Batch: 740, Loss: 0.49485378275220304, Accuracy: 0.7589666666666667\n",
            "Batch: 750, Loss: 0.4958598744046533, Accuracy: 0.7587666666666667\n",
            "Batch: 760, Loss: 0.4913915467894054, Accuracy: 0.761\n",
            "Batch: 770, Loss: 0.4914640760704546, Accuracy: 0.7604833333333333\n",
            "Batch: 780, Loss: 0.4897622557464434, Accuracy: 0.7614\n",
            "Batch: 790, Loss: 0.4866123076308945, Accuracy: 0.7626166666666667\n",
            "Batch: 800, Loss: 0.48451657446289675, Accuracy: 0.7641666666666667\n",
            "Batch: 810, Loss: 0.4828564170364252, Accuracy: 0.7650666666666667\n",
            "Batch: 820, Loss: 0.4811847514966341, Accuracy: 0.76565\n",
            "Batch: 830, Loss: 0.47964764109350894, Accuracy: 0.7668166666666667\n",
            "Batch: 840, Loss: 0.48077307550109544, Accuracy: 0.7662333333333333\n",
            "Batch: 850, Loss: 0.4795904913977583, Accuracy: 0.7667666666666667\n",
            "Batch: 860, Loss: 0.47713032222410073, Accuracy: 0.768\n",
            "Batch: 870, Loss: 0.4766935412131576, Accuracy: 0.76825\n",
            "Batch: 880, Loss: 0.47589379788295805, Accuracy: 0.7687666666666667\n",
            "Batch: 890, Loss: 0.4760286171862194, Accuracy: 0.7672166666666667\n",
            "Batch: 900, Loss: 0.47540033364226564, Accuracy: 0.7683666666666666\n",
            "Batch: 910, Loss: 0.4725532966051754, Accuracy: 0.7698333333333334\n",
            "Batch: 920, Loss: 0.47213604313259266, Accuracy: 0.76995\n",
            "Batch: 930, Loss: 0.4754091451371796, Accuracy: 0.76815\n",
            "Epoch: 2, Loss: 0.4716902970185465, Accuracy: 0.7699666666666667\n",
            "Batch: 0, Loss: 0.4710752510692099, Accuracy: 0.7703833333333333\n",
            "Batch: 10, Loss: 0.4693311760064598, Accuracy: 0.7714\n",
            "Batch: 20, Loss: 0.46564668500664025, Accuracy: 0.7738333333333334\n",
            "Batch: 30, Loss: 0.4656708066806171, Accuracy: 0.7736666666666666\n",
            "Batch: 40, Loss: 0.4630605162601482, Accuracy: 0.7750166666666667\n",
            "Batch: 50, Loss: 0.4633957682629366, Accuracy: 0.7748\n",
            "Batch: 60, Loss: 0.46274822617080325, Accuracy: 0.7751333333333333\n",
            "Batch: 70, Loss: 0.4620494713029245, Accuracy: 0.7751\n",
            "Batch: 80, Loss: 0.46175598169947624, Accuracy: 0.7751833333333333\n",
            "Batch: 90, Loss: 0.45814951757422534, Accuracy: 0.7767666666666667\n",
            "Batch: 100, Loss: 0.4570821402546491, Accuracy: 0.7774833333333333\n",
            "Batch: 110, Loss: 0.45623524376314134, Accuracy: 0.7779166666666667\n",
            "Batch: 120, Loss: 0.4560441448326785, Accuracy: 0.7774833333333333\n",
            "Batch: 130, Loss: 0.45491195043314003, Accuracy: 0.7778166666666667\n",
            "Batch: 140, Loss: 0.4545776530195379, Accuracy: 0.7779333333333334\n",
            "Batch: 150, Loss: 0.452345946301101, Accuracy: 0.7797333333333333\n",
            "Batch: 160, Loss: 0.45066262923192457, Accuracy: 0.78085\n",
            "Batch: 170, Loss: 0.44886960603528586, Accuracy: 0.78075\n",
            "Batch: 180, Loss: 0.44856047789960196, Accuracy: 0.7810833333333334\n",
            "Batch: 190, Loss: 0.4488687331266473, Accuracy: 0.7816\n",
            "Batch: 200, Loss: 0.44815359585514797, Accuracy: 0.7818666666666667\n",
            "Batch: 210, Loss: 0.4471919100221654, Accuracy: 0.7823166666666667\n",
            "Batch: 220, Loss: 0.44720196858768796, Accuracy: 0.78215\n",
            "Batch: 230, Loss: 0.4459545836901619, Accuracy: 0.78335\n",
            "Batch: 240, Loss: 0.4449422276268686, Accuracy: 0.7837333333333333\n",
            "Batch: 250, Loss: 0.44480437909898357, Accuracy: 0.7841333333333333\n",
            "Batch: 260, Loss: 0.4428151502877112, Accuracy: 0.7844166666666667\n",
            "Batch: 270, Loss: 0.44178797158721056, Accuracy: 0.7851166666666667\n",
            "Batch: 280, Loss: 0.4405785554618927, Accuracy: 0.7852\n",
            "Batch: 290, Loss: 0.4405014442216741, Accuracy: 0.7851666666666667\n",
            "Batch: 300, Loss: 0.4391178106964852, Accuracy: 0.78595\n",
            "Batch: 310, Loss: 0.4380485678837942, Accuracy: 0.7864\n",
            "Batch: 320, Loss: 0.43811632106149695, Accuracy: 0.7862333333333333\n",
            "Batch: 330, Loss: 0.4372680020952251, Accuracy: 0.78665\n",
            "Batch: 340, Loss: 0.43679005647393815, Accuracy: 0.7868\n",
            "Batch: 350, Loss: 0.43624342415911677, Accuracy: 0.78705\n",
            "Batch: 360, Loss: 0.4347706036031884, Accuracy: 0.7876666666666666\n",
            "Batch: 370, Loss: 0.4331216791466981, Accuracy: 0.7883666666666667\n",
            "Batch: 380, Loss: 0.43297860617049966, Accuracy: 0.78875\n",
            "Batch: 390, Loss: 0.4329975544518471, Accuracy: 0.7888666666666667\n",
            "Batch: 400, Loss: 0.43379341560165996, Accuracy: 0.7884666666666666\n",
            "Batch: 410, Loss: 0.4320653266386855, Accuracy: 0.7887333333333333\n",
            "Batch: 420, Loss: 0.43100407280881264, Accuracy: 0.7892166666666667\n",
            "Batch: 430, Loss: 0.4303111687066856, Accuracy: 0.7899333333333334\n",
            "Batch: 440, Loss: 0.4290491869456691, Accuracy: 0.7901833333333333\n",
            "Batch: 450, Loss: 0.429061316010885, Accuracy: 0.7905333333333333\n",
            "Batch: 460, Loss: 0.42832382267063074, Accuracy: 0.7910166666666667\n",
            "Batch: 470, Loss: 0.42506528856784054, Accuracy: 0.79345\n",
            "Batch: 480, Loss: 0.424574891699959, Accuracy: 0.7935833333333333\n",
            "Batch: 490, Loss: 0.4244404499623633, Accuracy: 0.7934333333333333\n",
            "Batch: 500, Loss: 0.42386514314388063, Accuracy: 0.7934166666666667\n",
            "Batch: 510, Loss: 0.4215485469370449, Accuracy: 0.7952\n",
            "Batch: 520, Loss: 0.42060536243202606, Accuracy: 0.7959666666666667\n",
            "Batch: 530, Loss: 0.4201823035036092, Accuracy: 0.7959833333333334\n",
            "Batch: 540, Loss: 0.4189836375695411, Accuracy: 0.7967\n",
            "Batch: 550, Loss: 0.4184494955908226, Accuracy: 0.79655\n",
            "Batch: 560, Loss: 0.418086750634943, Accuracy: 0.7964166666666667\n",
            "Batch: 570, Loss: 0.4172173299011658, Accuracy: 0.7969166666666667\n",
            "Batch: 580, Loss: 0.4168312210653642, Accuracy: 0.7981833333333334\n",
            "Batch: 590, Loss: 0.4150331317866138, Accuracy: 0.7983666666666667\n",
            "Batch: 600, Loss: 0.4146605795146176, Accuracy: 0.7984833333333333\n",
            "Batch: 610, Loss: 0.4140099106222702, Accuracy: 0.79885\n",
            "Batch: 620, Loss: 0.4134263525550416, Accuracy: 0.79865\n",
            "Batch: 630, Loss: 0.4128793293520908, Accuracy: 0.7991333333333334\n",
            "Batch: 640, Loss: 0.4123486547544762, Accuracy: 0.7992\n",
            "Batch: 650, Loss: 0.4121309795649571, Accuracy: 0.79905\n",
            "Batch: 660, Loss: 0.41103131575191265, Accuracy: 0.7995333333333333\n",
            "Batch: 670, Loss: 0.410120878264842, Accuracy: 0.80025\n",
            "Batch: 680, Loss: 0.4102844808880372, Accuracy: 0.8004\n",
            "Batch: 690, Loss: 0.40992819033355554, Accuracy: 0.8004166666666667\n",
            "Batch: 700, Loss: 0.40906605328517753, Accuracy: 0.8008\n",
            "Batch: 710, Loss: 0.4092700024038217, Accuracy: 0.8005833333333333\n",
            "Batch: 720, Loss: 0.4086676357131674, Accuracy: 0.8010666666666667\n",
            "Batch: 730, Loss: 0.40772237763195235, Accuracy: 0.8016666666666666\n",
            "Batch: 740, Loss: 0.40793288522104476, Accuracy: 0.8015166666666667\n",
            "Batch: 750, Loss: 0.4082766456096446, Accuracy: 0.80075\n",
            "Batch: 760, Loss: 0.4056417342074682, Accuracy: 0.80235\n",
            "Batch: 770, Loss: 0.4054993334944912, Accuracy: 0.8020833333333334\n",
            "Batch: 780, Loss: 0.4054849400851651, Accuracy: 0.8018333333333333\n",
            "Batch: 790, Loss: 0.4038018562730774, Accuracy: 0.80285\n",
            "Batch: 800, Loss: 0.4027779882334879, Accuracy: 0.80365\n",
            "Batch: 810, Loss: 0.4024680929512897, Accuracy: 0.8037666666666666\n",
            "Batch: 820, Loss: 0.4017576727171384, Accuracy: 0.8042166666666667\n",
            "Batch: 830, Loss: 0.40107294319301057, Accuracy: 0.8047666666666666\n",
            "Batch: 840, Loss: 0.40158905806867023, Accuracy: 0.8041166666666667\n",
            "Batch: 850, Loss: 0.4010934464681579, Accuracy: 0.8042\n",
            "Batch: 860, Loss: 0.39914387986133343, Accuracy: 0.8058\n",
            "Batch: 870, Loss: 0.39947705036717, Accuracy: 0.8048\n",
            "Batch: 880, Loss: 0.3991964940033806, Accuracy: 0.8051166666666667\n",
            "Batch: 890, Loss: 0.3989942503066776, Accuracy: 0.8051666666666667\n",
            "Batch: 900, Loss: 0.398234449859732, Accuracy: 0.80535\n",
            "Batch: 910, Loss: 0.3968901803932745, Accuracy: 0.8065166666666667\n",
            "Batch: 920, Loss: 0.3971844474630166, Accuracy: 0.8063333333333333\n",
            "Batch: 930, Loss: 0.3982763488990614, Accuracy: 0.8054333333333333\n",
            "Epoch: 3, Loss: 0.3971574887274081, Accuracy: 0.8066\n",
            "Batch: 0, Loss: 0.3972575652328866, Accuracy: 0.8066666666666666\n",
            "Batch: 10, Loss: 0.39703715235764886, Accuracy: 0.8063333333333333\n",
            "Batch: 20, Loss: 0.39524456925268253, Accuracy: 0.8073166666666667\n",
            "Batch: 30, Loss: 0.395003819979015, Accuracy: 0.8072833333333334\n",
            "Batch: 40, Loss: 0.39304834581081327, Accuracy: 0.8089666666666666\n",
            "Batch: 50, Loss: 0.3929934895101969, Accuracy: 0.8089333333333333\n",
            "Batch: 60, Loss: 0.39253944511729494, Accuracy: 0.8093\n",
            "Batch: 70, Loss: 0.3916557649311397, Accuracy: 0.8087833333333333\n",
            "Batch: 80, Loss: 0.39247024843006884, Accuracy: 0.8085666666666667\n",
            "Batch: 90, Loss: 0.3902354441251767, Accuracy: 0.8097833333333333\n",
            "Batch: 100, Loss: 0.38963420518815495, Accuracy: 0.8100666666666667\n",
            "Batch: 110, Loss: 0.38964612252360437, Accuracy: 0.8098666666666666\n",
            "Batch: 120, Loss: 0.3886621906782746, Accuracy: 0.8099166666666666\n",
            "Batch: 130, Loss: 0.3885605460924575, Accuracy: 0.81\n",
            "Batch: 140, Loss: 0.3883579351976404, Accuracy: 0.8102666666666667\n",
            "Batch: 150, Loss: 0.38686166905405617, Accuracy: 0.8110333333333334\n",
            "Batch: 160, Loss: 0.3851885514985049, Accuracy: 0.8118666666666666\n",
            "Batch: 170, Loss: 0.38429758766544303, Accuracy: 0.8119666666666666\n",
            "Batch: 180, Loss: 0.383826855432796, Accuracy: 0.8119833333333333\n",
            "Batch: 190, Loss: 0.38542380042130364, Accuracy: 0.8121833333333334\n",
            "Batch: 200, Loss: 0.384859918404241, Accuracy: 0.81155\n",
            "Batch: 210, Loss: 0.38426971867820886, Accuracy: 0.8115833333333333\n",
            "Batch: 220, Loss: 0.3845533987219167, Accuracy: 0.8117\n",
            "Batch: 230, Loss: 0.38348278921703827, Accuracy: 0.8124833333333333\n",
            "Batch: 240, Loss: 0.38242570173353196, Accuracy: 0.8126833333333333\n",
            "Batch: 250, Loss: 0.38202701524780874, Accuracy: 0.81315\n",
            "Batch: 260, Loss: 0.38179862907255235, Accuracy: 0.8128333333333333\n",
            "Batch: 270, Loss: 0.3803857720505581, Accuracy: 0.8135833333333333\n",
            "Batch: 280, Loss: 0.3804567624437159, Accuracy: 0.8135333333333333\n",
            "Batch: 290, Loss: 0.3798154849232898, Accuracy: 0.8135333333333333\n",
            "Batch: 300, Loss: 0.37882827269724634, Accuracy: 0.8137166666666666\n",
            "Batch: 310, Loss: 0.3782446028107782, Accuracy: 0.8142666666666667\n",
            "Batch: 320, Loss: 0.3780541143246131, Accuracy: 0.8139833333333333\n",
            "Batch: 330, Loss: 0.377809669533823, Accuracy: 0.8142833333333334\n",
            "Batch: 340, Loss: 0.37713005863058846, Accuracy: 0.8147333333333333\n",
            "Batch: 350, Loss: 0.3775526676204196, Accuracy: 0.8145333333333333\n",
            "Batch: 360, Loss: 0.37736467615558894, Accuracy: 0.8148833333333333\n",
            "Batch: 370, Loss: 0.3759706627865966, Accuracy: 0.8154333333333333\n",
            "Batch: 380, Loss: 0.37599698218370126, Accuracy: 0.8157333333333333\n",
            "Batch: 390, Loss: 0.3757898536764001, Accuracy: 0.8162333333333334\n",
            "Batch: 400, Loss: 0.37604002336955705, Accuracy: 0.8152\n",
            "Batch: 410, Loss: 0.3753807393288081, Accuracy: 0.8161666666666667\n",
            "Batch: 420, Loss: 0.37515676000305387, Accuracy: 0.8158833333333333\n",
            "Batch: 430, Loss: 0.3749609074584248, Accuracy: 0.81665\n",
            "Batch: 440, Loss: 0.37403029740678206, Accuracy: 0.8163166666666667\n",
            "Batch: 450, Loss: 0.3741355418767955, Accuracy: 0.8167833333333333\n",
            "Batch: 460, Loss: 0.3735379157428602, Accuracy: 0.81755\n",
            "Batch: 470, Loss: 0.3718421900647025, Accuracy: 0.8175666666666667\n",
            "Batch: 480, Loss: 0.37133091950185104, Accuracy: 0.8177833333333333\n",
            "Batch: 490, Loss: 0.37103379061007463, Accuracy: 0.8179166666666666\n",
            "Batch: 500, Loss: 0.37115934091697383, Accuracy: 0.8177\n",
            "Batch: 510, Loss: 0.36949202578169393, Accuracy: 0.8188666666666666\n",
            "Batch: 520, Loss: 0.368500911514687, Accuracy: 0.81885\n",
            "Batch: 530, Loss: 0.36834645631933094, Accuracy: 0.8191166666666667\n",
            "Batch: 540, Loss: 0.3681563231850388, Accuracy: 0.8192333333333334\n",
            "Batch: 550, Loss: 0.3679041517773538, Accuracy: 0.8197333333333333\n",
            "Batch: 560, Loss: 0.36779293454533013, Accuracy: 0.8199666666666666\n",
            "Batch: 570, Loss: 0.3668048529767475, Accuracy: 0.8197\n",
            "Batch: 580, Loss: 0.3657216747711774, Accuracy: 0.8201166666666667\n",
            "Batch: 590, Loss: 0.3649766509477411, Accuracy: 0.82055\n",
            "Batch: 600, Loss: 0.36462461815074576, Accuracy: 0.8209333333333333\n",
            "Batch: 610, Loss: 0.36400162578115164, Accuracy: 0.8214666666666667\n",
            "Batch: 620, Loss: 0.36467234850792724, Accuracy: 0.8213666666666667\n",
            "Batch: 630, Loss: 0.3641803229172038, Accuracy: 0.8216\n",
            "Batch: 640, Loss: 0.36439375483899533, Accuracy: 0.8213333333333334\n",
            "Batch: 650, Loss: 0.3648839002220016, Accuracy: 0.8210333333333333\n",
            "Batch: 660, Loss: 0.3636782644004872, Accuracy: 0.8216833333333333\n",
            "Batch: 670, Loss: 0.36272710098932126, Accuracy: 0.82185\n",
            "Batch: 680, Loss: 0.3631845650744625, Accuracy: 0.8215333333333333\n",
            "Batch: 690, Loss: 0.36339719716830277, Accuracy: 0.8214833333333333\n",
            "Batch: 700, Loss: 0.36263689572235236, Accuracy: 0.82225\n",
            "Batch: 710, Loss: 0.3630823887330197, Accuracy: 0.8216833333333333\n",
            "Batch: 720, Loss: 0.3627790101984236, Accuracy: 0.8217833333333333\n",
            "Batch: 730, Loss: 0.3618778866752478, Accuracy: 0.8224666666666667\n",
            "Batch: 740, Loss: 0.3619049449095136, Accuracy: 0.8226166666666667\n",
            "Batch: 750, Loss: 0.3621987188296847, Accuracy: 0.8217666666666666\n",
            "Batch: 760, Loss: 0.3600636311361467, Accuracy: 0.8232166666666667\n",
            "Batch: 770, Loss: 0.3599873335628959, Accuracy: 0.8232833333333334\n",
            "Batch: 780, Loss: 0.3605287191676207, Accuracy: 0.8233333333333334\n",
            "Batch: 790, Loss: 0.3591485006968697, Accuracy: 0.8237833333333333\n",
            "Batch: 800, Loss: 0.3593066745452674, Accuracy: 0.8238666666666666\n",
            "Batch: 810, Loss: 0.3584929704510756, Accuracy: 0.8242\n",
            "Batch: 820, Loss: 0.35808506548372604, Accuracy: 0.8242\n",
            "Batch: 830, Loss: 0.3573577767318315, Accuracy: 0.8243833333333334\n",
            "Batch: 840, Loss: 0.35749583139701613, Accuracy: 0.8243333333333334\n",
            "Batch: 850, Loss: 0.35684017929585415, Accuracy: 0.82485\n",
            "Batch: 860, Loss: 0.3557083606927519, Accuracy: 0.82445\n",
            "Batch: 870, Loss: 0.355989152924944, Accuracy: 0.8247333333333333\n",
            "Batch: 880, Loss: 0.35601199957199053, Accuracy: 0.8252833333333334\n",
            "Batch: 890, Loss: 0.3557036201829151, Accuracy: 0.8249666666666666\n",
            "Batch: 900, Loss: 0.35542413957326896, Accuracy: 0.82485\n",
            "Batch: 910, Loss: 0.35442304513203543, Accuracy: 0.8256833333333333\n",
            "Batch: 920, Loss: 0.3547615014638585, Accuracy: 0.8255333333333333\n",
            "Batch: 930, Loss: 0.35553759602741336, Accuracy: 0.8257666666666666\n",
            "Epoch: 4, Loss: 0.35429487987514136, Accuracy: 0.8258666666666666\n",
            "Batch: 0, Loss: 0.35436981435849646, Accuracy: 0.8260833333333333\n",
            "Batch: 10, Loss: 0.3544253726594251, Accuracy: 0.8258333333333333\n",
            "Batch: 20, Loss: 0.3531617402827926, Accuracy: 0.8266\n",
            "Batch: 30, Loss: 0.35275145261689306, Accuracy: 0.8266\n",
            "Batch: 40, Loss: 0.3515001308180645, Accuracy: 0.82725\n",
            "Batch: 50, Loss: 0.3513705460582831, Accuracy: 0.8273166666666667\n",
            "Batch: 60, Loss: 0.35062657823730553, Accuracy: 0.8274666666666667\n",
            "Batch: 70, Loss: 0.35015028651154495, Accuracy: 0.8279333333333333\n",
            "Batch: 80, Loss: 0.35121739109159217, Accuracy: 0.8269833333333333\n",
            "Batch: 90, Loss: 0.35006622743174814, Accuracy: 0.8280333333333333\n",
            "Batch: 100, Loss: 0.3497296281576987, Accuracy: 0.828\n",
            "Batch: 110, Loss: 0.34971814625377184, Accuracy: 0.82765\n",
            "Batch: 120, Loss: 0.3487805844509684, Accuracy: 0.8282\n",
            "Batch: 130, Loss: 0.34914858335111376, Accuracy: 0.8281833333333334\n",
            "Batch: 140, Loss: 0.34904947628018984, Accuracy: 0.8287833333333333\n",
            "Batch: 150, Loss: 0.34795566276614814, Accuracy: 0.8291\n",
            "Batch: 160, Loss: 0.3466241092735759, Accuracy: 0.82945\n",
            "Batch: 170, Loss: 0.3455257238171087, Accuracy: 0.8293\n",
            "Batch: 180, Loss: 0.345352856032417, Accuracy: 0.82965\n",
            "Batch: 190, Loss: 0.34708136291424174, Accuracy: 0.8295833333333333\n",
            "Batch: 200, Loss: 0.34622127781315437, Accuracy: 0.8293666666666667\n",
            "Batch: 210, Loss: 0.345985645971223, Accuracy: 0.8298166666666666\n",
            "Batch: 220, Loss: 0.34589565051502374, Accuracy: 0.8302333333333334\n",
            "Batch: 230, Loss: 0.3448765048592499, Accuracy: 0.83065\n",
            "Batch: 240, Loss: 0.3441993516787775, Accuracy: 0.8302333333333334\n",
            "Batch: 250, Loss: 0.34349957277414256, Accuracy: 0.83055\n",
            "Batch: 260, Loss: 0.3443644256353379, Accuracy: 0.8302166666666667\n",
            "Batch: 270, Loss: 0.34297234406662686, Accuracy: 0.8309333333333333\n",
            "Batch: 280, Loss: 0.3426809232090457, Accuracy: 0.8315333333333333\n",
            "Batch: 290, Loss: 0.3424015260596458, Accuracy: 0.83155\n",
            "Batch: 300, Loss: 0.34160827409453226, Accuracy: 0.8315166666666667\n",
            "Batch: 310, Loss: 0.34098782287658536, Accuracy: 0.832\n",
            "Batch: 320, Loss: 0.34099540402846684, Accuracy: 0.83185\n",
            "Batch: 330, Loss: 0.3411326131002511, Accuracy: 0.8314833333333334\n",
            "Batch: 340, Loss: 0.3407928787707525, Accuracy: 0.8316\n",
            "Batch: 350, Loss: 0.3410772821693353, Accuracy: 0.8319833333333333\n",
            "Batch: 360, Loss: 0.34079042196346415, Accuracy: 0.8317\n",
            "Batch: 370, Loss: 0.34064775487091714, Accuracy: 0.8318666666666666\n",
            "Batch: 380, Loss: 0.3406739487813355, Accuracy: 0.8318166666666666\n",
            "Batch: 390, Loss: 0.3398402341704167, Accuracy: 0.8322166666666667\n",
            "Batch: 400, Loss: 0.340055980203092, Accuracy: 0.83235\n",
            "Batch: 410, Loss: 0.33955887721429123, Accuracy: 0.8321833333333334\n",
            "Batch: 420, Loss: 0.33916250035557793, Accuracy: 0.8322333333333334\n",
            "Batch: 430, Loss: 0.3393114102709641, Accuracy: 0.8327166666666667\n",
            "Batch: 440, Loss: 0.3385226596325763, Accuracy: 0.8329833333333333\n",
            "Batch: 450, Loss: 0.3388007320591177, Accuracy: 0.8332\n",
            "Batch: 460, Loss: 0.3378835176290996, Accuracy: 0.8331833333333334\n",
            "Batch: 470, Loss: 0.3367523623000356, Accuracy: 0.83355\n",
            "Batch: 480, Loss: 0.3367911479360683, Accuracy: 0.8339666666666666\n",
            "Batch: 490, Loss: 0.33666315135562364, Accuracy: 0.83395\n",
            "Batch: 500, Loss: 0.3363372317756002, Accuracy: 0.83415\n",
            "Batch: 510, Loss: 0.33550270694731615, Accuracy: 0.8341666666666666\n",
            "Batch: 520, Loss: 0.33503129833251766, Accuracy: 0.8348166666666667\n",
            "Batch: 530, Loss: 0.33504791781903687, Accuracy: 0.8342\n",
            "Batch: 540, Loss: 0.33471488898446483, Accuracy: 0.8349333333333333\n",
            "Batch: 550, Loss: 0.33502578039121, Accuracy: 0.8346333333333333\n",
            "Batch: 560, Loss: 0.3351704578244168, Accuracy: 0.8345333333333333\n",
            "Batch: 570, Loss: 0.33402110537102025, Accuracy: 0.8351166666666666\n",
            "Batch: 580, Loss: 0.3332842961361342, Accuracy: 0.8361166666666666\n",
            "Batch: 590, Loss: 0.33282857936346816, Accuracy: 0.8355666666666667\n",
            "Batch: 600, Loss: 0.3322201007046183, Accuracy: 0.8360666666666666\n",
            "Batch: 610, Loss: 0.33217891247262604, Accuracy: 0.83625\n",
            "Batch: 620, Loss: 0.3317079688356523, Accuracy: 0.8361833333333333\n",
            "Batch: 630, Loss: 0.33267863674184084, Accuracy: 0.8359333333333333\n",
            "Batch: 640, Loss: 0.33360201355906444, Accuracy: 0.8359\n",
            "Batch: 650, Loss: 0.33364340013370847, Accuracy: 0.8359166666666666\n",
            "Batch: 660, Loss: 0.3322039976904628, Accuracy: 0.83625\n",
            "Batch: 670, Loss: 0.331764233623787, Accuracy: 0.8363333333333334\n",
            "Batch: 680, Loss: 0.33195429534144033, Accuracy: 0.8366166666666667\n",
            "Batch: 690, Loss: 0.3323817153117078, Accuracy: 0.8363\n",
            "Batch: 700, Loss: 0.33198727883404977, Accuracy: 0.83665\n",
            "Batch: 710, Loss: 0.332076134226964, Accuracy: 0.83625\n",
            "Batch: 720, Loss: 0.3314278182468488, Accuracy: 0.8364833333333334\n",
            "Batch: 730, Loss: 0.33097135099131325, Accuracy: 0.8365\n",
            "Batch: 740, Loss: 0.3308926197875336, Accuracy: 0.8371\n",
            "Batch: 750, Loss: 0.33118488738096286, Accuracy: 0.8366\n",
            "Batch: 760, Loss: 0.32893091589165485, Accuracy: 0.8371833333333333\n",
            "Batch: 770, Loss: 0.3297215970961408, Accuracy: 0.8374\n",
            "Batch: 780, Loss: 0.3298385394282532, Accuracy: 0.83695\n",
            "Batch: 790, Loss: 0.328837113391986, Accuracy: 0.8373166666666667\n",
            "Batch: 800, Loss: 0.3290482286853627, Accuracy: 0.83725\n",
            "Batch: 810, Loss: 0.32842221740408906, Accuracy: 0.8377333333333333\n",
            "Batch: 820, Loss: 0.3284382764653319, Accuracy: 0.83765\n",
            "Batch: 830, Loss: 0.3271605469270776, Accuracy: 0.83875\n",
            "Batch: 840, Loss: 0.3276601082519315, Accuracy: 0.8380166666666666\n",
            "Batch: 850, Loss: 0.3268262977613327, Accuracy: 0.8385333333333334\n",
            "Batch: 860, Loss: 0.32681786991275136, Accuracy: 0.8386666666666667\n",
            "Batch: 870, Loss: 0.3266303871558162, Accuracy: 0.83895\n",
            "Batch: 880, Loss: 0.32652703884534273, Accuracy: 0.8386833333333333\n",
            "Batch: 890, Loss: 0.32682882470933355, Accuracy: 0.83875\n",
            "Batch: 900, Loss: 0.3272144791197654, Accuracy: 0.8386166666666667\n",
            "Batch: 910, Loss: 0.3256808393199706, Accuracy: 0.83905\n",
            "Batch: 920, Loss: 0.325931056866312, Accuracy: 0.8389166666666666\n",
            "Batch: 930, Loss: 0.32650645365613484, Accuracy: 0.8388166666666667\n",
            "Epoch: 5, Loss: 0.32540721352306756, Accuracy: 0.8392666666666667\n",
            "Batch: 0, Loss: 0.3253681918942729, Accuracy: 0.8390333333333333\n",
            "Batch: 10, Loss: 0.3257395336010049, Accuracy: 0.839\n",
            "Batch: 20, Loss: 0.3241628346331684, Accuracy: 0.8394\n",
            "Batch: 30, Loss: 0.3237395818888765, Accuracy: 0.8396166666666667\n",
            "Batch: 40, Loss: 0.3235633195197514, Accuracy: 0.8397666666666667\n",
            "Batch: 50, Loss: 0.32334830540038323, Accuracy: 0.8403166666666667\n",
            "Batch: 60, Loss: 0.3226459155170443, Accuracy: 0.8406333333333333\n",
            "Batch: 70, Loss: 0.3225871947583334, Accuracy: 0.8404833333333334\n",
            "Batch: 80, Loss: 0.32398797826678255, Accuracy: 0.8404833333333334\n",
            "Batch: 90, Loss: 0.32291506745595955, Accuracy: 0.8401166666666666\n",
            "Batch: 100, Loss: 0.322900099379605, Accuracy: 0.84045\n",
            "Batch: 110, Loss: 0.3233885692155018, Accuracy: 0.84045\n",
            "Batch: 120, Loss: 0.3218955201510471, Accuracy: 0.8404333333333334\n",
            "Batch: 130, Loss: 0.3228240673775218, Accuracy: 0.8402333333333334\n",
            "Batch: 140, Loss: 0.3229141910398558, Accuracy: 0.8403666666666667\n",
            "Batch: 150, Loss: 0.32208346669170956, Accuracy: 0.8408833333333333\n",
            "Batch: 160, Loss: 0.32040857056355887, Accuracy: 0.8411166666666666\n",
            "Batch: 170, Loss: 0.3198367335287783, Accuracy: 0.8417666666666667\n",
            "Batch: 180, Loss: 0.31995761638479686, Accuracy: 0.8416\n",
            "Batch: 190, Loss: 0.3211121962367971, Accuracy: 0.84075\n",
            "Batch: 200, Loss: 0.32001738212929026, Accuracy: 0.8411666666666666\n",
            "Batch: 210, Loss: 0.3193767115774138, Accuracy: 0.84175\n",
            "Batch: 220, Loss: 0.31923780520202794, Accuracy: 0.8415666666666667\n",
            "Batch: 230, Loss: 0.3183816566137794, Accuracy: 0.8424666666666667\n",
            "Batch: 240, Loss: 0.3179685911314428, Accuracy: 0.8430166666666666\n",
            "Batch: 250, Loss: 0.3173744730913183, Accuracy: 0.8433333333333334\n",
            "Batch: 260, Loss: 0.31736758602914933, Accuracy: 0.8426166666666667\n",
            "Batch: 270, Loss: 0.316562251156634, Accuracy: 0.8431\n",
            "Batch: 280, Loss: 0.3165560650608269, Accuracy: 0.8432166666666666\n",
            "Batch: 290, Loss: 0.31649531084643884, Accuracy: 0.84375\n",
            "Batch: 300, Loss: 0.3161987467499723, Accuracy: 0.8437833333333333\n",
            "Batch: 310, Loss: 0.31523627602511034, Accuracy: 0.8443\n",
            "Batch: 320, Loss: 0.3157550473292321, Accuracy: 0.8441\n",
            "Batch: 330, Loss: 0.3155003672893586, Accuracy: 0.8436333333333333\n",
            "Batch: 340, Loss: 0.31543437186636003, Accuracy: 0.8436333333333333\n",
            "Batch: 350, Loss: 0.3160286064579318, Accuracy: 0.84385\n",
            "Batch: 360, Loss: 0.31547873911558755, Accuracy: 0.8435\n",
            "Batch: 370, Loss: 0.31513416627741814, Accuracy: 0.8434666666666667\n",
            "Batch: 380, Loss: 0.31497492148060074, Accuracy: 0.84365\n",
            "Batch: 390, Loss: 0.3145840704878341, Accuracy: 0.8441\n",
            "Batch: 400, Loss: 0.3154239608101538, Accuracy: 0.8437166666666667\n",
            "Batch: 410, Loss: 0.3146900818869272, Accuracy: 0.8439166666666666\n",
            "Batch: 420, Loss: 0.3142672978503102, Accuracy: 0.84435\n",
            "Batch: 430, Loss: 0.3140404372669966, Accuracy: 0.8442\n",
            "Batch: 440, Loss: 0.31332296872663057, Accuracy: 0.8445333333333334\n",
            "Batch: 450, Loss: 0.3132936011470805, Accuracy: 0.84465\n",
            "Batch: 460, Loss: 0.3127350836048801, Accuracy: 0.8447333333333333\n",
            "Batch: 470, Loss: 0.3119252240752752, Accuracy: 0.84495\n",
            "Batch: 480, Loss: 0.3120995237051902, Accuracy: 0.8448666666666667\n",
            "Batch: 490, Loss: 0.3116964798359139, Accuracy: 0.84485\n",
            "Batch: 500, Loss: 0.31164485615521514, Accuracy: 0.8453166666666667\n",
            "Batch: 510, Loss: 0.31085292138496684, Accuracy: 0.84575\n",
            "Batch: 520, Loss: 0.3106291588753828, Accuracy: 0.8456666666666667\n",
            "Batch: 530, Loss: 0.3104419158250603, Accuracy: 0.84575\n",
            "Batch: 540, Loss: 0.3105508709311688, Accuracy: 0.8457333333333333\n",
            "Batch: 550, Loss: 0.3105040994918194, Accuracy: 0.8457333333333333\n",
            "Batch: 560, Loss: 0.31041773341972195, Accuracy: 0.8462166666666666\n",
            "Batch: 570, Loss: 0.30982647794852425, Accuracy: 0.8467333333333333\n",
            "Batch: 580, Loss: 0.30996326371536453, Accuracy: 0.8465833333333334\n",
            "Batch: 590, Loss: 0.3093673021170397, Accuracy: 0.8469333333333333\n",
            "Batch: 600, Loss: 0.3087555023578191, Accuracy: 0.84755\n",
            "Batch: 610, Loss: 0.3088589402747731, Accuracy: 0.8472833333333334\n",
            "Batch: 620, Loss: 0.3086448665519034, Accuracy: 0.8471666666666666\n",
            "Batch: 630, Loss: 0.30953383259755574, Accuracy: 0.8469166666666667\n",
            "Batch: 640, Loss: 0.31035309710352604, Accuracy: 0.8461166666666666\n",
            "Batch: 650, Loss: 0.3104681955165876, Accuracy: 0.8463166666666667\n",
            "Batch: 660, Loss: 0.3090167356486587, Accuracy: 0.8470166666666666\n",
            "Batch: 670, Loss: 0.3085955892813435, Accuracy: 0.8474333333333334\n",
            "Batch: 680, Loss: 0.3089403538786399, Accuracy: 0.8467833333333333\n",
            "Batch: 690, Loss: 0.30923768895823306, Accuracy: 0.8464\n",
            "Batch: 700, Loss: 0.30945148192464556, Accuracy: 0.8469\n",
            "Batch: 710, Loss: 0.3095767526880427, Accuracy: 0.8465666666666667\n",
            "Batch: 720, Loss: 0.30851839621816546, Accuracy: 0.84715\n",
            "Batch: 730, Loss: 0.3083846900498677, Accuracy: 0.84715\n",
            "Batch: 740, Loss: 0.30865989522413534, Accuracy: 0.8469333333333333\n",
            "Batch: 750, Loss: 0.30921378847505565, Accuracy: 0.84685\n",
            "Batch: 760, Loss: 0.30710470811414875, Accuracy: 0.8476666666666667\n",
            "Batch: 770, Loss: 0.3078545341730163, Accuracy: 0.84725\n",
            "Batch: 780, Loss: 0.3079911367949635, Accuracy: 0.8471833333333333\n",
            "Batch: 790, Loss: 0.3072229897008005, Accuracy: 0.84755\n",
            "Batch: 800, Loss: 0.307073045493903, Accuracy: 0.8475666666666667\n",
            "Batch: 810, Loss: 0.30688605622244247, Accuracy: 0.848\n",
            "Batch: 820, Loss: 0.3072160984755766, Accuracy: 0.8475333333333334\n",
            "Batch: 830, Loss: 0.3058261731985465, Accuracy: 0.8481333333333333\n",
            "Batch: 840, Loss: 0.3063398329473116, Accuracy: 0.8478333333333333\n",
            "Batch: 850, Loss: 0.3055754795904096, Accuracy: 0.8482833333333333\n",
            "Batch: 860, Loss: 0.3058801651550175, Accuracy: 0.8483833333333334\n",
            "Batch: 870, Loss: 0.3052101758852092, Accuracy: 0.8486666666666667\n",
            "Batch: 880, Loss: 0.3048299452329801, Accuracy: 0.8488166666666667\n",
            "Batch: 890, Loss: 0.3053855073450756, Accuracy: 0.84845\n",
            "Batch: 900, Loss: 0.3056506872634518, Accuracy: 0.8483833333333334\n",
            "Batch: 910, Loss: 0.30444836559248, Accuracy: 0.8488166666666667\n",
            "Batch: 920, Loss: 0.30497525975672823, Accuracy: 0.8488\n",
            "Batch: 930, Loss: 0.3049364210412462, Accuracy: 0.8487166666666667\n",
            "Epoch: 6, Loss: 0.3040134676733735, Accuracy: 0.8488333333333333\n",
            "Batch: 0, Loss: 0.30403497978067995, Accuracy: 0.84875\n",
            "Batch: 10, Loss: 0.3043482237052092, Accuracy: 0.8484\n",
            "Batch: 20, Loss: 0.3024519977410462, Accuracy: 0.8494\n",
            "Batch: 30, Loss: 0.3023585034575281, Accuracy: 0.84935\n",
            "Batch: 40, Loss: 0.3018340837038066, Accuracy: 0.84995\n",
            "Batch: 50, Loss: 0.3021667434514054, Accuracy: 0.8498\n",
            "Batch: 60, Loss: 0.3016457005285783, Accuracy: 0.8498333333333333\n",
            "Batch: 70, Loss: 0.30130497729004174, Accuracy: 0.8503\n",
            "Batch: 80, Loss: 0.3025955535697216, Accuracy: 0.8497\n",
            "Batch: 90, Loss: 0.3012126983468725, Accuracy: 0.8501166666666666\n",
            "Batch: 100, Loss: 0.301475036134006, Accuracy: 0.85005\n",
            "Batch: 110, Loss: 0.30200874329540095, Accuracy: 0.8495\n",
            "Batch: 120, Loss: 0.30062497917956676, Accuracy: 0.85025\n",
            "Batch: 130, Loss: 0.30221685457287184, Accuracy: 0.8499833333333333\n",
            "Batch: 140, Loss: 0.3020307246581731, Accuracy: 0.8494666666666667\n",
            "Batch: 150, Loss: 0.30121538883131116, Accuracy: 0.8500833333333333\n",
            "Batch: 160, Loss: 0.2998395495027232, Accuracy: 0.8505833333333334\n",
            "Batch: 170, Loss: 0.29955393081914483, Accuracy: 0.8510833333333333\n",
            "Batch: 180, Loss: 0.2993894747300929, Accuracy: 0.8513\n",
            "Batch: 190, Loss: 0.3000094974653626, Accuracy: 0.8504333333333334\n",
            "Batch: 200, Loss: 0.2998101965996134, Accuracy: 0.8508333333333333\n",
            "Batch: 210, Loss: 0.2992537165561523, Accuracy: 0.8513833333333334\n",
            "Batch: 220, Loss: 0.29887951327645673, Accuracy: 0.8512666666666666\n",
            "Batch: 230, Loss: 0.2979848364960795, Accuracy: 0.8519666666666666\n",
            "Batch: 240, Loss: 0.29793437354914715, Accuracy: 0.8523666666666667\n",
            "Batch: 250, Loss: 0.29776384872662204, Accuracy: 0.8524833333333334\n",
            "Batch: 260, Loss: 0.29749900417561775, Accuracy: 0.8526\n",
            "Batch: 270, Loss: 0.2968659817762231, Accuracy: 0.8526166666666667\n",
            "Batch: 280, Loss: 0.29690116109032294, Accuracy: 0.8534166666666667\n",
            "Batch: 290, Loss: 0.2973457360998738, Accuracy: 0.8533\n",
            "Batch: 300, Loss: 0.2973261671727984, Accuracy: 0.853\n",
            "Batch: 310, Loss: 0.2963638654567959, Accuracy: 0.8533\n",
            "Batch: 320, Loss: 0.29705725609992745, Accuracy: 0.8530166666666666\n",
            "Batch: 330, Loss: 0.2968074603578745, Accuracy: 0.8533333333333334\n",
            "Batch: 340, Loss: 0.29651771500163016, Accuracy: 0.8529666666666667\n",
            "Batch: 350, Loss: 0.2970064169185288, Accuracy: 0.8524166666666667\n",
            "Batch: 360, Loss: 0.2967194652323463, Accuracy: 0.8526666666666667\n",
            "Batch: 370, Loss: 0.29618956911494077, Accuracy: 0.85305\n",
            "Batch: 380, Loss: 0.2959737727558511, Accuracy: 0.8531333333333333\n",
            "Batch: 390, Loss: 0.29575352420298695, Accuracy: 0.8529\n",
            "Batch: 400, Loss: 0.2963040521819042, Accuracy: 0.85245\n",
            "Batch: 410, Loss: 0.29571145730340753, Accuracy: 0.85315\n",
            "Batch: 420, Loss: 0.2953969980121296, Accuracy: 0.8530333333333333\n",
            "Batch: 430, Loss: 0.29540167784226457, Accuracy: 0.8535333333333334\n",
            "Batch: 440, Loss: 0.2948900468362153, Accuracy: 0.85355\n",
            "Batch: 450, Loss: 0.2947684142099686, Accuracy: 0.8534333333333334\n",
            "Batch: 460, Loss: 0.2939936397273527, Accuracy: 0.8537\n",
            "Batch: 470, Loss: 0.29327965976906134, Accuracy: 0.8544666666666667\n",
            "Batch: 480, Loss: 0.2933983626446722, Accuracy: 0.8542833333333333\n",
            "Batch: 490, Loss: 0.2929491599007186, Accuracy: 0.8548166666666667\n",
            "Batch: 500, Loss: 0.293259782708517, Accuracy: 0.85455\n",
            "Batch: 510, Loss: 0.2926184637650293, Accuracy: 0.8544666666666667\n",
            "Batch: 520, Loss: 0.29257651200036455, Accuracy: 0.8542666666666666\n",
            "Batch: 530, Loss: 0.29221884287122685, Accuracy: 0.8549833333333333\n",
            "Batch: 540, Loss: 0.2926909047136279, Accuracy: 0.8547333333333333\n",
            "Batch: 550, Loss: 0.2927873041093166, Accuracy: 0.8543666666666667\n",
            "Batch: 560, Loss: 0.29310391819376014, Accuracy: 0.8547333333333333\n",
            "Batch: 570, Loss: 0.2927896960490419, Accuracy: 0.8549166666666667\n",
            "Batch: 580, Loss: 0.2926364176383108, Accuracy: 0.8550166666666666\n",
            "Batch: 590, Loss: 0.29200856982966766, Accuracy: 0.8551666666666666\n",
            "Batch: 600, Loss: 0.2913595373671571, Accuracy: 0.8553\n",
            "Batch: 610, Loss: 0.2913158897697961, Accuracy: 0.8552166666666666\n",
            "Batch: 620, Loss: 0.291041226566562, Accuracy: 0.8550333333333333\n",
            "Batch: 630, Loss: 0.29150737643455293, Accuracy: 0.8549833333333333\n",
            "Batch: 640, Loss: 0.29203835432990766, Accuracy: 0.8544833333333334\n",
            "Batch: 650, Loss: 0.2920403264595696, Accuracy: 0.8547333333333333\n",
            "Batch: 660, Loss: 0.2916922313306955, Accuracy: 0.8551\n",
            "Batch: 670, Loss: 0.29109841423741845, Accuracy: 0.8554\n",
            "Batch: 680, Loss: 0.29121822091501537, Accuracy: 0.855\n",
            "Batch: 690, Loss: 0.29219837017168093, Accuracy: 0.8549833333333333\n",
            "Batch: 700, Loss: 0.2921670648153517, Accuracy: 0.8549333333333333\n",
            "Batch: 710, Loss: 0.2925261940637245, Accuracy: 0.8548333333333333\n",
            "Batch: 720, Loss: 0.29154350832812054, Accuracy: 0.8548666666666667\n",
            "Batch: 730, Loss: 0.29142428730666675, Accuracy: 0.8551833333333333\n",
            "Batch: 740, Loss: 0.291545686329979, Accuracy: 0.8548666666666667\n",
            "Batch: 750, Loss: 0.292109499966435, Accuracy: 0.8545166666666667\n",
            "Batch: 760, Loss: 0.2905506395012276, Accuracy: 0.8553333333333333\n",
            "Batch: 770, Loss: 0.2910829540864586, Accuracy: 0.8549666666666667\n",
            "Batch: 780, Loss: 0.2910590044806634, Accuracy: 0.8548166666666667\n",
            "Batch: 790, Loss: 0.2904136597454335, Accuracy: 0.85535\n",
            "Batch: 800, Loss: 0.2899295564324291, Accuracy: 0.8556333333333334\n",
            "Batch: 810, Loss: 0.2901654086936172, Accuracy: 0.8552666666666666\n",
            "Batch: 820, Loss: 0.29024983321496445, Accuracy: 0.8549666666666667\n",
            "Batch: 830, Loss: 0.2889595675162565, Accuracy: 0.8560666666666666\n",
            "Batch: 840, Loss: 0.28949532579642057, Accuracy: 0.8556333333333334\n",
            "Batch: 850, Loss: 0.28893054478595576, Accuracy: 0.8558333333333333\n",
            "Batch: 860, Loss: 0.28951035413702847, Accuracy: 0.8558333333333333\n",
            "Batch: 870, Loss: 0.28881068559318346, Accuracy: 0.8562833333333333\n",
            "Batch: 880, Loss: 0.2879542328003179, Accuracy: 0.8566333333333334\n",
            "Batch: 890, Loss: 0.28832961992754846, Accuracy: 0.85605\n",
            "Batch: 900, Loss: 0.2885179498848788, Accuracy: 0.8553833333333334\n",
            "Batch: 910, Loss: 0.28743025127711874, Accuracy: 0.8564833333333334\n",
            "Batch: 920, Loss: 0.28800175551987994, Accuracy: 0.85625\n",
            "Batch: 930, Loss: 0.2877683446560906, Accuracy: 0.8560833333333333\n",
            "Epoch: 7, Loss: 0.2873210365278669, Accuracy: 0.8561666666666666\n",
            "Batch: 0, Loss: 0.2873616138219982, Accuracy: 0.8562666666666666\n",
            "Batch: 10, Loss: 0.2876454148802995, Accuracy: 0.8563\n",
            "Batch: 20, Loss: 0.2858265620957115, Accuracy: 0.857\n",
            "Batch: 30, Loss: 0.2859464113860153, Accuracy: 0.8571833333333333\n",
            "Batch: 40, Loss: 0.2853714983937526, Accuracy: 0.8576666666666667\n",
            "Batch: 50, Loss: 0.28535491383035694, Accuracy: 0.8576833333333334\n",
            "Batch: 60, Loss: 0.28496848825278126, Accuracy: 0.8578666666666667\n",
            "Batch: 70, Loss: 0.2846737782916543, Accuracy: 0.8583166666666666\n",
            "Batch: 80, Loss: 0.28600452816956945, Accuracy: 0.8576333333333334\n",
            "Batch: 90, Loss: 0.2848400027538501, Accuracy: 0.8582166666666666\n",
            "Batch: 100, Loss: 0.28513026414720244, Accuracy: 0.8582333333333333\n",
            "Batch: 110, Loss: 0.2858189785950209, Accuracy: 0.8572833333333333\n",
            "Batch: 120, Loss: 0.28443168532926777, Accuracy: 0.8583\n",
            "Batch: 130, Loss: 0.2863138204211748, Accuracy: 0.8574\n",
            "Batch: 140, Loss: 0.28607021496241575, Accuracy: 0.8574833333333334\n",
            "Batch: 150, Loss: 0.28523199789315395, Accuracy: 0.8579666666666667\n",
            "Batch: 160, Loss: 0.2840169792130833, Accuracy: 0.8583166666666666\n",
            "Batch: 170, Loss: 0.28376860653412733, Accuracy: 0.85835\n",
            "Batch: 180, Loss: 0.28369487231423557, Accuracy: 0.85875\n",
            "Batch: 190, Loss: 0.28405487454319645, Accuracy: 0.85815\n",
            "Batch: 200, Loss: 0.28413661398315554, Accuracy: 0.8574166666666667\n",
            "Batch: 210, Loss: 0.28371779978100803, Accuracy: 0.85815\n",
            "Batch: 220, Loss: 0.2837722406270011, Accuracy: 0.8580666666666666\n",
            "Batch: 230, Loss: 0.2822698325409313, Accuracy: 0.8593333333333333\n",
            "Batch: 240, Loss: 0.28239840589020904, Accuracy: 0.8591\n",
            "Batch: 250, Loss: 0.282349644634434, Accuracy: 0.8591\n",
            "Batch: 260, Loss: 0.2819621500643602, Accuracy: 0.8590666666666666\n",
            "Batch: 270, Loss: 0.2814186551542744, Accuracy: 0.8600666666666666\n",
            "Batch: 280, Loss: 0.28138532336359373, Accuracy: 0.85955\n",
            "Batch: 290, Loss: 0.2819251730845463, Accuracy: 0.8598333333333333\n",
            "Batch: 300, Loss: 0.2818971952942472, Accuracy: 0.85985\n",
            "Batch: 310, Loss: 0.28110826719472226, Accuracy: 0.8601833333333333\n",
            "Batch: 320, Loss: 0.2814401670118044, Accuracy: 0.8598333333333333\n",
            "Batch: 330, Loss: 0.2813262474947527, Accuracy: 0.8599666666666667\n",
            "Batch: 340, Loss: 0.2811293524438967, Accuracy: 0.8598166666666667\n",
            "Batch: 350, Loss: 0.2816638071293154, Accuracy: 0.8592166666666666\n",
            "Batch: 360, Loss: 0.28169974444968865, Accuracy: 0.8590833333333333\n",
            "Batch: 370, Loss: 0.28106379303817963, Accuracy: 0.85995\n",
            "Batch: 380, Loss: 0.2809386982976324, Accuracy: 0.85975\n",
            "Batch: 390, Loss: 0.2806995546438645, Accuracy: 0.8599833333333333\n",
            "Batch: 400, Loss: 0.28090870276091123, Accuracy: 0.8597166666666667\n",
            "Batch: 410, Loss: 0.28051185181134053, Accuracy: 0.85965\n",
            "Batch: 420, Loss: 0.28012268998478074, Accuracy: 0.8600333333333333\n",
            "Batch: 430, Loss: 0.2800833286913853, Accuracy: 0.8605166666666667\n",
            "Batch: 440, Loss: 0.2797366545486893, Accuracy: 0.86005\n",
            "Batch: 450, Loss: 0.2795117088499226, Accuracy: 0.86015\n",
            "Batch: 460, Loss: 0.2790418807615502, Accuracy: 0.8606833333333334\n",
            "Batch: 470, Loss: 0.27840539359571936, Accuracy: 0.8611\n",
            "Batch: 480, Loss: 0.27886322530121865, Accuracy: 0.8607833333333333\n",
            "Batch: 490, Loss: 0.2784118865870715, Accuracy: 0.8613833333333333\n",
            "Batch: 500, Loss: 0.27888221243865224, Accuracy: 0.8610666666666666\n",
            "Batch: 510, Loss: 0.27808499507043993, Accuracy: 0.86135\n",
            "Batch: 520, Loss: 0.27820784153777567, Accuracy: 0.8611833333333333\n",
            "Batch: 530, Loss: 0.27773989500251145, Accuracy: 0.86145\n",
            "Batch: 540, Loss: 0.2784518509383217, Accuracy: 0.8610833333333333\n",
            "Batch: 550, Loss: 0.2787169673965789, Accuracy: 0.8609833333333333\n",
            "Batch: 560, Loss: 0.27921951590522387, Accuracy: 0.86095\n",
            "Batch: 570, Loss: 0.27896455399458664, Accuracy: 0.8609666666666667\n",
            "Batch: 580, Loss: 0.27851322394050465, Accuracy: 0.8613\n",
            "Batch: 590, Loss: 0.27746593473393666, Accuracy: 0.8613333333333333\n",
            "Batch: 600, Loss: 0.27672977248479214, Accuracy: 0.8618666666666667\n",
            "Batch: 610, Loss: 0.27684771705102135, Accuracy: 0.8618833333333333\n",
            "Batch: 620, Loss: 0.27655072326185387, Accuracy: 0.8617666666666667\n",
            "Batch: 630, Loss: 0.276896347358908, Accuracy: 0.8619666666666667\n",
            "Batch: 640, Loss: 0.27734492309406206, Accuracy: 0.8617833333333333\n",
            "Batch: 650, Loss: 0.27727665314300143, Accuracy: 0.8617666666666667\n",
            "Batch: 660, Loss: 0.277545721959727, Accuracy: 0.8618333333333333\n",
            "Batch: 670, Loss: 0.27671854011607955, Accuracy: 0.8616833333333334\n",
            "Batch: 680, Loss: 0.27650341755192515, Accuracy: 0.8617666666666667\n",
            "Batch: 690, Loss: 0.27734698166245286, Accuracy: 0.8614833333333334\n",
            "Batch: 700, Loss: 0.27720206221586263, Accuracy: 0.8615833333333334\n",
            "Batch: 710, Loss: 0.2778134510055119, Accuracy: 0.8614166666666667\n",
            "Batch: 720, Loss: 0.2770052394472035, Accuracy: 0.8619166666666667\n",
            "Batch: 730, Loss: 0.2769226722459661, Accuracy: 0.8619833333333333\n",
            "Batch: 740, Loss: 0.277275768243555, Accuracy: 0.862\n",
            "Batch: 750, Loss: 0.27793312106549545, Accuracy: 0.8608166666666667\n",
            "Batch: 760, Loss: 0.2766129616382856, Accuracy: 0.8618333333333333\n",
            "Batch: 770, Loss: 0.27675523773602545, Accuracy: 0.8615166666666667\n",
            "Batch: 780, Loss: 0.276822899705997, Accuracy: 0.8613166666666666\n",
            "Batch: 790, Loss: 0.27622962898523606, Accuracy: 0.8617833333333333\n",
            "Batch: 800, Loss: 0.27572191977920796, Accuracy: 0.86195\n",
            "Batch: 810, Loss: 0.27579418978368775, Accuracy: 0.8619833333333333\n",
            "Batch: 820, Loss: 0.27590152057135575, Accuracy: 0.8617\n",
            "Batch: 830, Loss: 0.2750510606917878, Accuracy: 0.8624333333333334\n",
            "Batch: 840, Loss: 0.27542319796219733, Accuracy: 0.8620166666666667\n",
            "Batch: 850, Loss: 0.2750418119605078, Accuracy: 0.8621833333333333\n",
            "Batch: 860, Loss: 0.27582914185800456, Accuracy: 0.8620166666666667\n",
            "Batch: 870, Loss: 0.27527542947952827, Accuracy: 0.8624833333333334\n",
            "Batch: 880, Loss: 0.2743993549159292, Accuracy: 0.8631\n",
            "Batch: 890, Loss: 0.27459481855456225, Accuracy: 0.8625166666666667\n",
            "Batch: 900, Loss: 0.2746882469998867, Accuracy: 0.8623\n",
            "Batch: 910, Loss: 0.27377389683428754, Accuracy: 0.8626333333333334\n",
            "Batch: 920, Loss: 0.2741113328499329, Accuracy: 0.8624166666666667\n",
            "Batch: 930, Loss: 0.2738009801880093, Accuracy: 0.8626666666666667\n",
            "Epoch: 8, Loss: 0.27367719757902337, Accuracy: 0.8629333333333333\n",
            "Batch: 0, Loss: 0.2737879338576811, Accuracy: 0.8627333333333334\n",
            "Batch: 10, Loss: 0.2740200578881847, Accuracy: 0.8626666666666667\n",
            "Batch: 20, Loss: 0.2724318951731798, Accuracy: 0.86375\n",
            "Batch: 30, Loss: 0.272729974871847, Accuracy: 0.86365\n",
            "Batch: 40, Loss: 0.27173281867798876, Accuracy: 0.8645\n",
            "Batch: 50, Loss: 0.27200675884607367, Accuracy: 0.8641833333333333\n",
            "Batch: 60, Loss: 0.2717053842117645, Accuracy: 0.8645333333333334\n",
            "Batch: 70, Loss: 0.271407769956824, Accuracy: 0.8646666666666667\n",
            "Batch: 80, Loss: 0.27231359039956793, Accuracy: 0.8641666666666666\n",
            "Batch: 90, Loss: 0.27142095664261945, Accuracy: 0.8647666666666667\n",
            "Batch: 100, Loss: 0.27187898152118517, Accuracy: 0.8646166666666667\n",
            "Batch: 110, Loss: 0.2725365708493314, Accuracy: 0.8643\n",
            "Batch: 120, Loss: 0.2713527221093006, Accuracy: 0.86485\n",
            "Batch: 130, Loss: 0.27293012478379997, Accuracy: 0.8639333333333333\n",
            "Batch: 140, Loss: 0.27307567712754915, Accuracy: 0.8637\n",
            "Batch: 150, Loss: 0.2720236964279084, Accuracy: 0.8643166666666666\n",
            "Batch: 160, Loss: 0.2713211694929245, Accuracy: 0.8643833333333333\n",
            "Batch: 170, Loss: 0.2710472689056715, Accuracy: 0.8647666666666667\n",
            "Batch: 180, Loss: 0.27118283285774625, Accuracy: 0.8648833333333333\n",
            "Batch: 190, Loss: 0.2717235762452743, Accuracy: 0.8642\n",
            "Batch: 200, Loss: 0.27150610041167395, Accuracy: 0.8640666666666666\n",
            "Batch: 210, Loss: 0.271442495782527, Accuracy: 0.8639\n",
            "Batch: 220, Loss: 0.27132240308559946, Accuracy: 0.8642666666666666\n",
            "Batch: 230, Loss: 0.26951664821216886, Accuracy: 0.8651666666666666\n",
            "Batch: 240, Loss: 0.269697596184485, Accuracy: 0.8648666666666667\n",
            "Batch: 250, Loss: 0.2696150779785053, Accuracy: 0.8649833333333333\n",
            "Batch: 260, Loss: 0.26934591759373727, Accuracy: 0.8650833333333333\n",
            "Batch: 270, Loss: 0.2686470574033464, Accuracy: 0.86585\n",
            "Batch: 280, Loss: 0.2685863804792466, Accuracy: 0.8656666666666667\n",
            "Batch: 290, Loss: 0.2687308642069308, Accuracy: 0.8652666666666666\n",
            "Batch: 300, Loss: 0.26868506145255894, Accuracy: 0.8656\n",
            "Batch: 310, Loss: 0.2679848554932583, Accuracy: 0.8657833333333333\n",
            "Batch: 320, Loss: 0.2680879040364603, Accuracy: 0.8657166666666667\n",
            "Batch: 330, Loss: 0.26826053752930745, Accuracy: 0.8652666666666666\n",
            "Batch: 340, Loss: 0.2678745350908749, Accuracy: 0.8659\n",
            "Batch: 350, Loss: 0.26834998193515536, Accuracy: 0.8653833333333333\n",
            "Batch: 360, Loss: 0.26857533685851154, Accuracy: 0.8651166666666666\n",
            "Batch: 370, Loss: 0.26797387401829453, Accuracy: 0.8654333333333334\n",
            "Batch: 380, Loss: 0.2679679936705606, Accuracy: 0.8655166666666667\n",
            "Batch: 390, Loss: 0.2678209847381809, Accuracy: 0.86575\n",
            "Batch: 400, Loss: 0.2679851206913585, Accuracy: 0.8655166666666667\n",
            "Batch: 410, Loss: 0.2677656260979781, Accuracy: 0.8659166666666667\n",
            "Batch: 420, Loss: 0.26722196355706707, Accuracy: 0.8658333333333333\n",
            "Batch: 430, Loss: 0.26731967935072787, Accuracy: 0.8660666666666667\n",
            "Batch: 440, Loss: 0.2668396173217867, Accuracy: 0.8663666666666666\n",
            "Batch: 450, Loss: 0.26680287185235985, Accuracy: 0.8660666666666667\n",
            "Batch: 460, Loss: 0.2666489944405039, Accuracy: 0.8662666666666666\n",
            "Batch: 470, Loss: 0.2663017292124616, Accuracy: 0.8667\n",
            "Batch: 480, Loss: 0.26635112944188755, Accuracy: 0.8666833333333334\n",
            "Batch: 490, Loss: 0.26608411125938586, Accuracy: 0.86695\n",
            "Batch: 500, Loss: 0.2665298422105643, Accuracy: 0.86665\n",
            "Batch: 510, Loss: 0.26591865123722414, Accuracy: 0.86705\n",
            "Batch: 520, Loss: 0.2658543578508181, Accuracy: 0.8665833333333334\n",
            "Batch: 530, Loss: 0.26544809547794, Accuracy: 0.8668166666666667\n",
            "Batch: 540, Loss: 0.26599854360414343, Accuracy: 0.86645\n",
            "Batch: 550, Loss: 0.26621214789690295, Accuracy: 0.8661833333333333\n",
            "Batch: 560, Loss: 0.26669226917602734, Accuracy: 0.86645\n",
            "Batch: 570, Loss: 0.2668619398960408, Accuracy: 0.8665666666666667\n",
            "Batch: 580, Loss: 0.2660675248743809, Accuracy: 0.86675\n",
            "Batch: 590, Loss: 0.264958013634405, Accuracy: 0.8671666666666666\n",
            "Batch: 600, Loss: 0.26437849833533755, Accuracy: 0.86765\n",
            "Batch: 610, Loss: 0.2644524988088763, Accuracy: 0.86715\n",
            "Batch: 620, Loss: 0.2643393393648988, Accuracy: 0.8676166666666667\n",
            "Batch: 630, Loss: 0.264528294869663, Accuracy: 0.8672833333333333\n",
            "Batch: 640, Loss: 0.2651243981769621, Accuracy: 0.8667666666666667\n",
            "Batch: 650, Loss: 0.2651741832103798, Accuracy: 0.8669166666666667\n",
            "Batch: 660, Loss: 0.26552090962641706, Accuracy: 0.8668833333333333\n",
            "Batch: 670, Loss: 0.26476512826127246, Accuracy: 0.8673833333333333\n",
            "Batch: 680, Loss: 0.2643381598443576, Accuracy: 0.8673666666666666\n",
            "Batch: 690, Loss: 0.26534129029165815, Accuracy: 0.86735\n",
            "Batch: 700, Loss: 0.2655692345597567, Accuracy: 0.86725\n",
            "Batch: 710, Loss: 0.2663959258779784, Accuracy: 0.8666166666666667\n",
            "Batch: 720, Loss: 0.26551312761960466, Accuracy: 0.8670333333333333\n",
            "Batch: 730, Loss: 0.26473292244448093, Accuracy: 0.8671333333333333\n",
            "Batch: 740, Loss: 0.2647776597560294, Accuracy: 0.8673666666666666\n",
            "Batch: 750, Loss: 0.26504554420479126, Accuracy: 0.8667666666666667\n",
            "Batch: 760, Loss: 0.26413216305283493, Accuracy: 0.8671333333333333\n",
            "Batch: 770, Loss: 0.2643009636536063, Accuracy: 0.8668833333333333\n",
            "Batch: 780, Loss: 0.2646004139548139, Accuracy: 0.86675\n",
            "Batch: 790, Loss: 0.2641892644011003, Accuracy: 0.86755\n",
            "Batch: 800, Loss: 0.263915254110513, Accuracy: 0.8674333333333333\n",
            "Batch: 810, Loss: 0.26386626606047514, Accuracy: 0.8676833333333334\n",
            "Batch: 820, Loss: 0.26413871878801104, Accuracy: 0.8671\n",
            "Batch: 830, Loss: 0.26356050075757864, Accuracy: 0.8676666666666667\n",
            "Batch: 840, Loss: 0.2637012580668826, Accuracy: 0.8673333333333333\n",
            "Batch: 850, Loss: 0.263057811013552, Accuracy: 0.8679333333333333\n",
            "Batch: 860, Loss: 0.2639994418950323, Accuracy: 0.8675666666666667\n",
            "Batch: 870, Loss: 0.2633947433982992, Accuracy: 0.868\n",
            "Batch: 880, Loss: 0.26300173594946535, Accuracy: 0.8682666666666666\n",
            "Batch: 890, Loss: 0.26339619201329606, Accuracy: 0.8675833333333334\n",
            "Batch: 900, Loss: 0.26325611755443185, Accuracy: 0.8676833333333334\n",
            "Batch: 910, Loss: 0.26236573414336706, Accuracy: 0.8686333333333334\n",
            "Batch: 920, Loss: 0.2627029403461882, Accuracy: 0.8681\n",
            "Batch: 930, Loss: 0.2625196429053452, Accuracy: 0.8682333333333333\n",
            "Epoch: 9, Loss: 0.2624015102276933, Accuracy: 0.8684333333333333\n",
            "Batch: 0, Loss: 0.26247126043205593, Accuracy: 0.8681833333333333\n",
            "Batch: 10, Loss: 0.2626886518590865, Accuracy: 0.86815\n",
            "Batch: 20, Loss: 0.2612861020580679, Accuracy: 0.8687166666666667\n",
            "Batch: 30, Loss: 0.26156460576692486, Accuracy: 0.8686333333333334\n",
            "Batch: 40, Loss: 0.2606985017405487, Accuracy: 0.8693166666666666\n",
            "Batch: 50, Loss: 0.26088373922298974, Accuracy: 0.8694166666666666\n",
            "Batch: 60, Loss: 0.2607662228155216, Accuracy: 0.8696\n",
            "Batch: 70, Loss: 0.26036006345303286, Accuracy: 0.8697666666666667\n",
            "Batch: 80, Loss: 0.261260607006424, Accuracy: 0.8695666666666667\n",
            "Batch: 90, Loss: 0.26031609248049564, Accuracy: 0.8697166666666667\n",
            "Batch: 100, Loss: 0.26060577639799154, Accuracy: 0.8694666666666667\n",
            "Batch: 110, Loss: 0.26113075230101895, Accuracy: 0.8696833333333334\n",
            "Batch: 120, Loss: 0.26008703725401533, Accuracy: 0.8699\n",
            "Batch: 130, Loss: 0.2614829700280861, Accuracy: 0.86915\n",
            "Batch: 140, Loss: 0.2618540814314463, Accuracy: 0.86875\n",
            "Batch: 150, Loss: 0.26052147117168, Accuracy: 0.86935\n",
            "Batch: 160, Loss: 0.26028589492273424, Accuracy: 0.8698333333333333\n",
            "Batch: 170, Loss: 0.2597104610871287, Accuracy: 0.8699666666666667\n",
            "Batch: 180, Loss: 0.25983786188737923, Accuracy: 0.87005\n",
            "Batch: 190, Loss: 0.26097069257901434, Accuracy: 0.8689833333333333\n",
            "Batch: 200, Loss: 0.2608483921906378, Accuracy: 0.86945\n",
            "Batch: 210, Loss: 0.26094534395009716, Accuracy: 0.8686333333333334\n",
            "Batch: 220, Loss: 0.2606439535250331, Accuracy: 0.8690833333333333\n",
            "Batch: 230, Loss: 0.2587150206147096, Accuracy: 0.8701833333333333\n",
            "Batch: 240, Loss: 0.2589281333458005, Accuracy: 0.8695833333333334\n",
            "Batch: 250, Loss: 0.25873664367506477, Accuracy: 0.8702833333333333\n",
            "Batch: 260, Loss: 0.25863111095108954, Accuracy: 0.8702166666666666\n",
            "Batch: 270, Loss: 0.2578860781271546, Accuracy: 0.8706\n",
            "Batch: 280, Loss: 0.2576175349295364, Accuracy: 0.8706666666666667\n",
            "Batch: 290, Loss: 0.25763141064852735, Accuracy: 0.87045\n",
            "Batch: 300, Loss: 0.25743360759748857, Accuracy: 0.8706666666666667\n",
            "Batch: 310, Loss: 0.25705808248214373, Accuracy: 0.8707166666666667\n",
            "Batch: 320, Loss: 0.25698660450094996, Accuracy: 0.8708\n",
            "Batch: 330, Loss: 0.2572869688522163, Accuracy: 0.8705166666666667\n",
            "Batch: 340, Loss: 0.25702971452316115, Accuracy: 0.8708166666666667\n",
            "Batch: 350, Loss: 0.2574249784037367, Accuracy: 0.8704833333333334\n",
            "Batch: 360, Loss: 0.2576726894765433, Accuracy: 0.87015\n",
            "Batch: 370, Loss: 0.2569043819508379, Accuracy: 0.87055\n",
            "Batch: 380, Loss: 0.2570359636452413, Accuracy: 0.8707333333333334\n",
            "Batch: 390, Loss: 0.25711830659852625, Accuracy: 0.8706333333333334\n",
            "Batch: 400, Loss: 0.25730048106532327, Accuracy: 0.8705166666666667\n",
            "Batch: 410, Loss: 0.2572181564274369, Accuracy: 0.8707666666666667\n",
            "Batch: 420, Loss: 0.2564997245344394, Accuracy: 0.87085\n",
            "Batch: 430, Loss: 0.2566599098356111, Accuracy: 0.8708333333333333\n",
            "Batch: 440, Loss: 0.25641643149499055, Accuracy: 0.8709833333333333\n",
            "Batch: 450, Loss: 0.25628019785636036, Accuracy: 0.87095\n",
            "Batch: 460, Loss: 0.2561598723334752, Accuracy: 0.8712166666666666\n",
            "Batch: 470, Loss: 0.2558456727513684, Accuracy: 0.8714\n",
            "Batch: 480, Loss: 0.25578581581875476, Accuracy: 0.8715166666666667\n",
            "Batch: 490, Loss: 0.25552685314346624, Accuracy: 0.8717333333333334\n",
            "Batch: 500, Loss: 0.2557712008319694, Accuracy: 0.8715333333333334\n",
            "Batch: 510, Loss: 0.25549391095340457, Accuracy: 0.87195\n",
            "Batch: 520, Loss: 0.25521329007031, Accuracy: 0.87185\n",
            "Batch: 530, Loss: 0.25486143771498815, Accuracy: 0.87205\n",
            "Batch: 540, Loss: 0.2551481672422085, Accuracy: 0.8718333333333333\n",
            "Batch: 550, Loss: 0.25561016491916333, Accuracy: 0.87175\n",
            "Batch: 560, Loss: 0.25600352161224565, Accuracy: 0.87165\n",
            "Batch: 570, Loss: 0.25632755901760507, Accuracy: 0.8714\n",
            "Batch: 580, Loss: 0.2553828549108161, Accuracy: 0.87155\n",
            "Batch: 590, Loss: 0.2545213711452762, Accuracy: 0.8720333333333333\n",
            "Batch: 600, Loss: 0.25399826710794593, Accuracy: 0.8725333333333334\n",
            "Batch: 610, Loss: 0.25413402025243176, Accuracy: 0.8724833333333334\n",
            "Batch: 620, Loss: 0.2539641641677695, Accuracy: 0.8725\n",
            "Batch: 630, Loss: 0.25428877919084303, Accuracy: 0.8721333333333333\n",
            "Batch: 640, Loss: 0.2546640878238284, Accuracy: 0.8718166666666667\n",
            "Batch: 650, Loss: 0.2549649405637669, Accuracy: 0.8712833333333333\n",
            "Batch: 660, Loss: 0.25456076599416544, Accuracy: 0.8724333333333333\n",
            "Batch: 670, Loss: 0.2539986250599752, Accuracy: 0.8721833333333333\n",
            "Batch: 680, Loss: 0.25382655981163266, Accuracy: 0.8723\n",
            "Batch: 690, Loss: 0.25481164683330204, Accuracy: 0.8719666666666667\n",
            "Batch: 700, Loss: 0.2550650444595221, Accuracy: 0.8718666666666667\n",
            "Batch: 710, Loss: 0.256037284162956, Accuracy: 0.8716166666666667\n",
            "Batch: 720, Loss: 0.25501370346059965, Accuracy: 0.8719833333333333\n",
            "Batch: 730, Loss: 0.25441557798211695, Accuracy: 0.8721666666666666\n",
            "Batch: 740, Loss: 0.2546200813610331, Accuracy: 0.8719666666666667\n",
            "Batch: 750, Loss: 0.25466276250259934, Accuracy: 0.87135\n",
            "Batch: 760, Loss: 0.25385458293926944, Accuracy: 0.8717833333333334\n",
            "Batch: 770, Loss: 0.253956668337796, Accuracy: 0.8719\n",
            "Batch: 780, Loss: 0.25433022608718536, Accuracy: 0.8716166666666667\n",
            "Batch: 790, Loss: 0.2537587047362209, Accuracy: 0.8716833333333334\n",
            "Batch: 800, Loss: 0.2537664939036532, Accuracy: 0.8722333333333333\n",
            "Batch: 810, Loss: 0.25381581110073514, Accuracy: 0.8724166666666666\n",
            "Batch: 820, Loss: 0.2541163367081572, Accuracy: 0.8720833333333333\n",
            "Batch: 830, Loss: 0.25344476598602067, Accuracy: 0.8721\n",
            "Batch: 840, Loss: 0.2534418594421646, Accuracy: 0.8725\n",
            "Batch: 850, Loss: 0.2529405100811676, Accuracy: 0.8729166666666667\n",
            "Batch: 860, Loss: 0.25390050671302766, Accuracy: 0.8723666666666666\n",
            "Batch: 870, Loss: 0.25335581747105146, Accuracy: 0.8725166666666667\n",
            "Batch: 880, Loss: 0.2532651877751604, Accuracy: 0.87255\n",
            "Batch: 890, Loss: 0.2536997994663619, Accuracy: 0.8723833333333333\n",
            "Batch: 900, Loss: 0.25357909715574906, Accuracy: 0.87225\n",
            "Batch: 910, Loss: 0.2527756545123874, Accuracy: 0.8724333333333333\n",
            "Batch: 920, Loss: 0.2528959559531063, Accuracy: 0.8725166666666667\n",
            "Batch: 930, Loss: 0.25302308829276665, Accuracy: 0.8725\n",
            "Epoch: 10, Loss: 0.25291185193724086, Accuracy: 0.8726166666666667\n",
            "Batch: 0, Loss: 0.2529634480137692, Accuracy: 0.8726333333333334\n",
            "Batch: 10, Loss: 0.2531043211642111, Accuracy: 0.8727333333333334\n",
            "Batch: 20, Loss: 0.2517523918229311, Accuracy: 0.8729833333333333\n",
            "Batch: 30, Loss: 0.25201357686993003, Accuracy: 0.87305\n",
            "Batch: 40, Loss: 0.25118501673984334, Accuracy: 0.8733166666666666\n",
            "Batch: 50, Loss: 0.251555951280516, Accuracy: 0.8732666666666666\n",
            "Batch: 60, Loss: 0.2513048542057023, Accuracy: 0.8734333333333333\n",
            "Batch: 70, Loss: 0.25108674565465927, Accuracy: 0.8737166666666667\n",
            "Batch: 80, Loss: 0.25181554395400124, Accuracy: 0.8735833333333334\n",
            "Batch: 90, Loss: 0.25074376848367724, Accuracy: 0.8740833333333333\n",
            "Batch: 100, Loss: 0.25079576712602764, Accuracy: 0.8741833333333333\n",
            "Batch: 110, Loss: 0.25130738001085867, Accuracy: 0.8739833333333333\n",
            "Batch: 120, Loss: 0.25049568347787454, Accuracy: 0.8739\n",
            "Batch: 130, Loss: 0.2519090365084502, Accuracy: 0.8738166666666667\n",
            "Batch: 140, Loss: 0.2525229640642678, Accuracy: 0.8733\n",
            "Batch: 150, Loss: 0.2510156143560851, Accuracy: 0.8741166666666667\n",
            "Batch: 160, Loss: 0.2510006295927729, Accuracy: 0.8740666666666667\n",
            "Batch: 170, Loss: 0.25051640312590817, Accuracy: 0.8741833333333333\n",
            "Batch: 180, Loss: 0.25050522090559796, Accuracy: 0.8743\n",
            "Batch: 190, Loss: 0.25153839665593514, Accuracy: 0.8735333333333334\n",
            "Batch: 200, Loss: 0.25157758193699903, Accuracy: 0.8735666666666667\n",
            "Batch: 210, Loss: 0.25183323108049505, Accuracy: 0.8731\n",
            "Batch: 220, Loss: 0.25159500544324126, Accuracy: 0.8734333333333333\n",
            "Batch: 230, Loss: 0.24973553164676182, Accuracy: 0.8744\n",
            "Batch: 240, Loss: 0.24980339174305308, Accuracy: 0.8743333333333333\n",
            "Batch: 250, Loss: 0.24942902150260812, Accuracy: 0.8741833333333333\n",
            "Batch: 260, Loss: 0.24929778057878896, Accuracy: 0.87455\n",
            "Batch: 270, Loss: 0.24853505362224323, Accuracy: 0.8751166666666667\n",
            "Batch: 280, Loss: 0.24827010153774653, Accuracy: 0.87525\n",
            "Batch: 290, Loss: 0.248123135996072, Accuracy: 0.8750333333333333\n",
            "Batch: 300, Loss: 0.247935237646704, Accuracy: 0.8751333333333333\n",
            "Batch: 310, Loss: 0.24767226473743592, Accuracy: 0.8751833333333333\n",
            "Batch: 320, Loss: 0.2476360256385058, Accuracy: 0.87545\n",
            "Batch: 330, Loss: 0.24762991666480128, Accuracy: 0.8751166666666667\n",
            "Batch: 340, Loss: 0.24768625511731743, Accuracy: 0.8753333333333333\n",
            "Batch: 350, Loss: 0.248105851833765, Accuracy: 0.8749666666666667\n",
            "Batch: 360, Loss: 0.24804826572625713, Accuracy: 0.8746\n",
            "Batch: 370, Loss: 0.2473171060094736, Accuracy: 0.8752666666666666\n",
            "Batch: 380, Loss: 0.24763178742846628, Accuracy: 0.8748833333333333\n",
            "Batch: 390, Loss: 0.24773480095216688, Accuracy: 0.87505\n",
            "Batch: 400, Loss: 0.2481568698200984, Accuracy: 0.87525\n",
            "Batch: 410, Loss: 0.24802418484561306, Accuracy: 0.8750166666666667\n",
            "Batch: 420, Loss: 0.2475242587010803, Accuracy: 0.87565\n",
            "Batch: 430, Loss: 0.2477576901811277, Accuracy: 0.8756166666666667\n",
            "Batch: 440, Loss: 0.24725918557293836, Accuracy: 0.8759\n",
            "Batch: 450, Loss: 0.24719057508910797, Accuracy: 0.8762\n",
            "Batch: 460, Loss: 0.24711768883222418, Accuracy: 0.8761666666666666\n",
            "Batch: 470, Loss: 0.24667937600850534, Accuracy: 0.87535\n",
            "Batch: 480, Loss: 0.24657102971279135, Accuracy: 0.87575\n",
            "Batch: 490, Loss: 0.24633390078821002, Accuracy: 0.8759333333333333\n",
            "Batch: 500, Loss: 0.2467234524451624, Accuracy: 0.8756\n",
            "Batch: 510, Loss: 0.24660221198412052, Accuracy: 0.8756666666666667\n",
            "Batch: 520, Loss: 0.24642551088064982, Accuracy: 0.8758666666666667\n",
            "Batch: 530, Loss: 0.24595806121776229, Accuracy: 0.8759666666666667\n",
            "Batch: 540, Loss: 0.24615432252017044, Accuracy: 0.8760833333333333\n",
            "Batch: 550, Loss: 0.24666667759815736, Accuracy: 0.8754\n",
            "Batch: 560, Loss: 0.24697374614542728, Accuracy: 0.87535\n",
            "Batch: 570, Loss: 0.24713791830378706, Accuracy: 0.8751833333333333\n",
            "Batch: 580, Loss: 0.24612960208244572, Accuracy: 0.87595\n",
            "Batch: 590, Loss: 0.24542791573430683, Accuracy: 0.8762666666666666\n",
            "Batch: 600, Loss: 0.24497523495713427, Accuracy: 0.87665\n",
            "Batch: 610, Loss: 0.2452555303062682, Accuracy: 0.8763833333333333\n",
            "Batch: 620, Loss: 0.24497932751140572, Accuracy: 0.8764166666666666\n",
            "Batch: 630, Loss: 0.2454266261629622, Accuracy: 0.8765166666666667\n",
            "Batch: 640, Loss: 0.24565603782043197, Accuracy: 0.87645\n",
            "Batch: 650, Loss: 0.24591902109720573, Accuracy: 0.8761\n",
            "Batch: 660, Loss: 0.24542352786591248, Accuracy: 0.8761666666666666\n",
            "Batch: 670, Loss: 0.24507319911823386, Accuracy: 0.87635\n",
            "Batch: 680, Loss: 0.24522898105212326, Accuracy: 0.8765833333333334\n",
            "Batch: 690, Loss: 0.2460758036697493, Accuracy: 0.8760333333333333\n",
            "Batch: 700, Loss: 0.24643427581742003, Accuracy: 0.87575\n",
            "Batch: 710, Loss: 0.247456152716684, Accuracy: 0.87525\n",
            "Batch: 720, Loss: 0.24636175501041438, Accuracy: 0.8760166666666667\n",
            "Batch: 730, Loss: 0.24587939453147906, Accuracy: 0.8763333333333333\n",
            "Batch: 740, Loss: 0.2459270042110834, Accuracy: 0.8760333333333333\n",
            "Batch: 750, Loss: 0.24589642100868406, Accuracy: 0.8758\n",
            "Batch: 760, Loss: 0.24501675137013484, Accuracy: 0.8761666666666666\n",
            "Batch: 770, Loss: 0.245061333886674, Accuracy: 0.8762666666666666\n",
            "Batch: 780, Loss: 0.24535735215406637, Accuracy: 0.876\n",
            "Batch: 790, Loss: 0.2449229342728744, Accuracy: 0.8759166666666667\n",
            "Batch: 800, Loss: 0.2449562734552208, Accuracy: 0.8761333333333333\n",
            "Batch: 810, Loss: 0.24500777284042283, Accuracy: 0.8766\n",
            "Batch: 820, Loss: 0.24533068806309882, Accuracy: 0.8759166666666667\n",
            "Batch: 830, Loss: 0.24464286011079361, Accuracy: 0.8763833333333333\n",
            "Batch: 840, Loss: 0.24456614614099442, Accuracy: 0.8766\n",
            "Batch: 850, Loss: 0.2442520174758504, Accuracy: 0.8767666666666667\n",
            "Batch: 860, Loss: 0.24504670553840882, Accuracy: 0.8761666666666666\n",
            "Batch: 870, Loss: 0.24448186396215277, Accuracy: 0.8765166666666667\n",
            "Batch: 880, Loss: 0.24457699211541892, Accuracy: 0.8763833333333333\n",
            "Batch: 890, Loss: 0.24495693009323197, Accuracy: 0.8764166666666666\n",
            "Batch: 900, Loss: 0.24487460379665602, Accuracy: 0.8762333333333333\n",
            "Batch: 910, Loss: 0.2439171285086356, Accuracy: 0.8766333333333334\n",
            "Batch: 920, Loss: 0.2439274476569573, Accuracy: 0.8766833333333334\n",
            "Batch: 930, Loss: 0.24417905568532416, Accuracy: 0.8766166666666667\n",
            "Epoch: 11, Loss: 0.24408468026266938, Accuracy: 0.8765833333333334\n",
            "Batch: 0, Loss: 0.24415453411534477, Accuracy: 0.8764166666666666\n",
            "Batch: 10, Loss: 0.24454977671646916, Accuracy: 0.8766666666666667\n",
            "Batch: 20, Loss: 0.2434307905487654, Accuracy: 0.87745\n",
            "Batch: 30, Loss: 0.24373808855228063, Accuracy: 0.87725\n",
            "Batch: 40, Loss: 0.24276499784235261, Accuracy: 0.8775\n",
            "Batch: 50, Loss: 0.24327997836020945, Accuracy: 0.8773\n",
            "Batch: 60, Loss: 0.24288778504533037, Accuracy: 0.87755\n",
            "Batch: 70, Loss: 0.24286490983548006, Accuracy: 0.8776166666666667\n",
            "Batch: 80, Loss: 0.24335319180784223, Accuracy: 0.87685\n",
            "Batch: 90, Loss: 0.2422512165532621, Accuracy: 0.8778166666666667\n",
            "Batch: 100, Loss: 0.24221452797649728, Accuracy: 0.8777333333333334\n",
            "Batch: 110, Loss: 0.24271188828325854, Accuracy: 0.8775333333333334\n",
            "Batch: 120, Loss: 0.2419057378458113, Accuracy: 0.8776666666666667\n",
            "Batch: 130, Loss: 0.24326725164632154, Accuracy: 0.8774166666666666\n",
            "Batch: 140, Loss: 0.24384423371722388, Accuracy: 0.8772666666666666\n",
            "Batch: 150, Loss: 0.2424438284369695, Accuracy: 0.8780166666666667\n",
            "Batch: 160, Loss: 0.2425003619610546, Accuracy: 0.8779333333333333\n",
            "Batch: 170, Loss: 0.24190439248665538, Accuracy: 0.87815\n",
            "Batch: 180, Loss: 0.24177920311070417, Accuracy: 0.8780166666666667\n",
            "Batch: 190, Loss: 0.24309187077287298, Accuracy: 0.8776166666666667\n",
            "Batch: 200, Loss: 0.2434468416875038, Accuracy: 0.8768333333333334\n",
            "Batch: 210, Loss: 0.24372315398937386, Accuracy: 0.8773333333333333\n",
            "Batch: 220, Loss: 0.24359416693309152, Accuracy: 0.8773\n",
            "Batch: 230, Loss: 0.24174068296736878, Accuracy: 0.8777666666666667\n",
            "Batch: 240, Loss: 0.24186190787269296, Accuracy: 0.8780333333333333\n",
            "Batch: 250, Loss: 0.2410428526316554, Accuracy: 0.87805\n",
            "Batch: 260, Loss: 0.2409297224128069, Accuracy: 0.87845\n",
            "Batch: 270, Loss: 0.24010085962891708, Accuracy: 0.8786666666666667\n",
            "Batch: 280, Loss: 0.23987922719161636, Accuracy: 0.8787\n",
            "Batch: 290, Loss: 0.23959277551583155, Accuracy: 0.87825\n",
            "Batch: 300, Loss: 0.2394749034322168, Accuracy: 0.8784833333333333\n",
            "Batch: 310, Loss: 0.23926232446639667, Accuracy: 0.87895\n",
            "Batch: 320, Loss: 0.2393009318220512, Accuracy: 0.8788333333333334\n",
            "Batch: 330, Loss: 0.23922589061990204, Accuracy: 0.8789833333333333\n",
            "Batch: 340, Loss: 0.23935913658792124, Accuracy: 0.8790166666666667\n",
            "Batch: 350, Loss: 0.2397518951670092, Accuracy: 0.8787166666666667\n",
            "Batch: 360, Loss: 0.2397629903622658, Accuracy: 0.8782166666666666\n",
            "Batch: 370, Loss: 0.23909006018699674, Accuracy: 0.8784833333333333\n",
            "Batch: 380, Loss: 0.23944516159871282, Accuracy: 0.8782\n",
            "Batch: 390, Loss: 0.23965663534835466, Accuracy: 0.8786666666666667\n",
            "Batch: 400, Loss: 0.24022770659855486, Accuracy: 0.8785833333333334\n",
            "Batch: 410, Loss: 0.2400549358625583, Accuracy: 0.8789166666666667\n",
            "Batch: 420, Loss: 0.23956965449758993, Accuracy: 0.8794833333333333\n",
            "Batch: 430, Loss: 0.23999098448306952, Accuracy: 0.8790666666666667\n",
            "Batch: 440, Loss: 0.23928481422119768, Accuracy: 0.8792833333333333\n",
            "Batch: 450, Loss: 0.2391959503960175, Accuracy: 0.8796\n",
            "Batch: 460, Loss: 0.23925579567555727, Accuracy: 0.8796166666666667\n",
            "Batch: 470, Loss: 0.2385707070789346, Accuracy: 0.8795666666666667\n",
            "Batch: 480, Loss: 0.2383609802920738, Accuracy: 0.8796666666666667\n",
            "Batch: 490, Loss: 0.23817684066085398, Accuracy: 0.87975\n",
            "Batch: 500, Loss: 0.238720300824063, Accuracy: 0.8791833333333333\n",
            "Batch: 510, Loss: 0.23868053465179154, Accuracy: 0.879\n",
            "Batch: 520, Loss: 0.2386061002301001, Accuracy: 0.8796333333333334\n",
            "Batch: 530, Loss: 0.23805566582970822, Accuracy: 0.87945\n",
            "Batch: 540, Loss: 0.238128583440869, Accuracy: 0.87945\n",
            "Batch: 550, Loss: 0.2383871580903302, Accuracy: 0.8794\n",
            "Batch: 560, Loss: 0.2387296877417023, Accuracy: 0.8792333333333333\n",
            "Batch: 570, Loss: 0.23905614286770885, Accuracy: 0.8786166666666667\n",
            "Batch: 580, Loss: 0.23814969789402665, Accuracy: 0.8794166666666666\n",
            "Batch: 590, Loss: 0.23752721232594814, Accuracy: 0.8797333333333334\n",
            "Batch: 600, Loss: 0.23699286487378424, Accuracy: 0.8800166666666667\n",
            "Batch: 610, Loss: 0.23727415813116565, Accuracy: 0.8798\n",
            "Batch: 620, Loss: 0.23702021484049357, Accuracy: 0.8800833333333333\n",
            "Batch: 630, Loss: 0.23739454501212434, Accuracy: 0.8800833333333333\n",
            "Batch: 640, Loss: 0.23757588263119145, Accuracy: 0.8800333333333333\n",
            "Batch: 650, Loss: 0.23761036134389782, Accuracy: 0.8799\n",
            "Batch: 660, Loss: 0.23733697602091916, Accuracy: 0.8799333333333333\n",
            "Batch: 670, Loss: 0.23695860274521155, Accuracy: 0.8801166666666667\n",
            "Batch: 680, Loss: 0.23723386873690339, Accuracy: 0.8799833333333333\n",
            "Batch: 690, Loss: 0.23824164442822765, Accuracy: 0.8795333333333333\n",
            "Batch: 700, Loss: 0.2386447366742127, Accuracy: 0.879\n",
            "Batch: 710, Loss: 0.23980864328862192, Accuracy: 0.8787833333333334\n",
            "Batch: 720, Loss: 0.23873278067992257, Accuracy: 0.8794833333333333\n",
            "Batch: 730, Loss: 0.238206311351566, Accuracy: 0.8797\n",
            "Batch: 740, Loss: 0.2380705682864955, Accuracy: 0.8797166666666667\n",
            "Batch: 750, Loss: 0.23840188417896463, Accuracy: 0.8790166666666667\n",
            "Batch: 760, Loss: 0.2373844999914382, Accuracy: 0.8796166666666667\n",
            "Batch: 770, Loss: 0.23720837969344036, Accuracy: 0.8797666666666667\n",
            "Batch: 780, Loss: 0.2376500147735438, Accuracy: 0.87985\n",
            "Batch: 790, Loss: 0.23734750138417227, Accuracy: 0.8797833333333334\n",
            "Batch: 800, Loss: 0.23726113988891762, Accuracy: 0.8797333333333334\n",
            "Batch: 810, Loss: 0.23749484449272368, Accuracy: 0.8793666666666666\n",
            "Batch: 820, Loss: 0.23791934399190884, Accuracy: 0.8792166666666666\n",
            "Batch: 830, Loss: 0.2370969583306004, Accuracy: 0.8800833333333333\n",
            "Batch: 840, Loss: 0.23703366679456372, Accuracy: 0.8799\n",
            "Batch: 850, Loss: 0.23681827868760913, Accuracy: 0.8802666666666666\n",
            "Batch: 860, Loss: 0.23773794275306606, Accuracy: 0.8795\n",
            "Batch: 870, Loss: 0.23698768997739025, Accuracy: 0.87955\n",
            "Batch: 880, Loss: 0.23709112977300567, Accuracy: 0.8800166666666667\n",
            "Batch: 890, Loss: 0.23734808070110408, Accuracy: 0.8798166666666667\n",
            "Batch: 900, Loss: 0.23724366345615738, Accuracy: 0.8796833333333334\n",
            "Batch: 910, Loss: 0.23628532863697954, Accuracy: 0.8800833333333333\n",
            "Batch: 920, Loss: 0.23639660694114106, Accuracy: 0.88025\n",
            "Batch: 930, Loss: 0.23653862206078677, Accuracy: 0.88035\n",
            "Epoch: 12, Loss: 0.23657349085262638, Accuracy: 0.8804333333333333\n",
            "Batch: 0, Loss: 0.2366096694485155, Accuracy: 0.8802666666666666\n",
            "Batch: 10, Loss: 0.2369502323059567, Accuracy: 0.8799666666666667\n",
            "Batch: 20, Loss: 0.23597011079842525, Accuracy: 0.8809833333333333\n",
            "Batch: 30, Loss: 0.2362666574689224, Accuracy: 0.8804833333333333\n",
            "Batch: 40, Loss: 0.23528976642418828, Accuracy: 0.8810833333333333\n",
            "Batch: 50, Loss: 0.23589992028333573, Accuracy: 0.8808833333333334\n",
            "Batch: 60, Loss: 0.23540727591123678, Accuracy: 0.8809\n",
            "Batch: 70, Loss: 0.2353374761327096, Accuracy: 0.8808833333333334\n",
            "Batch: 80, Loss: 0.23570668393859193, Accuracy: 0.88025\n",
            "Batch: 90, Loss: 0.23467178830671764, Accuracy: 0.881\n",
            "Batch: 100, Loss: 0.23476093284138327, Accuracy: 0.8804833333333333\n",
            "Batch: 110, Loss: 0.23518788496733103, Accuracy: 0.88055\n",
            "Batch: 120, Loss: 0.23432659591068358, Accuracy: 0.8810833333333333\n",
            "Batch: 130, Loss: 0.23550334178754578, Accuracy: 0.8808666666666667\n",
            "Batch: 140, Loss: 0.23609912972348712, Accuracy: 0.8808333333333334\n",
            "Batch: 150, Loss: 0.23478091910011256, Accuracy: 0.8813\n",
            "Batch: 160, Loss: 0.2348602864343955, Accuracy: 0.88125\n",
            "Batch: 170, Loss: 0.23417449100265647, Accuracy: 0.8810833333333333\n",
            "Batch: 180, Loss: 0.2340187847529434, Accuracy: 0.8814833333333333\n",
            "Batch: 190, Loss: 0.23539764073470923, Accuracy: 0.8811\n",
            "Batch: 200, Loss: 0.2356885634238484, Accuracy: 0.8806166666666667\n",
            "Batch: 210, Loss: 0.23585072249897823, Accuracy: 0.8807833333333334\n",
            "Batch: 220, Loss: 0.23605039342778064, Accuracy: 0.88035\n",
            "Batch: 230, Loss: 0.2342813326359546, Accuracy: 0.88115\n",
            "Batch: 240, Loss: 0.23455669222523232, Accuracy: 0.8810333333333333\n",
            "Batch: 250, Loss: 0.23369075668668984, Accuracy: 0.8815833333333334\n",
            "Batch: 260, Loss: 0.233517510743923, Accuracy: 0.8814166666666666\n",
            "Batch: 270, Loss: 0.232795996942845, Accuracy: 0.8819166666666667\n",
            "Batch: 280, Loss: 0.23250087803492783, Accuracy: 0.8817333333333334\n",
            "Batch: 290, Loss: 0.23221464338304101, Accuracy: 0.8813666666666666\n",
            "Batch: 300, Loss: 0.23205807206475107, Accuracy: 0.8817\n",
            "Batch: 310, Loss: 0.23184863816612328, Accuracy: 0.8823166666666666\n",
            "Batch: 320, Loss: 0.2318636509701354, Accuracy: 0.8817666666666667\n",
            "Batch: 330, Loss: 0.23169229810607897, Accuracy: 0.8822166666666666\n",
            "Batch: 340, Loss: 0.23176517026037943, Accuracy: 0.8822166666666666\n",
            "Batch: 350, Loss: 0.23202458491973937, Accuracy: 0.8821166666666667\n",
            "Batch: 360, Loss: 0.23221310841776255, Accuracy: 0.8814833333333333\n",
            "Batch: 370, Loss: 0.23161788661850785, Accuracy: 0.88165\n",
            "Batch: 380, Loss: 0.2320630654543494, Accuracy: 0.8812833333333333\n",
            "Batch: 390, Loss: 0.23226874433516448, Accuracy: 0.8812666666666666\n",
            "Batch: 400, Loss: 0.23292387244800306, Accuracy: 0.8814\n",
            "Batch: 410, Loss: 0.23270552046792872, Accuracy: 0.8819833333333333\n",
            "Batch: 420, Loss: 0.23221560309285041, Accuracy: 0.88235\n",
            "Batch: 430, Loss: 0.23282392706680377, Accuracy: 0.8822333333333333\n",
            "Batch: 440, Loss: 0.23204689968055814, Accuracy: 0.8825\n",
            "Batch: 450, Loss: 0.23192800725968937, Accuracy: 0.8826166666666667\n",
            "Batch: 460, Loss: 0.23207028461977364, Accuracy: 0.8826333333333334\n",
            "Batch: 470, Loss: 0.231353792097873, Accuracy: 0.8828333333333334\n",
            "Batch: 480, Loss: 0.2312028154116983, Accuracy: 0.88285\n",
            "Batch: 490, Loss: 0.23099941553081474, Accuracy: 0.88265\n",
            "Batch: 500, Loss: 0.231384152338488, Accuracy: 0.8824333333333333\n",
            "Batch: 510, Loss: 0.2313989089839682, Accuracy: 0.8825\n",
            "Batch: 520, Loss: 0.23134922221329324, Accuracy: 0.8826833333333334\n",
            "Batch: 530, Loss: 0.23080893904506247, Accuracy: 0.88285\n",
            "Batch: 540, Loss: 0.2307371423030746, Accuracy: 0.88255\n",
            "Batch: 550, Loss: 0.23107087609364957, Accuracy: 0.8828666666666667\n",
            "Batch: 560, Loss: 0.2313211393691949, Accuracy: 0.8822\n",
            "Batch: 570, Loss: 0.231699237623941, Accuracy: 0.8822333333333333\n",
            "Batch: 580, Loss: 0.2310284032718672, Accuracy: 0.8823166666666666\n",
            "Batch: 590, Loss: 0.23018986494667526, Accuracy: 0.88315\n",
            "Batch: 600, Loss: 0.22962114401952252, Accuracy: 0.8833833333333333\n",
            "Batch: 610, Loss: 0.2298405394185886, Accuracy: 0.88305\n",
            "Batch: 620, Loss: 0.22987953900364277, Accuracy: 0.88315\n",
            "Batch: 630, Loss: 0.22994905686752784, Accuracy: 0.8830666666666667\n",
            "Batch: 640, Loss: 0.23029444011263764, Accuracy: 0.8831666666666667\n",
            "Batch: 650, Loss: 0.23025716581413183, Accuracy: 0.8827166666666667\n",
            "Batch: 660, Loss: 0.2300635330300008, Accuracy: 0.8829333333333333\n",
            "Batch: 670, Loss: 0.22973879473224354, Accuracy: 0.88325\n",
            "Batch: 680, Loss: 0.2299252220238982, Accuracy: 0.8830333333333333\n",
            "Batch: 690, Loss: 0.23094370305114373, Accuracy: 0.8825666666666667\n",
            "Batch: 700, Loss: 0.2311180978948232, Accuracy: 0.8822\n",
            "Batch: 710, Loss: 0.23245991802630928, Accuracy: 0.882\n",
            "Batch: 720, Loss: 0.23144000326849976, Accuracy: 0.8827833333333334\n",
            "Batch: 730, Loss: 0.2310346792714926, Accuracy: 0.8827333333333334\n",
            "Batch: 740, Loss: 0.23100430861145782, Accuracy: 0.8826\n",
            "Batch: 750, Loss: 0.23156145120878932, Accuracy: 0.8819166666666667\n",
            "Batch: 760, Loss: 0.23044261968208535, Accuracy: 0.8828333333333334\n",
            "Batch: 770, Loss: 0.23019269890779887, Accuracy: 0.8828166666666667\n",
            "Batch: 780, Loss: 0.23082223528999787, Accuracy: 0.8829666666666667\n",
            "Batch: 790, Loss: 0.23037988108026183, Accuracy: 0.8831166666666667\n",
            "Batch: 800, Loss: 0.23018769775359507, Accuracy: 0.8830666666666667\n",
            "Batch: 810, Loss: 0.2304682581330096, Accuracy: 0.88275\n",
            "Batch: 820, Loss: 0.2311048494415039, Accuracy: 0.8825833333333334\n",
            "Batch: 830, Loss: 0.23030886974631115, Accuracy: 0.8830833333333333\n",
            "Batch: 840, Loss: 0.23025275759935393, Accuracy: 0.8831\n",
            "Batch: 850, Loss: 0.22987152418953954, Accuracy: 0.88275\n",
            "Batch: 860, Loss: 0.23081682365185494, Accuracy: 0.8823666666666666\n",
            "Batch: 870, Loss: 0.23011999486605186, Accuracy: 0.8826166666666667\n",
            "Batch: 880, Loss: 0.23017758028320778, Accuracy: 0.8827333333333334\n",
            "Batch: 890, Loss: 0.23023237041973504, Accuracy: 0.8828166666666667\n",
            "Batch: 900, Loss: 0.2301797064606354, Accuracy: 0.8827666666666667\n",
            "Batch: 910, Loss: 0.2290945274359671, Accuracy: 0.8835\n",
            "Batch: 920, Loss: 0.22941938654774902, Accuracy: 0.8833666666666666\n",
            "Batch: 930, Loss: 0.2294242857467433, Accuracy: 0.8830833333333333\n",
            "Epoch: 13, Loss: 0.229634864380054, Accuracy: 0.8834166666666666\n",
            "Batch: 0, Loss: 0.22964976100961007, Accuracy: 0.88315\n",
            "Batch: 10, Loss: 0.22996277769427426, Accuracy: 0.8829666666666667\n",
            "Batch: 20, Loss: 0.2290919827180839, Accuracy: 0.8833333333333333\n",
            "Batch: 30, Loss: 0.22935952892421774, Accuracy: 0.8833833333333333\n",
            "Batch: 40, Loss: 0.22837149625391714, Accuracy: 0.8836833333333334\n",
            "Batch: 50, Loss: 0.2289286456650998, Accuracy: 0.8835166666666666\n",
            "Batch: 60, Loss: 0.22853074163772724, Accuracy: 0.8836\n",
            "Batch: 70, Loss: 0.22829374511806105, Accuracy: 0.8834166666666666\n",
            "Batch: 80, Loss: 0.22863251795165174, Accuracy: 0.8831833333333333\n",
            "Batch: 90, Loss: 0.22759887169658807, Accuracy: 0.8836666666666667\n",
            "Batch: 100, Loss: 0.22775512715184537, Accuracy: 0.8834333333333333\n",
            "Batch: 110, Loss: 0.2283732896347247, Accuracy: 0.88345\n",
            "Batch: 120, Loss: 0.22745949851809447, Accuracy: 0.8838666666666667\n",
            "Batch: 130, Loss: 0.22852271032502156, Accuracy: 0.8835166666666666\n",
            "Batch: 140, Loss: 0.22912517751440717, Accuracy: 0.8836\n",
            "Batch: 150, Loss: 0.22781284586940095, Accuracy: 0.8843666666666666\n",
            "Batch: 160, Loss: 0.22787811939660946, Accuracy: 0.8841833333333333\n",
            "Batch: 170, Loss: 0.22709947904198818, Accuracy: 0.8842\n",
            "Batch: 180, Loss: 0.22700614001514535, Accuracy: 0.8842666666666666\n",
            "Batch: 190, Loss: 0.22849488448817695, Accuracy: 0.8841166666666667\n",
            "Batch: 200, Loss: 0.22908979302610505, Accuracy: 0.8834666666666666\n",
            "Batch: 210, Loss: 0.22942295166043083, Accuracy: 0.8836333333333334\n",
            "Batch: 220, Loss: 0.2295433885631528, Accuracy: 0.88335\n",
            "Batch: 230, Loss: 0.22752144403147817, Accuracy: 0.8839\n",
            "Batch: 240, Loss: 0.2280082333502497, Accuracy: 0.88425\n",
            "Batch: 250, Loss: 0.22721345824115782, Accuracy: 0.8845333333333333\n",
            "Batch: 260, Loss: 0.22720395997559037, Accuracy: 0.8844\n",
            "Batch: 270, Loss: 0.22635874631384068, Accuracy: 0.8847666666666667\n",
            "Batch: 280, Loss: 0.22584837356762966, Accuracy: 0.8845166666666666\n",
            "Batch: 290, Loss: 0.22559393999313243, Accuracy: 0.8846166666666667\n",
            "Batch: 300, Loss: 0.22542563080255962, Accuracy: 0.8846833333333334\n",
            "Batch: 310, Loss: 0.2253017820430015, Accuracy: 0.8849\n",
            "Batch: 320, Loss: 0.22524132496129726, Accuracy: 0.8845\n",
            "Batch: 330, Loss: 0.2250539556762227, Accuracy: 0.8848333333333334\n",
            "Batch: 340, Loss: 0.22508886877251208, Accuracy: 0.8850666666666667\n",
            "Batch: 350, Loss: 0.22523107529081463, Accuracy: 0.8848333333333334\n",
            "Batch: 360, Loss: 0.2255656898858521, Accuracy: 0.8844166666666666\n",
            "Batch: 370, Loss: 0.22489459478163845, Accuracy: 0.8846166666666667\n",
            "Batch: 380, Loss: 0.22531553820299052, Accuracy: 0.8842666666666666\n",
            "Batch: 390, Loss: 0.22560937280087684, Accuracy: 0.8844166666666666\n",
            "Batch: 400, Loss: 0.2264374829276381, Accuracy: 0.8843166666666666\n",
            "Batch: 410, Loss: 0.22612768656486606, Accuracy: 0.8851666666666667\n",
            "Batch: 420, Loss: 0.2256157908939365, Accuracy: 0.88535\n",
            "Batch: 430, Loss: 0.22623197678408, Accuracy: 0.8854666666666666\n",
            "Batch: 440, Loss: 0.22549335061931086, Accuracy: 0.88545\n",
            "Batch: 450, Loss: 0.22530969390345926, Accuracy: 0.8856166666666667\n",
            "Batch: 460, Loss: 0.22542973836371882, Accuracy: 0.8855666666666666\n",
            "Batch: 470, Loss: 0.22484042136410237, Accuracy: 0.8852833333333333\n",
            "Batch: 480, Loss: 0.2246627931949992, Accuracy: 0.8853333333333333\n",
            "Batch: 490, Loss: 0.22439598880676567, Accuracy: 0.8853333333333333\n",
            "Batch: 500, Loss: 0.22473156398173738, Accuracy: 0.88535\n",
            "Batch: 510, Loss: 0.22480827228035608, Accuracy: 0.8850833333333333\n",
            "Batch: 520, Loss: 0.2248619943696972, Accuracy: 0.8856166666666667\n",
            "Batch: 530, Loss: 0.22432886401210392, Accuracy: 0.8859666666666667\n",
            "Batch: 540, Loss: 0.22414198501772126, Accuracy: 0.8855666666666666\n",
            "Batch: 550, Loss: 0.2244692937508556, Accuracy: 0.8854\n",
            "Batch: 560, Loss: 0.22478643422827982, Accuracy: 0.88505\n",
            "Batch: 570, Loss: 0.2251648487212705, Accuracy: 0.8851333333333333\n",
            "Batch: 580, Loss: 0.224623362068521, Accuracy: 0.8850666666666667\n",
            "Batch: 590, Loss: 0.22374963593990577, Accuracy: 0.8858166666666667\n",
            "Batch: 600, Loss: 0.22308802897222646, Accuracy: 0.8861666666666667\n",
            "Batch: 610, Loss: 0.22329390487034068, Accuracy: 0.8860666666666667\n",
            "Batch: 620, Loss: 0.2233586692510213, Accuracy: 0.8861333333333333\n",
            "Batch: 630, Loss: 0.22332142856046494, Accuracy: 0.8861833333333333\n",
            "Batch: 640, Loss: 0.22380365277150477, Accuracy: 0.8858\n",
            "Batch: 650, Loss: 0.22381795677868097, Accuracy: 0.8860166666666667\n",
            "Batch: 660, Loss: 0.22360094775818545, Accuracy: 0.8856833333333334\n",
            "Batch: 670, Loss: 0.22322476578199518, Accuracy: 0.8859166666666667\n",
            "Batch: 680, Loss: 0.2233962525989965, Accuracy: 0.8858\n",
            "Batch: 690, Loss: 0.2242842114799462, Accuracy: 0.8854833333333333\n",
            "Batch: 700, Loss: 0.22434142856830344, Accuracy: 0.8849\n",
            "Batch: 710, Loss: 0.22565957907551695, Accuracy: 0.88485\n",
            "Batch: 720, Loss: 0.22487651043779106, Accuracy: 0.8851333333333333\n",
            "Batch: 730, Loss: 0.224581012503209, Accuracy: 0.8854333333333333\n",
            "Batch: 740, Loss: 0.22474936470557116, Accuracy: 0.88505\n",
            "Batch: 750, Loss: 0.22568984248011828, Accuracy: 0.8848833333333334\n",
            "Batch: 760, Loss: 0.224524039781964, Accuracy: 0.8857333333333334\n",
            "Batch: 770, Loss: 0.22405002329342993, Accuracy: 0.8857666666666667\n",
            "Batch: 780, Loss: 0.22479763651068094, Accuracy: 0.8854833333333333\n",
            "Batch: 790, Loss: 0.22433690457935004, Accuracy: 0.8856666666666667\n",
            "Batch: 800, Loss: 0.22404115908562466, Accuracy: 0.8859333333333334\n",
            "Batch: 810, Loss: 0.22424252476390072, Accuracy: 0.88525\n",
            "Batch: 820, Loss: 0.2251772287290649, Accuracy: 0.8852666666666666\n",
            "Batch: 830, Loss: 0.22434969555754966, Accuracy: 0.8857166666666667\n",
            "Batch: 840, Loss: 0.22415285277976013, Accuracy: 0.8860333333333333\n",
            "Batch: 850, Loss: 0.22354538644800143, Accuracy: 0.8858166666666667\n",
            "Batch: 860, Loss: 0.2246012631496538, Accuracy: 0.8850666666666667\n",
            "Batch: 870, Loss: 0.22397212408500025, Accuracy: 0.88525\n",
            "Batch: 880, Loss: 0.22383234287825587, Accuracy: 0.8854\n",
            "Batch: 890, Loss: 0.22386736343242214, Accuracy: 0.8857333333333334\n",
            "Batch: 900, Loss: 0.22388599916036314, Accuracy: 0.8858166666666667\n",
            "Batch: 910, Loss: 0.22285021916410322, Accuracy: 0.8859666666666667\n",
            "Batch: 920, Loss: 0.22314169891520738, Accuracy: 0.88605\n",
            "Batch: 930, Loss: 0.22318461090571645, Accuracy: 0.8857166666666667\n",
            "Epoch: 14, Loss: 0.2235759162905278, Accuracy: 0.8856833333333334\n",
            "Batch: 0, Loss: 0.22358114195461132, Accuracy: 0.8858833333333334\n",
            "Batch: 10, Loss: 0.22394950241640307, Accuracy: 0.8855666666666666\n",
            "Batch: 20, Loss: 0.22322552998189127, Accuracy: 0.8857666666666667\n",
            "Batch: 30, Loss: 0.2234387453795693, Accuracy: 0.88585\n",
            "Batch: 40, Loss: 0.22231555556754917, Accuracy: 0.8863666666666666\n",
            "Batch: 50, Loss: 0.2231019384988203, Accuracy: 0.8858\n",
            "Batch: 60, Loss: 0.22256563667809953, Accuracy: 0.88605\n",
            "Batch: 70, Loss: 0.22202998382127082, Accuracy: 0.8864333333333333\n",
            "Batch: 80, Loss: 0.22236114009083238, Accuracy: 0.8859166666666667\n",
            "Batch: 90, Loss: 0.22123366794421517, Accuracy: 0.8862166666666667\n",
            "Batch: 100, Loss: 0.22129536899937563, Accuracy: 0.8863\n",
            "Batch: 110, Loss: 0.22208893815377878, Accuracy: 0.8863666666666666\n",
            "Batch: 120, Loss: 0.22125243430715544, Accuracy: 0.8868166666666667\n",
            "Batch: 130, Loss: 0.22223554277778013, Accuracy: 0.88645\n",
            "Batch: 140, Loss: 0.2229962850734343, Accuracy: 0.8863\n",
            "Batch: 150, Loss: 0.22170137616377325, Accuracy: 0.8869833333333333\n",
            "Batch: 160, Loss: 0.2216516978069643, Accuracy: 0.8868833333333334\n",
            "Batch: 170, Loss: 0.22090354860646538, Accuracy: 0.8870166666666667\n",
            "Batch: 180, Loss: 0.22075716483865218, Accuracy: 0.8868833333333334\n",
            "Batch: 190, Loss: 0.22218938090762477, Accuracy: 0.8862666666666666\n",
            "Batch: 200, Loss: 0.22313321085239682, Accuracy: 0.8865666666666666\n",
            "Batch: 210, Loss: 0.22358478178433802, Accuracy: 0.8866\n",
            "Batch: 220, Loss: 0.223469484635161, Accuracy: 0.8860666666666667\n",
            "Batch: 230, Loss: 0.22147122094584246, Accuracy: 0.8863666666666666\n",
            "Batch: 240, Loss: 0.22201947712645764, Accuracy: 0.8868333333333334\n",
            "Batch: 250, Loss: 0.2214529661088054, Accuracy: 0.8869\n",
            "Batch: 260, Loss: 0.2214743426101489, Accuracy: 0.8869666666666667\n",
            "Batch: 270, Loss: 0.22037319282888984, Accuracy: 0.8871333333333333\n",
            "Batch: 280, Loss: 0.21975391620902232, Accuracy: 0.8872666666666666\n",
            "Batch: 290, Loss: 0.21953325063884938, Accuracy: 0.8873833333333333\n",
            "Batch: 300, Loss: 0.21938497537572169, Accuracy: 0.8877\n",
            "Batch: 310, Loss: 0.219423651029507, Accuracy: 0.8874666666666666\n",
            "Batch: 320, Loss: 0.21926990422092635, Accuracy: 0.8872333333333333\n",
            "Batch: 330, Loss: 0.21906210044193755, Accuracy: 0.8878666666666667\n",
            "Batch: 340, Loss: 0.219124281328623, Accuracy: 0.88755\n",
            "Batch: 350, Loss: 0.21923794437243851, Accuracy: 0.88745\n",
            "Batch: 360, Loss: 0.219536818594762, Accuracy: 0.8874833333333333\n",
            "Batch: 370, Loss: 0.2188782557602417, Accuracy: 0.8877166666666667\n",
            "Batch: 380, Loss: 0.21926397821104265, Accuracy: 0.8870666666666667\n",
            "Batch: 390, Loss: 0.2195759814517753, Accuracy: 0.8869166666666667\n",
            "Batch: 400, Loss: 0.22046055933326808, Accuracy: 0.8871\n",
            "Batch: 410, Loss: 0.22012292213920998, Accuracy: 0.8874833333333333\n",
            "Batch: 420, Loss: 0.21964670255488858, Accuracy: 0.8881333333333333\n",
            "Batch: 430, Loss: 0.22027553459898538, Accuracy: 0.8879166666666667\n",
            "Batch: 440, Loss: 0.21973941120214863, Accuracy: 0.888\n",
            "Batch: 450, Loss: 0.2194993915978564, Accuracy: 0.88825\n",
            "Batch: 460, Loss: 0.21962802062301587, Accuracy: 0.8881166666666667\n",
            "Batch: 470, Loss: 0.21902375475496383, Accuracy: 0.88795\n",
            "Batch: 480, Loss: 0.21880008169102924, Accuracy: 0.8881333333333333\n",
            "Batch: 490, Loss: 0.21850558915015916, Accuracy: 0.8880833333333333\n",
            "Batch: 500, Loss: 0.21872018374974506, Accuracy: 0.8878666666666667\n",
            "Batch: 510, Loss: 0.2188876351895177, Accuracy: 0.8878666666666667\n",
            "Batch: 520, Loss: 0.2186943625532105, Accuracy: 0.8884166666666666\n",
            "Batch: 530, Loss: 0.21830628199306665, Accuracy: 0.88815\n",
            "Batch: 540, Loss: 0.21816990735143565, Accuracy: 0.8883\n",
            "Batch: 550, Loss: 0.2186918078592374, Accuracy: 0.8879833333333333\n",
            "Batch: 560, Loss: 0.21922331262660266, Accuracy: 0.8878833333333334\n",
            "Batch: 570, Loss: 0.2197652795729582, Accuracy: 0.8875333333333333\n",
            "Batch: 580, Loss: 0.21895983784273776, Accuracy: 0.88825\n",
            "Batch: 590, Loss: 0.2180221081150641, Accuracy: 0.8887666666666667\n",
            "Batch: 600, Loss: 0.21729079911231006, Accuracy: 0.8890333333333333\n",
            "Batch: 610, Loss: 0.2173909521079212, Accuracy: 0.88895\n",
            "Batch: 620, Loss: 0.2176015587058479, Accuracy: 0.8884166666666666\n",
            "Batch: 630, Loss: 0.21742228093727403, Accuracy: 0.88875\n",
            "Batch: 640, Loss: 0.21799948827168245, Accuracy: 0.8886166666666667\n",
            "Batch: 650, Loss: 0.21806283393415518, Accuracy: 0.88865\n",
            "Batch: 660, Loss: 0.21797636466909387, Accuracy: 0.8881166666666667\n",
            "Batch: 670, Loss: 0.21759432095332526, Accuracy: 0.8884666666666666\n",
            "Batch: 680, Loss: 0.21785220997505864, Accuracy: 0.88835\n",
            "Batch: 690, Loss: 0.21869198182150004, Accuracy: 0.8879\n",
            "Batch: 700, Loss: 0.21871779378470368, Accuracy: 0.8877833333333334\n",
            "Batch: 710, Loss: 0.21982667657950467, Accuracy: 0.8872666666666666\n",
            "Batch: 720, Loss: 0.21906912768259237, Accuracy: 0.8878\n",
            "Batch: 730, Loss: 0.21903120461847392, Accuracy: 0.8879\n",
            "Batch: 740, Loss: 0.2191876303921423, Accuracy: 0.8877666666666667\n",
            "Batch: 750, Loss: 0.2203941767720784, Accuracy: 0.8872333333333333\n",
            "Batch: 760, Loss: 0.21930256935320175, Accuracy: 0.88775\n",
            "Batch: 770, Loss: 0.2186884411872998, Accuracy: 0.8880333333333333\n",
            "Batch: 780, Loss: 0.21951812929798534, Accuracy: 0.8874333333333333\n",
            "Batch: 790, Loss: 0.21903012398067084, Accuracy: 0.8877166666666667\n",
            "Batch: 800, Loss: 0.21861796701689862, Accuracy: 0.8881\n",
            "Batch: 810, Loss: 0.21867731509894855, Accuracy: 0.8877166666666667\n",
            "Batch: 820, Loss: 0.21977645589858275, Accuracy: 0.8872833333333333\n",
            "Batch: 830, Loss: 0.21883876295462928, Accuracy: 0.8882666666666666\n",
            "Batch: 840, Loss: 0.21858138527407436, Accuracy: 0.8882333333333333\n",
            "Batch: 850, Loss: 0.2179721671277155, Accuracy: 0.8882166666666667\n",
            "Batch: 860, Loss: 0.21903443415306711, Accuracy: 0.88735\n",
            "Batch: 870, Loss: 0.21836990087934782, Accuracy: 0.8875333333333333\n",
            "Batch: 880, Loss: 0.21807860283280192, Accuracy: 0.8879833333333333\n",
            "Batch: 890, Loss: 0.21808723165983368, Accuracy: 0.8877\n",
            "Batch: 900, Loss: 0.2180148523792805, Accuracy: 0.8876833333333334\n",
            "Batch: 910, Loss: 0.21721287045727813, Accuracy: 0.8886666666666667\n",
            "Batch: 920, Loss: 0.21764187817644276, Accuracy: 0.88835\n",
            "Batch: 930, Loss: 0.2175531033338958, Accuracy: 0.8881333333333333\n",
            "Epoch: 15, Loss: 0.21801103429794685, Accuracy: 0.8878833333333334\n",
            "Batch: 0, Loss: 0.21803560768870747, Accuracy: 0.8878833333333334\n",
            "Batch: 10, Loss: 0.2184504767140666, Accuracy: 0.8876333333333334\n",
            "Batch: 20, Loss: 0.21784909139497474, Accuracy: 0.8881\n",
            "Batch: 30, Loss: 0.21772827934112876, Accuracy: 0.8879666666666667\n",
            "Batch: 40, Loss: 0.21656754163812642, Accuracy: 0.8886166666666667\n",
            "Batch: 50, Loss: 0.2173796016760565, Accuracy: 0.8882166666666667\n",
            "Batch: 60, Loss: 0.21687077896504395, Accuracy: 0.8885333333333333\n",
            "Batch: 70, Loss: 0.2162694412789764, Accuracy: 0.8888166666666667\n",
            "Batch: 80, Loss: 0.21672735736649928, Accuracy: 0.8882166666666667\n",
            "Batch: 90, Loss: 0.21559361148212353, Accuracy: 0.8891\n",
            "Batch: 100, Loss: 0.21537877368769925, Accuracy: 0.8891333333333333\n",
            "Batch: 110, Loss: 0.2163480365188125, Accuracy: 0.8886\n",
            "Batch: 120, Loss: 0.21544846005697277, Accuracy: 0.8896666666666667\n",
            "Batch: 130, Loss: 0.21648700300361196, Accuracy: 0.8894333333333333\n",
            "Batch: 140, Loss: 0.217141777748611, Accuracy: 0.8887333333333334\n",
            "Batch: 150, Loss: 0.21595232218722737, Accuracy: 0.8891166666666667\n",
            "Batch: 160, Loss: 0.2160308936322184, Accuracy: 0.8891666666666667\n",
            "Batch: 170, Loss: 0.21523853133257861, Accuracy: 0.8894\n",
            "Batch: 180, Loss: 0.21506836500192497, Accuracy: 0.8895\n",
            "Batch: 190, Loss: 0.21646149177275562, Accuracy: 0.8886333333333334\n",
            "Batch: 200, Loss: 0.217550445040129, Accuracy: 0.8888166666666667\n",
            "Batch: 210, Loss: 0.21800270230399935, Accuracy: 0.88885\n",
            "Batch: 220, Loss: 0.21809277756563, Accuracy: 0.8889333333333334\n",
            "Batch: 230, Loss: 0.2158923118568758, Accuracy: 0.8886833333333334\n",
            "Batch: 240, Loss: 0.2164653525833484, Accuracy: 0.8892666666666666\n",
            "Batch: 250, Loss: 0.21607792077376667, Accuracy: 0.8894833333333333\n",
            "Batch: 260, Loss: 0.21607447312956926, Accuracy: 0.8892666666666666\n",
            "Batch: 270, Loss: 0.21486597689731943, Accuracy: 0.88985\n",
            "Batch: 280, Loss: 0.2140940405340452, Accuracy: 0.8899666666666667\n",
            "Batch: 290, Loss: 0.21392999328946039, Accuracy: 0.8900166666666667\n",
            "Batch: 300, Loss: 0.21387294415575908, Accuracy: 0.88995\n",
            "Batch: 310, Loss: 0.214046739821409, Accuracy: 0.89015\n",
            "Batch: 320, Loss: 0.213782867645884, Accuracy: 0.8898666666666667\n",
            "Batch: 330, Loss: 0.21369970739148855, Accuracy: 0.89045\n",
            "Batch: 340, Loss: 0.2138055098151947, Accuracy: 0.8899833333333333\n",
            "Batch: 350, Loss: 0.21385322817933025, Accuracy: 0.8902\n",
            "Batch: 360, Loss: 0.214065316040777, Accuracy: 0.89015\n",
            "Batch: 370, Loss: 0.213371934132702, Accuracy: 0.8904833333333333\n",
            "Batch: 380, Loss: 0.2136406661134023, Accuracy: 0.88975\n",
            "Batch: 390, Loss: 0.21394729061372958, Accuracy: 0.8893666666666666\n",
            "Batch: 400, Loss: 0.21489666567655985, Accuracy: 0.8891666666666667\n",
            "Batch: 410, Loss: 0.2145170072770147, Accuracy: 0.8898833333333334\n",
            "Batch: 420, Loss: 0.21402625977470924, Accuracy: 0.8903166666666666\n",
            "Batch: 430, Loss: 0.21467761309031044, Accuracy: 0.8904333333333333\n",
            "Batch: 440, Loss: 0.21442982076760267, Accuracy: 0.8904666666666666\n",
            "Batch: 450, Loss: 0.21417876815268974, Accuracy: 0.8906166666666666\n",
            "Batch: 460, Loss: 0.21426492690320947, Accuracy: 0.8904833333333333\n",
            "Batch: 470, Loss: 0.2135240888009756, Accuracy: 0.8903666666666666\n",
            "Batch: 480, Loss: 0.21331659534576197, Accuracy: 0.8905\n",
            "Batch: 490, Loss: 0.21300634407092064, Accuracy: 0.8909\n",
            "Batch: 500, Loss: 0.21315236586514205, Accuracy: 0.8909\n",
            "Batch: 510, Loss: 0.2132633806901267, Accuracy: 0.8903333333333333\n",
            "Batch: 520, Loss: 0.213101360878216, Accuracy: 0.891\n",
            "Batch: 530, Loss: 0.21283061819079474, Accuracy: 0.8910166666666667\n",
            "Batch: 540, Loss: 0.2128143491826197, Accuracy: 0.89105\n",
            "Batch: 550, Loss: 0.2134522184516215, Accuracy: 0.8907666666666667\n",
            "Batch: 560, Loss: 0.21404683497952612, Accuracy: 0.8905\n",
            "Batch: 570, Loss: 0.21481858455471117, Accuracy: 0.88995\n",
            "Batch: 580, Loss: 0.21384753564376635, Accuracy: 0.8904\n",
            "Batch: 590, Loss: 0.21272547585748633, Accuracy: 0.8913666666666666\n",
            "Batch: 600, Loss: 0.21209481779452458, Accuracy: 0.8916166666666666\n",
            "Batch: 610, Loss: 0.21205811995723978, Accuracy: 0.8914\n",
            "Batch: 620, Loss: 0.21230570379321986, Accuracy: 0.8911333333333333\n",
            "Batch: 630, Loss: 0.2120816808364657, Accuracy: 0.8912333333333333\n",
            "Batch: 640, Loss: 0.21288208520888194, Accuracy: 0.8907166666666667\n",
            "Batch: 650, Loss: 0.21272983229841216, Accuracy: 0.89085\n",
            "Batch: 660, Loss: 0.21281531331303305, Accuracy: 0.8902666666666667\n",
            "Batch: 670, Loss: 0.21235705713624295, Accuracy: 0.8911166666666667\n",
            "Batch: 680, Loss: 0.21260113845920917, Accuracy: 0.89065\n",
            "Batch: 690, Loss: 0.2136074981454811, Accuracy: 0.8898833333333334\n",
            "Batch: 700, Loss: 0.2134436481494881, Accuracy: 0.89\n",
            "Batch: 710, Loss: 0.21464432944275033, Accuracy: 0.8897833333333334\n",
            "Batch: 720, Loss: 0.2138857534649712, Accuracy: 0.8902166666666667\n",
            "Batch: 730, Loss: 0.21411852753994323, Accuracy: 0.8900333333333333\n",
            "Batch: 740, Loss: 0.21421829116849367, Accuracy: 0.88995\n",
            "Batch: 750, Loss: 0.2154502711193932, Accuracy: 0.8896\n",
            "Batch: 760, Loss: 0.2142335446493704, Accuracy: 0.8901666666666667\n",
            "Batch: 770, Loss: 0.21356841390610282, Accuracy: 0.8899\n",
            "Batch: 780, Loss: 0.21445327526330418, Accuracy: 0.8895166666666666\n",
            "Batch: 790, Loss: 0.21388546580688178, Accuracy: 0.8896666666666667\n",
            "Batch: 800, Loss: 0.2134879784048019, Accuracy: 0.8899833333333333\n",
            "Batch: 810, Loss: 0.21346815677365275, Accuracy: 0.8899333333333334\n",
            "Batch: 820, Loss: 0.2145753484528994, Accuracy: 0.8895666666666666\n",
            "Batch: 830, Loss: 0.21374355598224673, Accuracy: 0.8904333333333333\n",
            "Batch: 840, Loss: 0.21336831321085606, Accuracy: 0.8902166666666667\n",
            "Batch: 850, Loss: 0.21260248777023918, Accuracy: 0.8906\n",
            "Batch: 860, Loss: 0.2137174083391739, Accuracy: 0.8893333333333333\n",
            "Batch: 870, Loss: 0.21306768233730125, Accuracy: 0.8899\n",
            "Batch: 880, Loss: 0.21272721423555335, Accuracy: 0.8905166666666666\n",
            "Batch: 890, Loss: 0.21269228212442118, Accuracy: 0.8900333333333333\n",
            "Batch: 900, Loss: 0.21261949765001492, Accuracy: 0.8903166666666666\n",
            "Batch: 910, Loss: 0.21196904563556973, Accuracy: 0.8909\n",
            "Batch: 920, Loss: 0.21248015973224377, Accuracy: 0.8906833333333334\n",
            "Batch: 930, Loss: 0.21233481506537957, Accuracy: 0.89065\n",
            "Epoch: 16, Loss: 0.21268819981169748, Accuracy: 0.8903\n",
            "Batch: 0, Loss: 0.2127306583497492, Accuracy: 0.8901166666666667\n",
            "Batch: 10, Loss: 0.21316990204947958, Accuracy: 0.8896666666666667\n",
            "Batch: 20, Loss: 0.21252091992390942, Accuracy: 0.8904\n",
            "Batch: 30, Loss: 0.21242751255375106, Accuracy: 0.8901833333333333\n",
            "Batch: 40, Loss: 0.21125584632739852, Accuracy: 0.8908\n",
            "Batch: 50, Loss: 0.21200492566021453, Accuracy: 0.8903833333333333\n",
            "Batch: 60, Loss: 0.21151563547857916, Accuracy: 0.8908333333333334\n",
            "Batch: 70, Loss: 0.21087204398441659, Accuracy: 0.8910333333333333\n",
            "Batch: 80, Loss: 0.21141773015913734, Accuracy: 0.8910833333333333\n",
            "Batch: 90, Loss: 0.2104993559503151, Accuracy: 0.89155\n",
            "Batch: 100, Loss: 0.21012811072928655, Accuracy: 0.8914333333333333\n",
            "Batch: 110, Loss: 0.2110558051409019, Accuracy: 0.89135\n",
            "Batch: 120, Loss: 0.21017912487349746, Accuracy: 0.8918666666666667\n",
            "Batch: 130, Loss: 0.21132796123400613, Accuracy: 0.8914\n",
            "Batch: 140, Loss: 0.21193122939500567, Accuracy: 0.8912666666666667\n",
            "Batch: 150, Loss: 0.2106571018805936, Accuracy: 0.8914\n",
            "Batch: 160, Loss: 0.21087031214748514, Accuracy: 0.8915\n",
            "Batch: 170, Loss: 0.2099969368066056, Accuracy: 0.8918833333333334\n",
            "Batch: 180, Loss: 0.2098843550694285, Accuracy: 0.8919833333333334\n",
            "Batch: 190, Loss: 0.2109804809869111, Accuracy: 0.89135\n",
            "Batch: 200, Loss: 0.2120090927808963, Accuracy: 0.8908166666666667\n",
            "Batch: 210, Loss: 0.21242489406543769, Accuracy: 0.8910166666666667\n",
            "Batch: 220, Loss: 0.21282528892039218, Accuracy: 0.8908666666666667\n",
            "Batch: 230, Loss: 0.21055516557900616, Accuracy: 0.89115\n",
            "Batch: 240, Loss: 0.21101682879602468, Accuracy: 0.8917666666666667\n",
            "Batch: 250, Loss: 0.21095604473944948, Accuracy: 0.8919\n",
            "Batch: 260, Loss: 0.2109764932287561, Accuracy: 0.8917\n",
            "Batch: 270, Loss: 0.2097496804554018, Accuracy: 0.8924333333333333\n",
            "Batch: 280, Loss: 0.20884177580690194, Accuracy: 0.89275\n",
            "Batch: 290, Loss: 0.20881292217641348, Accuracy: 0.8922333333333333\n",
            "Batch: 300, Loss: 0.20872085808231503, Accuracy: 0.8924666666666666\n",
            "Batch: 310, Loss: 0.20892934453831152, Accuracy: 0.89195\n",
            "Batch: 320, Loss: 0.20857092399273028, Accuracy: 0.8921\n",
            "Batch: 330, Loss: 0.2086408759779155, Accuracy: 0.8927833333333334\n",
            "Batch: 340, Loss: 0.2088093181382723, Accuracy: 0.89245\n",
            "Batch: 350, Loss: 0.20882399817583192, Accuracy: 0.8924166666666666\n",
            "Batch: 360, Loss: 0.20917178414508944, Accuracy: 0.8926\n",
            "Batch: 370, Loss: 0.20831086925005118, Accuracy: 0.8927833333333334\n",
            "Batch: 380, Loss: 0.20837417458356455, Accuracy: 0.8921333333333333\n",
            "Batch: 390, Loss: 0.20861388247440008, Accuracy: 0.8915666666666666\n",
            "Batch: 400, Loss: 0.20956138363316257, Accuracy: 0.8916333333333334\n",
            "Batch: 410, Loss: 0.20924258188631895, Accuracy: 0.8924166666666666\n",
            "Batch: 420, Loss: 0.20882929705278247, Accuracy: 0.8928\n",
            "Batch: 430, Loss: 0.20956421230796068, Accuracy: 0.89275\n",
            "Batch: 440, Loss: 0.20951170382075904, Accuracy: 0.8927666666666667\n",
            "Batch: 450, Loss: 0.2092073803502903, Accuracy: 0.8928833333333334\n",
            "Batch: 460, Loss: 0.20919067290231533, Accuracy: 0.8928\n",
            "Batch: 470, Loss: 0.20835547751416617, Accuracy: 0.8924333333333333\n",
            "Batch: 480, Loss: 0.20821778438699218, Accuracy: 0.8929333333333334\n",
            "Batch: 490, Loss: 0.20794930404353393, Accuracy: 0.8929333333333334\n",
            "Batch: 500, Loss: 0.20809953243411855, Accuracy: 0.8933166666666666\n",
            "Batch: 510, Loss: 0.20822567613854165, Accuracy: 0.8928166666666667\n",
            "Batch: 520, Loss: 0.2081044632000019, Accuracy: 0.8933166666666666\n",
            "Batch: 530, Loss: 0.20786146191946162, Accuracy: 0.8931666666666667\n",
            "Batch: 540, Loss: 0.20776587330993962, Accuracy: 0.8929166666666667\n",
            "Batch: 550, Loss: 0.20849258644584748, Accuracy: 0.8930333333333333\n",
            "Batch: 560, Loss: 0.20916348178288985, Accuracy: 0.8925\n",
            "Batch: 570, Loss: 0.20984027482766063, Accuracy: 0.8921166666666667\n",
            "Batch: 580, Loss: 0.20906767128939185, Accuracy: 0.8923833333333333\n",
            "Batch: 590, Loss: 0.2077872286891439, Accuracy: 0.8937333333333334\n",
            "Batch: 600, Loss: 0.20727216844854274, Accuracy: 0.8937\n",
            "Batch: 610, Loss: 0.20711391957222375, Accuracy: 0.8939333333333334\n",
            "Batch: 620, Loss: 0.20733294191240245, Accuracy: 0.8935666666666666\n",
            "Batch: 630, Loss: 0.20705529163673905, Accuracy: 0.89375\n",
            "Batch: 640, Loss: 0.20769809434791905, Accuracy: 0.8933166666666666\n",
            "Batch: 650, Loss: 0.20764028217540756, Accuracy: 0.8933333333333333\n",
            "Batch: 660, Loss: 0.20778867877275373, Accuracy: 0.8927833333333334\n",
            "Batch: 670, Loss: 0.2071844522917163, Accuracy: 0.8934833333333333\n",
            "Batch: 680, Loss: 0.2074489089551907, Accuracy: 0.8928\n",
            "Batch: 690, Loss: 0.20846088197927648, Accuracy: 0.8921833333333333\n",
            "Batch: 700, Loss: 0.2083024396485444, Accuracy: 0.8922166666666667\n",
            "Batch: 710, Loss: 0.20963588022421215, Accuracy: 0.8917166666666667\n",
            "Batch: 720, Loss: 0.20891860925365166, Accuracy: 0.8922\n",
            "Batch: 730, Loss: 0.2092599292537273, Accuracy: 0.8922333333333333\n",
            "Batch: 740, Loss: 0.20927183463835525, Accuracy: 0.8920666666666667\n",
            "Batch: 750, Loss: 0.21035232346769464, Accuracy: 0.8914833333333333\n",
            "Batch: 760, Loss: 0.20912743631208736, Accuracy: 0.89215\n",
            "Batch: 770, Loss: 0.20854666939228383, Accuracy: 0.8921333333333333\n",
            "Batch: 780, Loss: 0.20968093844479926, Accuracy: 0.8914833333333333\n",
            "Batch: 790, Loss: 0.2090484388827723, Accuracy: 0.8917333333333334\n",
            "Batch: 800, Loss: 0.20879480590502272, Accuracy: 0.8920166666666667\n",
            "Batch: 810, Loss: 0.20863460220409577, Accuracy: 0.8920833333333333\n",
            "Batch: 820, Loss: 0.20969040636539416, Accuracy: 0.89145\n",
            "Batch: 830, Loss: 0.20891043941635012, Accuracy: 0.89175\n",
            "Batch: 840, Loss: 0.20846762899547716, Accuracy: 0.8924\n",
            "Batch: 850, Loss: 0.207614807280782, Accuracy: 0.8929666666666667\n",
            "Batch: 860, Loss: 0.2086746819539646, Accuracy: 0.8918333333333334\n",
            "Batch: 870, Loss: 0.20793371901575994, Accuracy: 0.8922333333333333\n",
            "Batch: 880, Loss: 0.20768267411872257, Accuracy: 0.8928166666666667\n",
            "Batch: 890, Loss: 0.20765675479867848, Accuracy: 0.89245\n",
            "Batch: 900, Loss: 0.20756914656579525, Accuracy: 0.8925666666666666\n",
            "Batch: 910, Loss: 0.20700606326617277, Accuracy: 0.89265\n",
            "Batch: 920, Loss: 0.20758731956206458, Accuracy: 0.8926166666666666\n",
            "Batch: 930, Loss: 0.20732047740712214, Accuracy: 0.8928666666666667\n",
            "Epoch: 17, Loss: 0.20767390568934774, Accuracy: 0.8926833333333334\n",
            "Batch: 0, Loss: 0.20772454801039525, Accuracy: 0.8926166666666666\n",
            "Batch: 10, Loss: 0.208301071062132, Accuracy: 0.8918166666666667\n",
            "Batch: 20, Loss: 0.20745200300173566, Accuracy: 0.8928166666666667\n",
            "Batch: 30, Loss: 0.20750109082612567, Accuracy: 0.89265\n",
            "Batch: 40, Loss: 0.20633055364417555, Accuracy: 0.89325\n",
            "Batch: 50, Loss: 0.20699943777002924, Accuracy: 0.8928333333333334\n",
            "Batch: 60, Loss: 0.20637020017301858, Accuracy: 0.8930166666666667\n",
            "Batch: 70, Loss: 0.20576822317155877, Accuracy: 0.8935\n",
            "Batch: 80, Loss: 0.20626090080707152, Accuracy: 0.8931333333333333\n",
            "Batch: 90, Loss: 0.205666236133452, Accuracy: 0.89375\n",
            "Batch: 100, Loss: 0.20521121830383277, Accuracy: 0.89385\n",
            "Batch: 110, Loss: 0.20614325823986637, Accuracy: 0.8935\n",
            "Batch: 120, Loss: 0.2052365765065883, Accuracy: 0.8942666666666667\n",
            "Batch: 130, Loss: 0.206375227281762, Accuracy: 0.8937166666666667\n",
            "Batch: 140, Loss: 0.20720962007906235, Accuracy: 0.8932833333333333\n",
            "Batch: 150, Loss: 0.2057803256693236, Accuracy: 0.8935666666666666\n",
            "Batch: 160, Loss: 0.20580956842705153, Accuracy: 0.8936166666666666\n",
            "Batch: 170, Loss: 0.2050357489626546, Accuracy: 0.8938833333333334\n",
            "Batch: 180, Loss: 0.20490842378167348, Accuracy: 0.8943166666666666\n",
            "Batch: 190, Loss: 0.20577982116518412, Accuracy: 0.8937833333333334\n",
            "Batch: 200, Loss: 0.20697084856238737, Accuracy: 0.8930833333333333\n",
            "Batch: 210, Loss: 0.20706711450571283, Accuracy: 0.8931\n",
            "Batch: 220, Loss: 0.20775782314825195, Accuracy: 0.8926666666666667\n",
            "Batch: 230, Loss: 0.20585822717248395, Accuracy: 0.8931166666666667\n",
            "Batch: 240, Loss: 0.20620045160355538, Accuracy: 0.8939166666666667\n",
            "Batch: 250, Loss: 0.2062287737445784, Accuracy: 0.8940333333333333\n",
            "Batch: 260, Loss: 0.20620081466321047, Accuracy: 0.8935833333333333\n",
            "Batch: 270, Loss: 0.20499537583157554, Accuracy: 0.8943666666666666\n",
            "Batch: 280, Loss: 0.2039605456937967, Accuracy: 0.8948\n",
            "Batch: 290, Loss: 0.20393743239777667, Accuracy: 0.89455\n",
            "Batch: 300, Loss: 0.2038491673477455, Accuracy: 0.8944666666666666\n",
            "Batch: 310, Loss: 0.2041560393587539, Accuracy: 0.8945\n",
            "Batch: 320, Loss: 0.2037766035232886, Accuracy: 0.8944666666666666\n",
            "Batch: 330, Loss: 0.20386759974496962, Accuracy: 0.8947333333333334\n",
            "Batch: 340, Loss: 0.2039781175328834, Accuracy: 0.8951333333333333\n",
            "Batch: 350, Loss: 0.2039769518561769, Accuracy: 0.89475\n",
            "Batch: 360, Loss: 0.20442819556025657, Accuracy: 0.89485\n",
            "Batch: 370, Loss: 0.20357463378000692, Accuracy: 0.8951166666666667\n",
            "Batch: 380, Loss: 0.20350652272743525, Accuracy: 0.8945333333333333\n",
            "Batch: 390, Loss: 0.2036832554516777, Accuracy: 0.8942166666666667\n",
            "Batch: 400, Loss: 0.204569637439901, Accuracy: 0.8936333333333333\n",
            "Batch: 410, Loss: 0.20438446876635163, Accuracy: 0.8946166666666666\n",
            "Batch: 420, Loss: 0.2040351563600496, Accuracy: 0.8949\n",
            "Batch: 430, Loss: 0.20478286755375938, Accuracy: 0.8948\n",
            "Batch: 440, Loss: 0.20493226905896492, Accuracy: 0.8945666666666666\n",
            "Batch: 450, Loss: 0.20457414695289947, Accuracy: 0.8946166666666666\n",
            "Batch: 460, Loss: 0.20450012011920826, Accuracy: 0.89455\n",
            "Batch: 470, Loss: 0.20357491710845887, Accuracy: 0.8944166666666666\n",
            "Batch: 480, Loss: 0.20346874486191105, Accuracy: 0.89505\n",
            "Batch: 490, Loss: 0.20326299974703957, Accuracy: 0.8953333333333333\n",
            "Batch: 500, Loss: 0.203376004649632, Accuracy: 0.8952833333333333\n",
            "Batch: 510, Loss: 0.20347832383170467, Accuracy: 0.89455\n",
            "Batch: 520, Loss: 0.2033873008485626, Accuracy: 0.89495\n",
            "Batch: 530, Loss: 0.2031926793877032, Accuracy: 0.8953\n",
            "Batch: 540, Loss: 0.20304396616933448, Accuracy: 0.8951166666666667\n",
            "Batch: 550, Loss: 0.2035780420650528, Accuracy: 0.8951\n",
            "Batch: 560, Loss: 0.20420896930607052, Accuracy: 0.8948\n",
            "Batch: 570, Loss: 0.20499465236839448, Accuracy: 0.89435\n",
            "Batch: 580, Loss: 0.20438725141148983, Accuracy: 0.89465\n",
            "Batch: 590, Loss: 0.20316376529030364, Accuracy: 0.8955333333333333\n",
            "Batch: 600, Loss: 0.20260313893164741, Accuracy: 0.8956833333333334\n",
            "Batch: 610, Loss: 0.20246611710589735, Accuracy: 0.8958166666666667\n",
            "Batch: 620, Loss: 0.2027219194057923, Accuracy: 0.8955833333333333\n",
            "Batch: 630, Loss: 0.2023879461665878, Accuracy: 0.8957\n",
            "Batch: 640, Loss: 0.20300744402534854, Accuracy: 0.8952833333333333\n",
            "Batch: 650, Loss: 0.2029331596334696, Accuracy: 0.8957333333333334\n",
            "Batch: 660, Loss: 0.20320982273445032, Accuracy: 0.8950833333333333\n",
            "Batch: 670, Loss: 0.20241247066570106, Accuracy: 0.8953833333333333\n",
            "Batch: 680, Loss: 0.20268136644331788, Accuracy: 0.8949\n",
            "Batch: 690, Loss: 0.20382315576535012, Accuracy: 0.8947166666666667\n",
            "Batch: 700, Loss: 0.20377382690626475, Accuracy: 0.89405\n",
            "Batch: 710, Loss: 0.2052163023352642, Accuracy: 0.89365\n",
            "Batch: 720, Loss: 0.2043735440137878, Accuracy: 0.8944166666666666\n",
            "Batch: 730, Loss: 0.20472664696899467, Accuracy: 0.8942666666666667\n",
            "Batch: 740, Loss: 0.20467605899550628, Accuracy: 0.8941166666666667\n",
            "Batch: 750, Loss: 0.20559263531380087, Accuracy: 0.8933833333333333\n",
            "Batch: 760, Loss: 0.20441293935394558, Accuracy: 0.8939\n",
            "Batch: 770, Loss: 0.20413781773375306, Accuracy: 0.8937666666666667\n",
            "Batch: 780, Loss: 0.2054313240415119, Accuracy: 0.8934666666666666\n",
            "Batch: 790, Loss: 0.20463097113535697, Accuracy: 0.8938833333333334\n",
            "Batch: 800, Loss: 0.20443078108314916, Accuracy: 0.8940666666666667\n",
            "Batch: 810, Loss: 0.2042092296350283, Accuracy: 0.8938\n",
            "Batch: 820, Loss: 0.2050410766822614, Accuracy: 0.8932833333333333\n",
            "Batch: 830, Loss: 0.20432865266874262, Accuracy: 0.8936166666666666\n",
            "Batch: 840, Loss: 0.2038483137842547, Accuracy: 0.89415\n",
            "Batch: 850, Loss: 0.20298720123772038, Accuracy: 0.8947\n",
            "Batch: 860, Loss: 0.20407440874823826, Accuracy: 0.8939666666666667\n",
            "Batch: 870, Loss: 0.20325308580417806, Accuracy: 0.8942\n",
            "Batch: 880, Loss: 0.20307901353758356, Accuracy: 0.89465\n",
            "Batch: 890, Loss: 0.2030197871083276, Accuracy: 0.8945833333333333\n",
            "Batch: 900, Loss: 0.20296601698541103, Accuracy: 0.89475\n",
            "Batch: 910, Loss: 0.20243499698289263, Accuracy: 0.89505\n",
            "Batch: 920, Loss: 0.20296922027262876, Accuracy: 0.8946166666666666\n",
            "Batch: 930, Loss: 0.20256096559247466, Accuracy: 0.89495\n",
            "Epoch: 18, Loss: 0.2029263068739963, Accuracy: 0.8945833333333333\n",
            "Batch: 0, Loss: 0.20296360562153312, Accuracy: 0.8945333333333333\n",
            "Batch: 10, Loss: 0.20361423317809382, Accuracy: 0.8944\n",
            "Batch: 20, Loss: 0.202722102066728, Accuracy: 0.8947333333333334\n",
            "Batch: 30, Loss: 0.20276311328801574, Accuracy: 0.89465\n",
            "Batch: 40, Loss: 0.2017758809903936, Accuracy: 0.8952\n",
            "Batch: 50, Loss: 0.2024476358705241, Accuracy: 0.8950166666666667\n",
            "Batch: 60, Loss: 0.20168711202318296, Accuracy: 0.8954833333333333\n",
            "Batch: 70, Loss: 0.2010832252449514, Accuracy: 0.8958666666666667\n",
            "Batch: 80, Loss: 0.2019466589734402, Accuracy: 0.8950833333333333\n",
            "Batch: 90, Loss: 0.2012765007293457, Accuracy: 0.896\n",
            "Batch: 100, Loss: 0.200740776620456, Accuracy: 0.8961333333333333\n",
            "Batch: 110, Loss: 0.20160519426634418, Accuracy: 0.8954833333333333\n",
            "Batch: 120, Loss: 0.20059267238361708, Accuracy: 0.8965166666666666\n",
            "Batch: 130, Loss: 0.20181363501617747, Accuracy: 0.8957833333333334\n",
            "Batch: 140, Loss: 0.20285967773313218, Accuracy: 0.89505\n",
            "Batch: 150, Loss: 0.2012404478249136, Accuracy: 0.8957\n",
            "Batch: 160, Loss: 0.20116066573720182, Accuracy: 0.8955333333333333\n",
            "Batch: 170, Loss: 0.20045370123222714, Accuracy: 0.8962333333333333\n",
            "Batch: 180, Loss: 0.20020540553175686, Accuracy: 0.8965666666666666\n",
            "Batch: 190, Loss: 0.2011635230902509, Accuracy: 0.8960333333333333\n",
            "Batch: 200, Loss: 0.20245553886259351, Accuracy: 0.89505\n",
            "Batch: 210, Loss: 0.20250450501796396, Accuracy: 0.8948666666666667\n",
            "Batch: 220, Loss: 0.20340532072118087, Accuracy: 0.89455\n",
            "Batch: 230, Loss: 0.20166568950322053, Accuracy: 0.8956666666666667\n",
            "Batch: 240, Loss: 0.20192100248811395, Accuracy: 0.8956\n",
            "Batch: 250, Loss: 0.20178793405770523, Accuracy: 0.8958\n",
            "Batch: 260, Loss: 0.20172823239729273, Accuracy: 0.8955666666666666\n",
            "Batch: 270, Loss: 0.20056102932091535, Accuracy: 0.8963333333333333\n",
            "Batch: 280, Loss: 0.19954194661119984, Accuracy: 0.8972166666666667\n",
            "Batch: 290, Loss: 0.1995042451480153, Accuracy: 0.8967333333333334\n",
            "Batch: 300, Loss: 0.1994509981595834, Accuracy: 0.8968\n",
            "Batch: 310, Loss: 0.19989913584284474, Accuracy: 0.8963\n",
            "Batch: 320, Loss: 0.19946574131450173, Accuracy: 0.8968\n",
            "Batch: 330, Loss: 0.19944888099425334, Accuracy: 0.8968\n",
            "Batch: 340, Loss: 0.19961580218718356, Accuracy: 0.8966833333333334\n",
            "Batch: 350, Loss: 0.1995645346463835, Accuracy: 0.8966666666666666\n",
            "Batch: 360, Loss: 0.20000685066993376, Accuracy: 0.8966\n",
            "Batch: 370, Loss: 0.1991521644699933, Accuracy: 0.8969166666666667\n",
            "Batch: 380, Loss: 0.1990633820705501, Accuracy: 0.8968666666666667\n",
            "Batch: 390, Loss: 0.19926652712462672, Accuracy: 0.8964666666666666\n",
            "Batch: 400, Loss: 0.19997218462740243, Accuracy: 0.89605\n",
            "Batch: 410, Loss: 0.19992242805883007, Accuracy: 0.89645\n",
            "Batch: 420, Loss: 0.199508105474988, Accuracy: 0.89665\n",
            "Batch: 430, Loss: 0.20022336165827143, Accuracy: 0.8969333333333334\n",
            "Batch: 440, Loss: 0.20049688281763597, Accuracy: 0.8965333333333333\n",
            "Batch: 450, Loss: 0.2002131721114358, Accuracy: 0.8969\n",
            "Batch: 460, Loss: 0.20007846151168077, Accuracy: 0.8967833333333334\n",
            "Batch: 470, Loss: 0.1991279978652961, Accuracy: 0.8968833333333334\n",
            "Batch: 480, Loss: 0.19907571708717314, Accuracy: 0.8968833333333334\n",
            "Batch: 490, Loss: 0.1988796887570532, Accuracy: 0.89715\n",
            "Batch: 500, Loss: 0.1989469652042284, Accuracy: 0.8972666666666667\n",
            "Batch: 510, Loss: 0.19908434976102118, Accuracy: 0.8964666666666666\n",
            "Batch: 520, Loss: 0.19891088606012858, Accuracy: 0.8970833333333333\n",
            "Batch: 530, Loss: 0.19877545868706015, Accuracy: 0.8968333333333334\n",
            "Batch: 540, Loss: 0.19858709001362504, Accuracy: 0.8972166666666667\n",
            "Batch: 550, Loss: 0.19915510414004287, Accuracy: 0.8971833333333333\n",
            "Batch: 560, Loss: 0.1997056961522934, Accuracy: 0.8971333333333333\n",
            "Batch: 570, Loss: 0.20052296215982243, Accuracy: 0.8965166666666666\n",
            "Batch: 580, Loss: 0.1999632350831726, Accuracy: 0.8969166666666667\n",
            "Batch: 590, Loss: 0.19876194737474867, Accuracy: 0.8973666666666666\n",
            "Batch: 600, Loss: 0.1982271796913425, Accuracy: 0.8976\n",
            "Batch: 610, Loss: 0.19808393521669906, Accuracy: 0.8976\n",
            "Batch: 620, Loss: 0.1983625268214046, Accuracy: 0.8973833333333333\n",
            "Batch: 630, Loss: 0.19799291188207638, Accuracy: 0.89755\n",
            "Batch: 640, Loss: 0.19865439902633408, Accuracy: 0.89745\n",
            "Batch: 650, Loss: 0.19860631039679522, Accuracy: 0.8976333333333333\n",
            "Batch: 660, Loss: 0.19888184276303497, Accuracy: 0.8972\n",
            "Batch: 670, Loss: 0.19796527843409772, Accuracy: 0.8973666666666666\n",
            "Batch: 680, Loss: 0.19821122182940534, Accuracy: 0.8969166666666667\n",
            "Batch: 690, Loss: 0.19949240825503997, Accuracy: 0.8965166666666666\n",
            "Batch: 700, Loss: 0.19964616864179868, Accuracy: 0.89605\n",
            "Batch: 710, Loss: 0.20102394165611895, Accuracy: 0.8955166666666666\n",
            "Batch: 720, Loss: 0.2000589609475555, Accuracy: 0.8962166666666667\n",
            "Batch: 730, Loss: 0.20039167052705004, Accuracy: 0.8962\n",
            "Batch: 740, Loss: 0.20042177954374313, Accuracy: 0.8957666666666667\n",
            "Batch: 750, Loss: 0.20115786130423746, Accuracy: 0.89535\n",
            "Batch: 760, Loss: 0.1999040591442252, Accuracy: 0.89605\n",
            "Batch: 770, Loss: 0.1997668990681226, Accuracy: 0.8959333333333334\n",
            "Batch: 780, Loss: 0.20099867592323747, Accuracy: 0.8955666666666666\n",
            "Batch: 790, Loss: 0.20032402888827638, Accuracy: 0.8958666666666667\n",
            "Batch: 800, Loss: 0.20023065266144005, Accuracy: 0.8957666666666667\n",
            "Batch: 810, Loss: 0.19998057615109485, Accuracy: 0.8956\n",
            "Batch: 820, Loss: 0.20052238628183486, Accuracy: 0.8954833333333333\n",
            "Batch: 830, Loss: 0.19973436379103052, Accuracy: 0.8955666666666666\n",
            "Batch: 840, Loss: 0.1993971065324095, Accuracy: 0.8961666666666667\n",
            "Batch: 850, Loss: 0.19860222245210712, Accuracy: 0.89675\n",
            "Batch: 860, Loss: 0.19966817881506796, Accuracy: 0.8957666666666667\n",
            "Batch: 870, Loss: 0.19892291548396035, Accuracy: 0.8966333333333333\n",
            "Batch: 880, Loss: 0.19860930248441236, Accuracy: 0.8971\n",
            "Batch: 890, Loss: 0.19853507295979284, Accuracy: 0.8968333333333334\n",
            "Batch: 900, Loss: 0.19857365922072598, Accuracy: 0.8967666666666667\n",
            "Batch: 910, Loss: 0.19803872107106532, Accuracy: 0.8971166666666667\n",
            "Batch: 920, Loss: 0.19848368216278714, Accuracy: 0.8967166666666667\n",
            "Batch: 930, Loss: 0.19807817066494735, Accuracy: 0.8971166666666667\n",
            "Epoch: 19, Loss: 0.19838559688486687, Accuracy: 0.8969\n",
            "Batch: 0, Loss: 0.1984054842408965, Accuracy: 0.8967666666666667\n",
            "Batch: 10, Loss: 0.19920299307017508, Accuracy: 0.8963666666666666\n",
            "Batch: 20, Loss: 0.19829491894574253, Accuracy: 0.8969166666666667\n",
            "Batch: 30, Loss: 0.19825664316021316, Accuracy: 0.8966666666666666\n",
            "Batch: 40, Loss: 0.19739116743255725, Accuracy: 0.8975166666666666\n",
            "Batch: 50, Loss: 0.19803962280860632, Accuracy: 0.89695\n",
            "Batch: 60, Loss: 0.19731321700128798, Accuracy: 0.8975666666666666\n",
            "Batch: 70, Loss: 0.19675529086307922, Accuracy: 0.8979833333333334\n",
            "Batch: 80, Loss: 0.19771608555935144, Accuracy: 0.89695\n",
            "Batch: 90, Loss: 0.19702374939804684, Accuracy: 0.8975833333333333\n",
            "Batch: 100, Loss: 0.19650012624144653, Accuracy: 0.8977666666666667\n",
            "Batch: 110, Loss: 0.19736199990836042, Accuracy: 0.8971833333333333\n",
            "Batch: 120, Loss: 0.19620610460265445, Accuracy: 0.8984166666666666\n",
            "Batch: 130, Loss: 0.19757618232784024, Accuracy: 0.8972666666666667\n",
            "Batch: 140, Loss: 0.1987960987554407, Accuracy: 0.8967\n",
            "Batch: 150, Loss: 0.19701297107964963, Accuracy: 0.8976666666666666\n",
            "Batch: 160, Loss: 0.19702765007809264, Accuracy: 0.8972833333333333\n",
            "Batch: 170, Loss: 0.19624956993216006, Accuracy: 0.89805\n",
            "Batch: 180, Loss: 0.1959493294457859, Accuracy: 0.8986\n",
            "Batch: 190, Loss: 0.1969007687650533, Accuracy: 0.8982333333333333\n",
            "Batch: 200, Loss: 0.1982737760130343, Accuracy: 0.8967166666666667\n",
            "Batch: 210, Loss: 0.19827231498163703, Accuracy: 0.89655\n",
            "Batch: 220, Loss: 0.19933494422139222, Accuracy: 0.8963\n",
            "Batch: 230, Loss: 0.19781569891241793, Accuracy: 0.8975833333333333\n",
            "Batch: 240, Loss: 0.19784605554913243, Accuracy: 0.8973166666666667\n",
            "Batch: 250, Loss: 0.19759325736799516, Accuracy: 0.8975\n",
            "Batch: 260, Loss: 0.1974479789317917, Accuracy: 0.8973333333333333\n",
            "Batch: 270, Loss: 0.19626903291103354, Accuracy: 0.8983333333333333\n",
            "Batch: 280, Loss: 0.19546954360598634, Accuracy: 0.8990833333333333\n",
            "Batch: 290, Loss: 0.19533233483870074, Accuracy: 0.8989\n",
            "Batch: 300, Loss: 0.19529612865736065, Accuracy: 0.8988333333333334\n",
            "Batch: 310, Loss: 0.1958639797914384, Accuracy: 0.8985\n",
            "Batch: 320, Loss: 0.19538727436176956, Accuracy: 0.8988833333333334\n",
            "Batch: 330, Loss: 0.19525455851400925, Accuracy: 0.8983833333333333\n",
            "Batch: 340, Loss: 0.1955150074779321, Accuracy: 0.8983166666666667\n",
            "Batch: 350, Loss: 0.19528486616420218, Accuracy: 0.8984666666666666\n",
            "Batch: 360, Loss: 0.19588373023372976, Accuracy: 0.8982833333333333\n",
            "Batch: 370, Loss: 0.19493584100258, Accuracy: 0.8987\n",
            "Batch: 380, Loss: 0.19488607392449775, Accuracy: 0.8987333333333334\n",
            "Batch: 390, Loss: 0.19519016009856519, Accuracy: 0.8983833333333333\n",
            "Batch: 400, Loss: 0.19579587039478347, Accuracy: 0.8980166666666667\n",
            "Batch: 410, Loss: 0.1958385010891192, Accuracy: 0.8979333333333334\n",
            "Batch: 420, Loss: 0.1953058209343217, Accuracy: 0.8984\n",
            "Batch: 430, Loss: 0.1960179101412565, Accuracy: 0.8984333333333333\n",
            "Batch: 440, Loss: 0.19636009337868676, Accuracy: 0.8984166666666666\n",
            "Batch: 450, Loss: 0.1960790776560871, Accuracy: 0.89855\n",
            "Batch: 460, Loss: 0.19591696220078678, Accuracy: 0.8987833333333334\n",
            "Batch: 470, Loss: 0.19504508475614257, Accuracy: 0.89905\n",
            "Batch: 480, Loss: 0.1949430090852462, Accuracy: 0.89915\n",
            "Batch: 490, Loss: 0.19473348793873696, Accuracy: 0.8988833333333334\n",
            "Batch: 500, Loss: 0.19480256359106143, Accuracy: 0.89885\n",
            "Batch: 510, Loss: 0.19498029035522058, Accuracy: 0.8985833333333333\n",
            "Batch: 520, Loss: 0.1946740979745376, Accuracy: 0.8987666666666667\n",
            "Batch: 530, Loss: 0.19459780307237362, Accuracy: 0.8989333333333334\n",
            "Batch: 540, Loss: 0.19439180412696536, Accuracy: 0.89915\n",
            "Batch: 550, Loss: 0.19491781523298685, Accuracy: 0.8989166666666667\n",
            "Batch: 560, Loss: 0.19547233962408117, Accuracy: 0.8987333333333334\n",
            "Batch: 570, Loss: 0.19632586726330947, Accuracy: 0.8982666666666667\n",
            "Batch: 580, Loss: 0.19584145689520044, Accuracy: 0.8987333333333334\n",
            "Batch: 590, Loss: 0.19462641894297714, Accuracy: 0.89915\n",
            "Batch: 600, Loss: 0.1940653860744805, Accuracy: 0.8995666666666666\n",
            "Batch: 610, Loss: 0.19395901130619314, Accuracy: 0.8995166666666666\n",
            "Batch: 620, Loss: 0.19424291723800688, Accuracy: 0.8993833333333333\n",
            "Batch: 630, Loss: 0.19389656976925407, Accuracy: 0.8995\n",
            "Batch: 640, Loss: 0.1945789025111473, Accuracy: 0.8992\n",
            "Batch: 650, Loss: 0.194466813823999, Accuracy: 0.8991666666666667\n",
            "Batch: 660, Loss: 0.19470481614947027, Accuracy: 0.8992666666666667\n",
            "Batch: 670, Loss: 0.19380619221123038, Accuracy: 0.8992\n",
            "Batch: 680, Loss: 0.1940489674426259, Accuracy: 0.8991166666666667\n",
            "Batch: 690, Loss: 0.19533565482495185, Accuracy: 0.8983833333333333\n",
            "Batch: 700, Loss: 0.19552456192880213, Accuracy: 0.8980833333333333\n",
            "Batch: 710, Loss: 0.19677988210959874, Accuracy: 0.89735\n",
            "Batch: 720, Loss: 0.19567722693417838, Accuracy: 0.89785\n",
            "Batch: 730, Loss: 0.19617755589359426, Accuracy: 0.8979166666666667\n",
            "Batch: 740, Loss: 0.1960896901458671, Accuracy: 0.8976166666666666\n",
            "Batch: 750, Loss: 0.1966676659791776, Accuracy: 0.8975166666666666\n",
            "Batch: 760, Loss: 0.1954098754299714, Accuracy: 0.8979166666666667\n",
            "Batch: 770, Loss: 0.19536346329573606, Accuracy: 0.8982166666666667\n",
            "Batch: 780, Loss: 0.19657866697158347, Accuracy: 0.8974833333333333\n",
            "Batch: 790, Loss: 0.19599111496198238, Accuracy: 0.8976333333333333\n",
            "Batch: 800, Loss: 0.19615967506897233, Accuracy: 0.8975666666666666\n",
            "Batch: 810, Loss: 0.19588347293582098, Accuracy: 0.89745\n",
            "Batch: 820, Loss: 0.19620630088418634, Accuracy: 0.8972666666666667\n",
            "Batch: 830, Loss: 0.1953730848738856, Accuracy: 0.8978333333333334\n",
            "Batch: 840, Loss: 0.19502686890160092, Accuracy: 0.898\n",
            "Batch: 850, Loss: 0.19432596368447283, Accuracy: 0.8985\n",
            "Batch: 860, Loss: 0.19541585263281275, Accuracy: 0.8977666666666667\n",
            "Batch: 870, Loss: 0.19479214649971935, Accuracy: 0.8983833333333333\n",
            "Batch: 880, Loss: 0.19443159118068387, Accuracy: 0.8986666666666666\n",
            "Batch: 890, Loss: 0.1943101767886812, Accuracy: 0.8985166666666666\n",
            "Batch: 900, Loss: 0.1944459687010353, Accuracy: 0.8986\n",
            "Batch: 910, Loss: 0.19385730908456947, Accuracy: 0.8988666666666667\n",
            "Batch: 920, Loss: 0.19413414220188377, Accuracy: 0.899\n",
            "Batch: 930, Loss: 0.19386490256997813, Accuracy: 0.8990833333333333\n",
            "Epoch: 20, Loss: 0.1941459490632771, Accuracy: 0.8988166666666667\n",
            "Batch: 0, Loss: 0.19416639959342352, Accuracy: 0.8987166666666667\n",
            "Batch: 10, Loss: 0.1950385588313518, Accuracy: 0.8983166666666667\n",
            "Batch: 20, Loss: 0.19436486378028076, Accuracy: 0.89865\n",
            "Batch: 30, Loss: 0.1942185739853159, Accuracy: 0.89875\n",
            "Batch: 40, Loss: 0.19341323051273226, Accuracy: 0.8993\n",
            "Batch: 50, Loss: 0.1939536436352379, Accuracy: 0.89905\n",
            "Batch: 60, Loss: 0.19326854563866885, Accuracy: 0.8994333333333333\n",
            "Batch: 70, Loss: 0.19274962194937842, Accuracy: 0.8996833333333333\n",
            "Batch: 80, Loss: 0.1934912091988637, Accuracy: 0.8987833333333334\n",
            "Batch: 90, Loss: 0.192916615947878, Accuracy: 0.8994833333333333\n",
            "Batch: 100, Loss: 0.19247708392863844, Accuracy: 0.8991333333333333\n",
            "Batch: 110, Loss: 0.19340603626751876, Accuracy: 0.8988\n",
            "Batch: 120, Loss: 0.1921949249101611, Accuracy: 0.9000166666666667\n",
            "Batch: 130, Loss: 0.1937002627274722, Accuracy: 0.8986833333333333\n",
            "Batch: 140, Loss: 0.19510892229401314, Accuracy: 0.8985333333333333\n",
            "Batch: 150, Loss: 0.19309858355655862, Accuracy: 0.8994666666666666\n",
            "Batch: 160, Loss: 0.19315980977425445, Accuracy: 0.8989333333333334\n",
            "Batch: 170, Loss: 0.19217951491692767, Accuracy: 0.8998\n",
            "Batch: 180, Loss: 0.19200415381568423, Accuracy: 0.9000333333333334\n",
            "Batch: 190, Loss: 0.1929970926189934, Accuracy: 0.8999\n",
            "Batch: 200, Loss: 0.1943959096981434, Accuracy: 0.8984333333333333\n",
            "Batch: 210, Loss: 0.19432675709396124, Accuracy: 0.8985333333333333\n",
            "Batch: 220, Loss: 0.19539559403562573, Accuracy: 0.8983333333333333\n",
            "Batch: 230, Loss: 0.1940349111050697, Accuracy: 0.8990666666666667\n",
            "Batch: 240, Loss: 0.19394264425080468, Accuracy: 0.8992833333333333\n",
            "Batch: 250, Loss: 0.19359010469494656, Accuracy: 0.8996666666666666\n",
            "Batch: 260, Loss: 0.1933718891851349, Accuracy: 0.8993333333333333\n",
            "Batch: 270, Loss: 0.19228882555918758, Accuracy: 0.9002166666666667\n",
            "Batch: 280, Loss: 0.19157166946406506, Accuracy: 0.90085\n",
            "Batch: 290, Loss: 0.1913785281289882, Accuracy: 0.9006666666666666\n",
            "Batch: 300, Loss: 0.19133512364281494, Accuracy: 0.90055\n",
            "Batch: 310, Loss: 0.192115429823753, Accuracy: 0.9001833333333333\n",
            "Batch: 320, Loss: 0.19151692127461428, Accuracy: 0.9006\n",
            "Batch: 330, Loss: 0.1913982708367352, Accuracy: 0.9001666666666667\n",
            "Batch: 340, Loss: 0.19177897785579232, Accuracy: 0.9003333333333333\n",
            "Batch: 350, Loss: 0.19143061461511365, Accuracy: 0.9002833333333333\n",
            "Batch: 360, Loss: 0.19196614959678174, Accuracy: 0.8999666666666667\n",
            "Batch: 370, Loss: 0.19104121325118778, Accuracy: 0.9004666666666666\n",
            "Batch: 380, Loss: 0.19094034354613565, Accuracy: 0.9003666666666666\n",
            "Batch: 390, Loss: 0.19121931145047377, Accuracy: 0.9002166666666667\n",
            "Batch: 400, Loss: 0.19184412890796992, Accuracy: 0.8996333333333333\n",
            "Batch: 410, Loss: 0.19192017954430407, Accuracy: 0.89965\n",
            "Batch: 420, Loss: 0.1913746607691106, Accuracy: 0.9004666666666666\n",
            "Batch: 430, Loss: 0.1920245035198912, Accuracy: 0.9003666666666666\n",
            "Batch: 440, Loss: 0.19246555617356384, Accuracy: 0.9005333333333333\n",
            "Batch: 450, Loss: 0.19216837616959095, Accuracy: 0.9002333333333333\n",
            "Batch: 460, Loss: 0.19202296344888456, Accuracy: 0.9004333333333333\n",
            "Batch: 470, Loss: 0.1912864025458447, Accuracy: 0.9004\n",
            "Batch: 480, Loss: 0.1910848526717497, Accuracy: 0.9006666666666666\n",
            "Batch: 490, Loss: 0.19085635030838075, Accuracy: 0.9005666666666666\n",
            "Batch: 500, Loss: 0.190916769935157, Accuracy: 0.9004166666666666\n",
            "Batch: 510, Loss: 0.19104314837255007, Accuracy: 0.9002833333333333\n",
            "Batch: 520, Loss: 0.1906880964840705, Accuracy: 0.9006166666666666\n",
            "Batch: 530, Loss: 0.190672016745668, Accuracy: 0.9006333333333333\n",
            "Batch: 540, Loss: 0.19049236981186055, Accuracy: 0.90065\n",
            "Batch: 550, Loss: 0.1908728689729296, Accuracy: 0.9004666666666666\n",
            "Batch: 560, Loss: 0.191443061583707, Accuracy: 0.9003833333333333\n",
            "Batch: 570, Loss: 0.19218995942611103, Accuracy: 0.8999666666666667\n",
            "Batch: 580, Loss: 0.19177856991338998, Accuracy: 0.9002\n",
            "Batch: 590, Loss: 0.19070837738559882, Accuracy: 0.9007166666666667\n",
            "Batch: 600, Loss: 0.19015415421272142, Accuracy: 0.9010166666666667\n",
            "Batch: 610, Loss: 0.19010583994303223, Accuracy: 0.9011166666666667\n",
            "Batch: 620, Loss: 0.19045245831825464, Accuracy: 0.90085\n",
            "Batch: 630, Loss: 0.19009549599079875, Accuracy: 0.9011\n",
            "Batch: 640, Loss: 0.19085483123581798, Accuracy: 0.9007166666666667\n",
            "Batch: 650, Loss: 0.19060845525163755, Accuracy: 0.90075\n",
            "Batch: 660, Loss: 0.19063065552282246, Accuracy: 0.9008666666666667\n",
            "Batch: 670, Loss: 0.18994631223938066, Accuracy: 0.9008\n",
            "Batch: 680, Loss: 0.19019111075082537, Accuracy: 0.90065\n",
            "Batch: 690, Loss: 0.19137492778193893, Accuracy: 0.9001833333333333\n",
            "Batch: 700, Loss: 0.19150165953190923, Accuracy: 0.9000333333333334\n",
            "Batch: 710, Loss: 0.19272858129072082, Accuracy: 0.8995166666666666\n",
            "Batch: 720, Loss: 0.1915494948682996, Accuracy: 0.8999333333333334\n",
            "Batch: 730, Loss: 0.19222394749285487, Accuracy: 0.89945\n",
            "Batch: 740, Loss: 0.19210165606809268, Accuracy: 0.8995833333333333\n",
            "Batch: 750, Loss: 0.19267659025093328, Accuracy: 0.8989666666666667\n",
            "Batch: 760, Loss: 0.19132472544697338, Accuracy: 0.8997\n",
            "Batch: 770, Loss: 0.19140455555895944, Accuracy: 0.89995\n",
            "Batch: 780, Loss: 0.19273531852286566, Accuracy: 0.8992666666666667\n",
            "Batch: 790, Loss: 0.19217391211117438, Accuracy: 0.8992666666666667\n",
            "Batch: 800, Loss: 0.19233187892025141, Accuracy: 0.8993166666666667\n",
            "Batch: 810, Loss: 0.1920843454149966, Accuracy: 0.89955\n",
            "Batch: 820, Loss: 0.1922606518464357, Accuracy: 0.8992333333333333\n",
            "Batch: 830, Loss: 0.19139279187717076, Accuracy: 0.89965\n",
            "Batch: 840, Loss: 0.19091010758444624, Accuracy: 0.8999\n",
            "Batch: 850, Loss: 0.1902867455489745, Accuracy: 0.9003333333333333\n",
            "Batch: 860, Loss: 0.1914889678017752, Accuracy: 0.8997833333333334\n",
            "Batch: 870, Loss: 0.19091067403774045, Accuracy: 0.9001833333333333\n",
            "Batch: 880, Loss: 0.19052993495592424, Accuracy: 0.9001166666666667\n",
            "Batch: 890, Loss: 0.19038801644835868, Accuracy: 0.9002666666666667\n",
            "Batch: 900, Loss: 0.19053826372906205, Accuracy: 0.9003333333333333\n",
            "Batch: 910, Loss: 0.189872916699547, Accuracy: 0.9007166666666667\n",
            "Batch: 920, Loss: 0.1900291314156043, Accuracy: 0.9006166666666666\n",
            "Batch: 930, Loss: 0.18992320002537405, Accuracy: 0.9007666666666667\n",
            "Epoch: 21, Loss: 0.1902028602617932, Accuracy: 0.9005666666666666\n",
            "Batch: 0, Loss: 0.19020404986209047, Accuracy: 0.9005\n",
            "Batch: 10, Loss: 0.19118214899412853, Accuracy: 0.8996333333333333\n",
            "Batch: 20, Loss: 0.19058536433470272, Accuracy: 0.90015\n",
            "Batch: 30, Loss: 0.1902978817074133, Accuracy: 0.9004666666666666\n",
            "Batch: 40, Loss: 0.18956128953329487, Accuracy: 0.9011666666666667\n",
            "Batch: 50, Loss: 0.19009857375770464, Accuracy: 0.9008166666666667\n",
            "Batch: 60, Loss: 0.1893542846869786, Accuracy: 0.9010166666666667\n",
            "Batch: 70, Loss: 0.18889677819928066, Accuracy: 0.90135\n",
            "Batch: 80, Loss: 0.18951303722213514, Accuracy: 0.9005833333333333\n",
            "Batch: 90, Loss: 0.18901220263894122, Accuracy: 0.9010333333333334\n",
            "Batch: 100, Loss: 0.18864502196208813, Accuracy: 0.901\n",
            "Batch: 110, Loss: 0.1896733577367381, Accuracy: 0.9004333333333333\n",
            "Batch: 120, Loss: 0.18847398767255424, Accuracy: 0.9011666666666667\n",
            "Batch: 130, Loss: 0.19002043382828115, Accuracy: 0.9003166666666667\n",
            "Batch: 140, Loss: 0.19144289730467856, Accuracy: 0.8999666666666667\n",
            "Batch: 150, Loss: 0.18942665199212474, Accuracy: 0.9008166666666667\n",
            "Batch: 160, Loss: 0.18962840717962784, Accuracy: 0.9007833333333334\n",
            "Batch: 170, Loss: 0.18854300415259964, Accuracy: 0.9015\n",
            "Batch: 180, Loss: 0.18837363050328157, Accuracy: 0.9015666666666666\n",
            "Batch: 190, Loss: 0.18934561845855308, Accuracy: 0.9013833333333333\n",
            "Batch: 200, Loss: 0.19069894485929734, Accuracy: 0.8998166666666667\n",
            "Batch: 210, Loss: 0.1907158619032343, Accuracy: 0.9005166666666666\n",
            "Batch: 220, Loss: 0.19176047987501532, Accuracy: 0.9001166666666667\n",
            "Batch: 230, Loss: 0.19048812114579183, Accuracy: 0.9007166666666667\n",
            "Batch: 240, Loss: 0.19025878933447543, Accuracy: 0.9011\n",
            "Batch: 250, Loss: 0.18994841603834364, Accuracy: 0.9013666666666666\n",
            "Batch: 260, Loss: 0.18964505607501955, Accuracy: 0.9011\n",
            "Batch: 270, Loss: 0.18853919492814455, Accuracy: 0.90195\n",
            "Batch: 280, Loss: 0.18794000827035953, Accuracy: 0.9021833333333333\n",
            "Batch: 290, Loss: 0.18771501760492448, Accuracy: 0.9018666666666667\n",
            "Batch: 300, Loss: 0.18769990572876824, Accuracy: 0.9022666666666667\n",
            "Batch: 310, Loss: 0.1884621724544424, Accuracy: 0.9017333333333334\n",
            "Batch: 320, Loss: 0.18786678812224708, Accuracy: 0.9022666666666667\n",
            "Batch: 330, Loss: 0.18779426720853062, Accuracy: 0.9018333333333334\n",
            "Batch: 340, Loss: 0.18830306454179238, Accuracy: 0.9017333333333334\n",
            "Batch: 350, Loss: 0.18784412449240068, Accuracy: 0.9019833333333334\n",
            "Batch: 360, Loss: 0.18833319124827672, Accuracy: 0.9017333333333334\n",
            "Batch: 370, Loss: 0.18736322435934702, Accuracy: 0.90225\n",
            "Batch: 380, Loss: 0.1872194494765264, Accuracy: 0.9023166666666667\n",
            "Batch: 390, Loss: 0.18751221852141117, Accuracy: 0.9019333333333334\n",
            "Batch: 400, Loss: 0.18801825336440145, Accuracy: 0.90135\n",
            "Batch: 410, Loss: 0.1881699006263683, Accuracy: 0.9017166666666667\n",
            "Batch: 420, Loss: 0.18770249027833402, Accuracy: 0.902\n",
            "Batch: 430, Loss: 0.1882315158013289, Accuracy: 0.9019333333333334\n",
            "Batch: 440, Loss: 0.18873912384236627, Accuracy: 0.9018\n",
            "Batch: 450, Loss: 0.18847277491647094, Accuracy: 0.9017833333333334\n",
            "Batch: 460, Loss: 0.1882941622267449, Accuracy: 0.9018166666666667\n",
            "Batch: 470, Loss: 0.18769796032779767, Accuracy: 0.9023166666666667\n",
            "Batch: 480, Loss: 0.18740487250575727, Accuracy: 0.90215\n",
            "Batch: 490, Loss: 0.18718800964419002, Accuracy: 0.9023333333333333\n",
            "Batch: 500, Loss: 0.18731054797090804, Accuracy: 0.9017\n",
            "Batch: 510, Loss: 0.1872377200069692, Accuracy: 0.9020833333333333\n",
            "Batch: 520, Loss: 0.18690711215095265, Accuracy: 0.9023333333333333\n",
            "Batch: 530, Loss: 0.18692963104381347, Accuracy: 0.9022\n",
            "Batch: 540, Loss: 0.1867623581079772, Accuracy: 0.9020833333333333\n",
            "Batch: 550, Loss: 0.18708620723487698, Accuracy: 0.9020666666666667\n",
            "Batch: 560, Loss: 0.18759602787825225, Accuracy: 0.90195\n",
            "Batch: 570, Loss: 0.1882536922121404, Accuracy: 0.9018333333333334\n",
            "Batch: 580, Loss: 0.18792133063818597, Accuracy: 0.90195\n",
            "Batch: 590, Loss: 0.18699374072491803, Accuracy: 0.9020666666666667\n",
            "Batch: 600, Loss: 0.186420584958359, Accuracy: 0.9026\n",
            "Batch: 610, Loss: 0.18646300641184513, Accuracy: 0.9025833333333333\n",
            "Batch: 620, Loss: 0.18681406182431537, Accuracy: 0.9025833333333333\n",
            "Batch: 630, Loss: 0.18649669200191601, Accuracy: 0.9024166666666666\n",
            "Batch: 640, Loss: 0.18730000168616445, Accuracy: 0.9023\n",
            "Batch: 650, Loss: 0.18689169265016872, Accuracy: 0.9022\n",
            "Batch: 660, Loss: 0.18691285299023758, Accuracy: 0.9024333333333333\n",
            "Batch: 670, Loss: 0.18637293337722488, Accuracy: 0.9022166666666667\n",
            "Batch: 680, Loss: 0.1866064453531865, Accuracy: 0.9020333333333334\n",
            "Batch: 690, Loss: 0.1877668434369308, Accuracy: 0.9017\n",
            "Batch: 700, Loss: 0.18777015081938214, Accuracy: 0.9019833333333334\n",
            "Batch: 710, Loss: 0.18914399358934172, Accuracy: 0.9009833333333334\n",
            "Batch: 720, Loss: 0.18800244566248267, Accuracy: 0.9014833333333333\n",
            "Batch: 730, Loss: 0.18873028893092197, Accuracy: 0.9009166666666667\n",
            "Batch: 740, Loss: 0.18831878813641884, Accuracy: 0.9012\n",
            "Batch: 750, Loss: 0.18893358565268714, Accuracy: 0.90075\n",
            "Batch: 760, Loss: 0.187559672819314, Accuracy: 0.9015833333333333\n",
            "Batch: 770, Loss: 0.18779483159877486, Accuracy: 0.9011\n",
            "Batch: 780, Loss: 0.18920996203310902, Accuracy: 0.9005333333333333\n",
            "Batch: 790, Loss: 0.18857789187514884, Accuracy: 0.9006333333333333\n",
            "Batch: 800, Loss: 0.1888586895435112, Accuracy: 0.9009666666666667\n",
            "Batch: 810, Loss: 0.18874394873482797, Accuracy: 0.9012\n",
            "Batch: 820, Loss: 0.1888227048391066, Accuracy: 0.90065\n",
            "Batch: 830, Loss: 0.18781873769212384, Accuracy: 0.9011\n",
            "Batch: 840, Loss: 0.18727018989257643, Accuracy: 0.9018\n",
            "Batch: 850, Loss: 0.18662109983462827, Accuracy: 0.9018\n",
            "Batch: 860, Loss: 0.18779515677957656, Accuracy: 0.9012833333333333\n",
            "Batch: 870, Loss: 0.1873088332094006, Accuracy: 0.9016\n",
            "Batch: 880, Loss: 0.1869614826674388, Accuracy: 0.9016333333333333\n",
            "Batch: 890, Loss: 0.18679650559191177, Accuracy: 0.9016666666666666\n",
            "Batch: 900, Loss: 0.18697661980114796, Accuracy: 0.9014666666666666\n",
            "Batch: 910, Loss: 0.18623802490915878, Accuracy: 0.9023666666666667\n",
            "Batch: 920, Loss: 0.18638833325132628, Accuracy: 0.9023\n",
            "Batch: 930, Loss: 0.18632882846311355, Accuracy: 0.9021666666666667\n",
            "Epoch: 22, Loss: 0.18664032728116084, Accuracy: 0.9022166666666667\n",
            "Batch: 0, Loss: 0.18663404749669882, Accuracy: 0.902\n",
            "Batch: 10, Loss: 0.18777393859819955, Accuracy: 0.9014166666666666\n",
            "Batch: 20, Loss: 0.1870987196744887, Accuracy: 0.9015166666666666\n",
            "Batch: 30, Loss: 0.1866630888799627, Accuracy: 0.902\n",
            "Batch: 40, Loss: 0.18599136619947862, Accuracy: 0.9025666666666666\n",
            "Batch: 50, Loss: 0.18653640896093066, Accuracy: 0.9023666666666667\n",
            "Batch: 60, Loss: 0.1857014888295986, Accuracy: 0.9026833333333333\n",
            "Batch: 70, Loss: 0.18529485007117882, Accuracy: 0.9028833333333334\n",
            "Batch: 80, Loss: 0.18585324809212506, Accuracy: 0.9022666666666667\n",
            "Batch: 90, Loss: 0.18537826607863975, Accuracy: 0.90255\n",
            "Batch: 100, Loss: 0.18507368749631897, Accuracy: 0.9025666666666666\n",
            "Batch: 110, Loss: 0.1861465683464079, Accuracy: 0.9021833333333333\n",
            "Batch: 120, Loss: 0.18508514505690535, Accuracy: 0.9024833333333333\n",
            "Batch: 130, Loss: 0.1865664354766724, Accuracy: 0.9016833333333333\n",
            "Batch: 140, Loss: 0.18787909559605445, Accuracy: 0.9015666666666666\n",
            "Batch: 150, Loss: 0.18602686408734315, Accuracy: 0.9021833333333333\n",
            "Batch: 160, Loss: 0.1863719616152722, Accuracy: 0.9025\n",
            "Batch: 170, Loss: 0.18511336283509605, Accuracy: 0.9029\n",
            "Batch: 180, Loss: 0.18500052465543407, Accuracy: 0.9030666666666667\n",
            "Batch: 190, Loss: 0.18591908726065298, Accuracy: 0.9029666666666667\n",
            "Batch: 200, Loss: 0.18713767293362837, Accuracy: 0.90185\n",
            "Batch: 210, Loss: 0.18721511671483723, Accuracy: 0.9020333333333334\n",
            "Batch: 220, Loss: 0.18831192673417677, Accuracy: 0.9015\n",
            "Batch: 230, Loss: 0.18728370633619468, Accuracy: 0.9024166666666666\n",
            "Batch: 240, Loss: 0.18703254814494166, Accuracy: 0.9025833333333333\n",
            "Batch: 250, Loss: 0.18668457998637347, Accuracy: 0.9027833333333334\n",
            "Batch: 260, Loss: 0.1863143804489263, Accuracy: 0.9033333333333333\n",
            "Batch: 270, Loss: 0.18515560637993975, Accuracy: 0.9035333333333333\n",
            "Batch: 280, Loss: 0.18451282696330842, Accuracy: 0.9037333333333334\n",
            "Batch: 290, Loss: 0.1842732400767815, Accuracy: 0.9035333333333333\n",
            "Batch: 300, Loss: 0.18422502582637448, Accuracy: 0.9038666666666667\n",
            "Batch: 310, Loss: 0.18496060822853969, Accuracy: 0.9032333333333333\n",
            "Batch: 320, Loss: 0.1843670945466431, Accuracy: 0.9040666666666667\n",
            "Batch: 330, Loss: 0.18428613720177411, Accuracy: 0.9034833333333333\n",
            "Batch: 340, Loss: 0.18491503762942457, Accuracy: 0.9031\n",
            "Batch: 350, Loss: 0.1844214329281939, Accuracy: 0.9036333333333333\n",
            "Batch: 360, Loss: 0.18484338895685345, Accuracy: 0.90325\n",
            "Batch: 370, Loss: 0.1838691796992708, Accuracy: 0.90345\n",
            "Batch: 380, Loss: 0.18375349450604492, Accuracy: 0.9036333333333333\n",
            "Batch: 390, Loss: 0.18396834218619013, Accuracy: 0.9036333333333333\n",
            "Batch: 400, Loss: 0.1844341991914452, Accuracy: 0.9029333333333334\n",
            "Batch: 410, Loss: 0.18453720687209488, Accuracy: 0.9034166666666666\n",
            "Batch: 420, Loss: 0.18404723817782928, Accuracy: 0.9036166666666666\n",
            "Batch: 430, Loss: 0.18451889037549463, Accuracy: 0.9034666666666666\n",
            "Batch: 440, Loss: 0.18496184592008025, Accuracy: 0.9033\n",
            "Batch: 450, Loss: 0.18484436803381515, Accuracy: 0.90325\n",
            "Batch: 460, Loss: 0.1846997173450563, Accuracy: 0.9033833333333333\n",
            "Batch: 470, Loss: 0.18415928362580947, Accuracy: 0.9040333333333334\n",
            "Batch: 480, Loss: 0.18387952961068924, Accuracy: 0.9037333333333334\n",
            "Batch: 490, Loss: 0.18360688993524077, Accuracy: 0.90395\n",
            "Batch: 500, Loss: 0.18377308627724395, Accuracy: 0.9033333333333333\n",
            "Batch: 510, Loss: 0.18363494928741916, Accuracy: 0.9035333333333333\n",
            "Batch: 520, Loss: 0.1833203810172233, Accuracy: 0.9035666666666666\n",
            "Batch: 530, Loss: 0.18335992099797976, Accuracy: 0.9037333333333334\n",
            "Batch: 540, Loss: 0.18316227933574136, Accuracy: 0.90345\n",
            "Batch: 550, Loss: 0.18351775534186904, Accuracy: 0.9039666666666667\n",
            "Batch: 560, Loss: 0.18402645944792442, Accuracy: 0.9038333333333334\n",
            "Batch: 570, Loss: 0.18463599221703444, Accuracy: 0.9036166666666666\n",
            "Batch: 580, Loss: 0.18434425663824464, Accuracy: 0.9038666666666667\n",
            "Batch: 590, Loss: 0.1834326535865851, Accuracy: 0.90375\n",
            "Batch: 600, Loss: 0.18284075344810416, Accuracy: 0.9040166666666667\n",
            "Batch: 610, Loss: 0.18295109637551474, Accuracy: 0.9038333333333334\n",
            "Batch: 620, Loss: 0.18331134685103317, Accuracy: 0.90415\n",
            "Batch: 630, Loss: 0.18302941168185846, Accuracy: 0.9039833333333334\n",
            "Batch: 640, Loss: 0.1839609865715923, Accuracy: 0.90375\n",
            "Batch: 650, Loss: 0.18334614279454947, Accuracy: 0.90365\n",
            "Batch: 660, Loss: 0.18341810422608915, Accuracy: 0.9041\n",
            "Batch: 670, Loss: 0.18291372353450566, Accuracy: 0.90375\n",
            "Batch: 680, Loss: 0.18318094747700076, Accuracy: 0.9035166666666666\n",
            "Batch: 690, Loss: 0.18438713400513135, Accuracy: 0.9032\n",
            "Batch: 700, Loss: 0.18431683726205084, Accuracy: 0.9035666666666666\n",
            "Batch: 710, Loss: 0.1857619389731102, Accuracy: 0.9022833333333333\n",
            "Batch: 720, Loss: 0.18453017051969434, Accuracy: 0.9029166666666667\n",
            "Batch: 730, Loss: 0.18535458616597722, Accuracy: 0.9023833333333333\n",
            "Batch: 740, Loss: 0.18499031127197382, Accuracy: 0.9027\n",
            "Batch: 750, Loss: 0.18560105896748377, Accuracy: 0.902\n",
            "Batch: 760, Loss: 0.1841691657879792, Accuracy: 0.9027666666666667\n",
            "Batch: 770, Loss: 0.18442461913062036, Accuracy: 0.9025166666666666\n",
            "Batch: 780, Loss: 0.18590578947702877, Accuracy: 0.9018333333333334\n",
            "Batch: 790, Loss: 0.18522167173668538, Accuracy: 0.9021666666666667\n",
            "Batch: 800, Loss: 0.18557690489154077, Accuracy: 0.90255\n",
            "Batch: 810, Loss: 0.18556639286349233, Accuracy: 0.9022\n",
            "Batch: 820, Loss: 0.18560125221283955, Accuracy: 0.9020333333333334\n",
            "Batch: 830, Loss: 0.1843799491669392, Accuracy: 0.9024333333333333\n",
            "Batch: 840, Loss: 0.18385338748392369, Accuracy: 0.9031\n",
            "Batch: 850, Loss: 0.1831741210140749, Accuracy: 0.9031666666666667\n",
            "Batch: 860, Loss: 0.18431159562483546, Accuracy: 0.9025666666666666\n",
            "Batch: 870, Loss: 0.1839147245792096, Accuracy: 0.90295\n",
            "Batch: 880, Loss: 0.18357552363578097, Accuracy: 0.903\n",
            "Batch: 890, Loss: 0.18342731951739044, Accuracy: 0.9032833333333333\n",
            "Batch: 900, Loss: 0.18363352369086555, Accuracy: 0.90295\n",
            "Batch: 910, Loss: 0.18288712261810644, Accuracy: 0.9035333333333333\n",
            "Batch: 920, Loss: 0.18303496386256984, Accuracy: 0.9035\n",
            "Batch: 930, Loss: 0.1831375035535231, Accuracy: 0.9035666666666666\n",
            "Epoch: 23, Loss: 0.1834742364404048, Accuracy: 0.9031666666666667\n",
            "Batch: 0, Loss: 0.18345338271589096, Accuracy: 0.9032333333333333\n",
            "Batch: 10, Loss: 0.18472652547683954, Accuracy: 0.90255\n",
            "Batch: 20, Loss: 0.1839895852678176, Accuracy: 0.9031666666666667\n",
            "Batch: 30, Loss: 0.18338931646885862, Accuracy: 0.9032833333333333\n",
            "Batch: 40, Loss: 0.18273184519413305, Accuracy: 0.90415\n",
            "Batch: 50, Loss: 0.18319311510812383, Accuracy: 0.90385\n",
            "Batch: 60, Loss: 0.1823047304641618, Accuracy: 0.90435\n",
            "Batch: 70, Loss: 0.18197259207282646, Accuracy: 0.9042\n",
            "Batch: 80, Loss: 0.18248024084158526, Accuracy: 0.9037166666666666\n",
            "Batch: 90, Loss: 0.18197637924512042, Accuracy: 0.9040666666666667\n",
            "Batch: 100, Loss: 0.18173415451414016, Accuracy: 0.9039666666666667\n",
            "Batch: 110, Loss: 0.18284519988426332, Accuracy: 0.9034666666666666\n",
            "Batch: 120, Loss: 0.1818446144578677, Accuracy: 0.90395\n",
            "Batch: 130, Loss: 0.1832605886262613, Accuracy: 0.9033333333333333\n",
            "Batch: 140, Loss: 0.18455125599809247, Accuracy: 0.9029\n",
            "Batch: 150, Loss: 0.18279877062154737, Accuracy: 0.9035333333333333\n",
            "Batch: 160, Loss: 0.18323556581308373, Accuracy: 0.9039166666666667\n",
            "Batch: 170, Loss: 0.1818369999348331, Accuracy: 0.9042\n",
            "Batch: 180, Loss: 0.18181849141114215, Accuracy: 0.90445\n",
            "Batch: 190, Loss: 0.18270774252212918, Accuracy: 0.90425\n",
            "Batch: 200, Loss: 0.18382325946883823, Accuracy: 0.9032\n",
            "Batch: 210, Loss: 0.18392602692419782, Accuracy: 0.9034\n",
            "Batch: 220, Loss: 0.1850237177286897, Accuracy: 0.9031833333333333\n",
            "Batch: 230, Loss: 0.1840844828002595, Accuracy: 0.9035\n",
            "Batch: 240, Loss: 0.18386954568500544, Accuracy: 0.9038666666666667\n",
            "Batch: 250, Loss: 0.18342798092351326, Accuracy: 0.9040833333333333\n",
            "Batch: 260, Loss: 0.18314879035232096, Accuracy: 0.9044666666666666\n",
            "Batch: 270, Loss: 0.1819066326445362, Accuracy: 0.90485\n",
            "Batch: 280, Loss: 0.18114238424895848, Accuracy: 0.9051333333333333\n",
            "Batch: 290, Loss: 0.18097147528016125, Accuracy: 0.90515\n",
            "Batch: 300, Loss: 0.18088330955991178, Accuracy: 0.9052\n",
            "Batch: 310, Loss: 0.181602785463662, Accuracy: 0.9049\n",
            "Batch: 320, Loss: 0.1810088858277356, Accuracy: 0.9050833333333334\n",
            "Batch: 330, Loss: 0.18088039938426803, Accuracy: 0.90485\n",
            "Batch: 340, Loss: 0.18155009892414367, Accuracy: 0.90455\n",
            "Batch: 350, Loss: 0.18108069222645165, Accuracy: 0.90475\n",
            "Batch: 360, Loss: 0.1815121286330012, Accuracy: 0.9047166666666666\n",
            "Batch: 370, Loss: 0.18053117897490778, Accuracy: 0.9048833333333334\n",
            "Batch: 380, Loss: 0.18039136002029846, Accuracy: 0.9051166666666667\n",
            "Batch: 390, Loss: 0.18055210372993954, Accuracy: 0.9052\n",
            "Batch: 400, Loss: 0.18103219325255546, Accuracy: 0.9043333333333333\n",
            "Batch: 410, Loss: 0.18103661810499982, Accuracy: 0.9046333333333333\n",
            "Batch: 420, Loss: 0.1805280850678047, Accuracy: 0.9050666666666667\n",
            "Batch: 430, Loss: 0.18103315139990633, Accuracy: 0.9047333333333333\n",
            "Batch: 440, Loss: 0.18140263650221436, Accuracy: 0.9048\n",
            "Batch: 450, Loss: 0.18133734220032421, Accuracy: 0.9047666666666667\n",
            "Batch: 460, Loss: 0.18124212430198774, Accuracy: 0.9048333333333334\n",
            "Batch: 470, Loss: 0.18067037754774054, Accuracy: 0.9056166666666666\n",
            "Batch: 480, Loss: 0.18056242716389784, Accuracy: 0.90545\n",
            "Batch: 490, Loss: 0.18026476959635607, Accuracy: 0.9053833333333333\n",
            "Batch: 500, Loss: 0.18038308152436028, Accuracy: 0.9048\n",
            "Batch: 510, Loss: 0.18024601304191354, Accuracy: 0.9052166666666667\n",
            "Batch: 520, Loss: 0.1799303737142068, Accuracy: 0.9051\n",
            "Batch: 530, Loss: 0.1799736393664556, Accuracy: 0.9047333333333333\n",
            "Batch: 540, Loss: 0.17979849881228593, Accuracy: 0.9049333333333334\n",
            "Batch: 550, Loss: 0.18016314129846459, Accuracy: 0.9053166666666667\n",
            "Batch: 560, Loss: 0.18070338804818656, Accuracy: 0.9051833333333333\n",
            "Batch: 570, Loss: 0.1812533108122348, Accuracy: 0.9048666666666667\n",
            "Batch: 580, Loss: 0.18107158670040044, Accuracy: 0.9051333333333333\n",
            "Batch: 590, Loss: 0.18010786277710464, Accuracy: 0.9053\n",
            "Batch: 600, Loss: 0.179439475315111, Accuracy: 0.9055\n",
            "Batch: 610, Loss: 0.17958575323099532, Accuracy: 0.9054333333333333\n",
            "Batch: 620, Loss: 0.17992057460561883, Accuracy: 0.90565\n",
            "Batch: 630, Loss: 0.17978789834815176, Accuracy: 0.9052333333333333\n",
            "Batch: 640, Loss: 0.18076921594705728, Accuracy: 0.9052\n",
            "Batch: 650, Loss: 0.17998763843743398, Accuracy: 0.9054333333333333\n",
            "Batch: 660, Loss: 0.18007002774678646, Accuracy: 0.9054166666666666\n",
            "Batch: 670, Loss: 0.17958994714799603, Accuracy: 0.9052833333333333\n",
            "Batch: 680, Loss: 0.17992742756325125, Accuracy: 0.9048\n",
            "Batch: 690, Loss: 0.18120572771715834, Accuracy: 0.9043833333333333\n",
            "Batch: 700, Loss: 0.1811382706453278, Accuracy: 0.9045333333333333\n",
            "Batch: 710, Loss: 0.1826383702370016, Accuracy: 0.9035333333333333\n",
            "Batch: 720, Loss: 0.1813005667661567, Accuracy: 0.90415\n",
            "Batch: 730, Loss: 0.18217483519840602, Accuracy: 0.9037833333333334\n",
            "Batch: 740, Loss: 0.18188795493338894, Accuracy: 0.9038666666666667\n",
            "Batch: 750, Loss: 0.1824839270116404, Accuracy: 0.9034666666666666\n",
            "Batch: 760, Loss: 0.1811717151310802, Accuracy: 0.9041333333333333\n",
            "Batch: 770, Loss: 0.1813618419000696, Accuracy: 0.9039166666666667\n",
            "Batch: 780, Loss: 0.18280835503367318, Accuracy: 0.9031333333333333\n",
            "Batch: 790, Loss: 0.18212138391718177, Accuracy: 0.9033833333333333\n",
            "Batch: 800, Loss: 0.18246266223763158, Accuracy: 0.9036166666666666\n",
            "Batch: 810, Loss: 0.1824250256761422, Accuracy: 0.90375\n",
            "Batch: 820, Loss: 0.1825020954913207, Accuracy: 0.9034833333333333\n",
            "Batch: 830, Loss: 0.1811090480172794, Accuracy: 0.9037333333333334\n",
            "Batch: 840, Loss: 0.18052093218539889, Accuracy: 0.9042166666666667\n",
            "Batch: 850, Loss: 0.17990270093187713, Accuracy: 0.9046\n",
            "Batch: 860, Loss: 0.1810353278319674, Accuracy: 0.9041666666666667\n",
            "Batch: 870, Loss: 0.18081428559189222, Accuracy: 0.9042333333333333\n",
            "Batch: 880, Loss: 0.18036834967644727, Accuracy: 0.9043833333333333\n",
            "Batch: 890, Loss: 0.1801647248694608, Accuracy: 0.9045333333333333\n",
            "Batch: 900, Loss: 0.18041886238208568, Accuracy: 0.9042833333333333\n",
            "Batch: 910, Loss: 0.17969440631581965, Accuracy: 0.9047166666666666\n",
            "Batch: 920, Loss: 0.17979122540730225, Accuracy: 0.9048833333333334\n",
            "Batch: 930, Loss: 0.1802109310876677, Accuracy: 0.9044666666666666\n",
            "Epoch: 24, Loss: 0.18051922885407715, Accuracy: 0.9042\n",
            "Batch: 0, Loss: 0.18049403077295284, Accuracy: 0.9041833333333333\n",
            "Batch: 10, Loss: 0.18180353685010553, Accuracy: 0.9037333333333334\n",
            "Batch: 20, Loss: 0.18100934783674377, Accuracy: 0.9043\n",
            "Batch: 30, Loss: 0.1802755662678005, Accuracy: 0.90455\n",
            "Batch: 40, Loss: 0.1795717918806708, Accuracy: 0.9051666666666667\n",
            "Batch: 50, Loss: 0.1799135854421209, Accuracy: 0.9052333333333333\n",
            "Batch: 60, Loss: 0.17899860394929534, Accuracy: 0.9055166666666666\n",
            "Batch: 70, Loss: 0.17871424978516237, Accuracy: 0.90565\n",
            "Batch: 80, Loss: 0.1791168237377076, Accuracy: 0.9050833333333334\n",
            "Batch: 90, Loss: 0.17864397955025046, Accuracy: 0.9056\n",
            "Batch: 100, Loss: 0.17852152483180914, Accuracy: 0.9054666666666666\n",
            "Batch: 110, Loss: 0.1796795762115409, Accuracy: 0.90485\n",
            "Batch: 120, Loss: 0.17870717599230274, Accuracy: 0.9053333333333333\n",
            "Batch: 130, Loss: 0.1801035573293104, Accuracy: 0.9046333333333333\n",
            "Batch: 140, Loss: 0.18145424268563595, Accuracy: 0.90405\n",
            "Batch: 150, Loss: 0.17967419444622745, Accuracy: 0.9048666666666667\n",
            "Batch: 160, Loss: 0.18014104925907243, Accuracy: 0.9050833333333334\n",
            "Batch: 170, Loss: 0.17869630656972313, Accuracy: 0.9054\n",
            "Batch: 180, Loss: 0.1787677934809032, Accuracy: 0.9057166666666666\n",
            "Batch: 190, Loss: 0.17967005899984884, Accuracy: 0.9053833333333333\n",
            "Batch: 200, Loss: 0.1807674229297869, Accuracy: 0.90485\n",
            "Batch: 210, Loss: 0.18088553278957226, Accuracy: 0.9046833333333333\n",
            "Batch: 220, Loss: 0.18193339637697098, Accuracy: 0.9042\n",
            "Batch: 230, Loss: 0.18085859794486847, Accuracy: 0.9048833333333334\n",
            "Batch: 240, Loss: 0.18068360275687134, Accuracy: 0.90525\n",
            "Batch: 250, Loss: 0.18021666093586647, Accuracy: 0.9053833333333333\n",
            "Batch: 260, Loss: 0.18005297452630062, Accuracy: 0.9055666666666666\n",
            "Batch: 270, Loss: 0.1787894800813825, Accuracy: 0.9059833333333334\n",
            "Batch: 280, Loss: 0.17793800280557476, Accuracy: 0.9065333333333333\n",
            "Batch: 290, Loss: 0.17777903218596464, Accuracy: 0.90665\n",
            "Batch: 300, Loss: 0.1776173308691544, Accuracy: 0.90645\n",
            "Batch: 310, Loss: 0.1783389624187268, Accuracy: 0.90615\n",
            "Batch: 320, Loss: 0.17769121879708405, Accuracy: 0.90675\n",
            "Batch: 330, Loss: 0.1776311857507345, Accuracy: 0.9061833333333333\n",
            "Batch: 340, Loss: 0.178325330171755, Accuracy: 0.9060833333333334\n",
            "Batch: 350, Loss: 0.17784277155788375, Accuracy: 0.9063333333333333\n",
            "Batch: 360, Loss: 0.1784324337228152, Accuracy: 0.9060666666666667\n",
            "Batch: 370, Loss: 0.1773581490523186, Accuracy: 0.9062666666666667\n",
            "Batch: 380, Loss: 0.1771785479903774, Accuracy: 0.9063\n",
            "Batch: 390, Loss: 0.1772791763759922, Accuracy: 0.9066833333333333\n",
            "Batch: 400, Loss: 0.1777399726341861, Accuracy: 0.9057833333333334\n",
            "Batch: 410, Loss: 0.1776408987590005, Accuracy: 0.9060666666666667\n",
            "Batch: 420, Loss: 0.17714038995502696, Accuracy: 0.9063833333333333\n",
            "Batch: 430, Loss: 0.17764880226136662, Accuracy: 0.9062833333333333\n",
            "Batch: 440, Loss: 0.17796303590561197, Accuracy: 0.9062166666666667\n",
            "Batch: 450, Loss: 0.17788288625163554, Accuracy: 0.9061833333333333\n",
            "Batch: 460, Loss: 0.1778607989405026, Accuracy: 0.9061666666666667\n",
            "Batch: 470, Loss: 0.1773560564008435, Accuracy: 0.9069833333333334\n",
            "Batch: 480, Loss: 0.1773070945978043, Accuracy: 0.90665\n",
            "Batch: 490, Loss: 0.17707216457903466, Accuracy: 0.9065166666666666\n",
            "Batch: 500, Loss: 0.1771076921502685, Accuracy: 0.9064833333333333\n",
            "Batch: 510, Loss: 0.17700433551628958, Accuracy: 0.9067\n",
            "Batch: 520, Loss: 0.17667023005529067, Accuracy: 0.9068\n",
            "Batch: 530, Loss: 0.17669375146144475, Accuracy: 0.90645\n",
            "Batch: 540, Loss: 0.17654234001620772, Accuracy: 0.9065666666666666\n",
            "Batch: 550, Loss: 0.1768757743745124, Accuracy: 0.90675\n",
            "Batch: 560, Loss: 0.17755870473089716, Accuracy: 0.9064833333333333\n",
            "Batch: 570, Loss: 0.17805272920388004, Accuracy: 0.9062833333333333\n",
            "Batch: 580, Loss: 0.1779226543504041, Accuracy: 0.9062833333333333\n",
            "Batch: 590, Loss: 0.17681005570116373, Accuracy: 0.9066666666666666\n",
            "Batch: 600, Loss: 0.17614407893046655, Accuracy: 0.9069\n",
            "Batch: 610, Loss: 0.17636602744566546, Accuracy: 0.90685\n",
            "Batch: 620, Loss: 0.17662577275108476, Accuracy: 0.90665\n",
            "Batch: 630, Loss: 0.17660262585079065, Accuracy: 0.90675\n",
            "Batch: 640, Loss: 0.1775909479558239, Accuracy: 0.9063\n",
            "Batch: 650, Loss: 0.1767508992229762, Accuracy: 0.9064166666666666\n",
            "Batch: 660, Loss: 0.17679021385804797, Accuracy: 0.90685\n",
            "Batch: 670, Loss: 0.17639367966663436, Accuracy: 0.90685\n",
            "Batch: 680, Loss: 0.17675018594101558, Accuracy: 0.90615\n",
            "Batch: 690, Loss: 0.17811911062558736, Accuracy: 0.9056\n",
            "Batch: 700, Loss: 0.17803533030889607, Accuracy: 0.9059166666666667\n",
            "Batch: 710, Loss: 0.1795349961221071, Accuracy: 0.9049\n",
            "Batch: 720, Loss: 0.17823407759492058, Accuracy: 0.9056333333333333\n",
            "Batch: 730, Loss: 0.17911999843796148, Accuracy: 0.90505\n",
            "Batch: 740, Loss: 0.17888396222384023, Accuracy: 0.9053666666666667\n",
            "Batch: 750, Loss: 0.17947875058429916, Accuracy: 0.9046666666666666\n",
            "Batch: 760, Loss: 0.17825961490193065, Accuracy: 0.9051666666666667\n",
            "Batch: 770, Loss: 0.1784292026715832, Accuracy: 0.90525\n",
            "Batch: 780, Loss: 0.17977855570306278, Accuracy: 0.9045666666666666\n",
            "Batch: 790, Loss: 0.17912192810099126, Accuracy: 0.9048\n",
            "Batch: 800, Loss: 0.17966459130619244, Accuracy: 0.90475\n",
            "Batch: 810, Loss: 0.17941990178850908, Accuracy: 0.9051333333333333\n",
            "Batch: 820, Loss: 0.1795560154484374, Accuracy: 0.9047833333333334\n",
            "Batch: 830, Loss: 0.1779933792050674, Accuracy: 0.90525\n",
            "Batch: 840, Loss: 0.1773153642402007, Accuracy: 0.9055833333333333\n",
            "Batch: 850, Loss: 0.17678528885917075, Accuracy: 0.9056833333333333\n",
            "Batch: 860, Loss: 0.17791470696272607, Accuracy: 0.90545\n",
            "Batch: 870, Loss: 0.17775852274086054, Accuracy: 0.90535\n",
            "Batch: 880, Loss: 0.17730590126427306, Accuracy: 0.9057833333333334\n",
            "Batch: 890, Loss: 0.17695918781163705, Accuracy: 0.9060833333333334\n",
            "Batch: 900, Loss: 0.17722044679564194, Accuracy: 0.90545\n",
            "Batch: 910, Loss: 0.17650381387840486, Accuracy: 0.9058833333333334\n",
            "Batch: 920, Loss: 0.17655963936715502, Accuracy: 0.9060166666666667\n",
            "Batch: 930, Loss: 0.177270464120902, Accuracy: 0.9059833333333334\n",
            "Epoch: 25, Loss: 0.17754841261528936, Accuracy: 0.9057166666666666\n",
            "Batch: 0, Loss: 0.1775096030824517, Accuracy: 0.9057333333333333\n",
            "Batch: 10, Loss: 0.17879805246099723, Accuracy: 0.9050833333333334\n",
            "Batch: 20, Loss: 0.17788884111786846, Accuracy: 0.9055666666666666\n",
            "Batch: 30, Loss: 0.17716970633213133, Accuracy: 0.9060833333333334\n",
            "Batch: 40, Loss: 0.17644918858417508, Accuracy: 0.90645\n",
            "Batch: 50, Loss: 0.1767599467317754, Accuracy: 0.9064\n",
            "Batch: 60, Loss: 0.17584053289089283, Accuracy: 0.90685\n",
            "Batch: 70, Loss: 0.17557986921461388, Accuracy: 0.9068\n",
            "Batch: 80, Loss: 0.1759130975024184, Accuracy: 0.9064833333333333\n",
            "Batch: 90, Loss: 0.1754077570758154, Accuracy: 0.90685\n",
            "Batch: 100, Loss: 0.17533004837412983, Accuracy: 0.9069\n",
            "Batch: 110, Loss: 0.17654154058865723, Accuracy: 0.90625\n",
            "Batch: 120, Loss: 0.17565684174635626, Accuracy: 0.9067833333333334\n",
            "Batch: 130, Loss: 0.17705951594987862, Accuracy: 0.9059333333333334\n",
            "Batch: 140, Loss: 0.17823912513256304, Accuracy: 0.90535\n",
            "Batch: 150, Loss: 0.17646762052383447, Accuracy: 0.9061833333333333\n",
            "Batch: 160, Loss: 0.1769257742199368, Accuracy: 0.9062\n",
            "Batch: 170, Loss: 0.1755948121311937, Accuracy: 0.9066166666666666\n",
            "Batch: 180, Loss: 0.17570517146185152, Accuracy: 0.9069333333333334\n",
            "Batch: 190, Loss: 0.17667560424467077, Accuracy: 0.9065333333333333\n",
            "Batch: 200, Loss: 0.1778929928688437, Accuracy: 0.9062166666666667\n",
            "Batch: 210, Loss: 0.17802316351510872, Accuracy: 0.9059666666666667\n",
            "Batch: 220, Loss: 0.17905762041086246, Accuracy: 0.9055166666666666\n",
            "Batch: 230, Loss: 0.1778951467713646, Accuracy: 0.9059166666666667\n",
            "Batch: 240, Loss: 0.17778394418762938, Accuracy: 0.90635\n",
            "Batch: 250, Loss: 0.1772497729545468, Accuracy: 0.9066833333333333\n",
            "Batch: 260, Loss: 0.1771522643067064, Accuracy: 0.9067166666666666\n",
            "Batch: 270, Loss: 0.1758185397908472, Accuracy: 0.9074333333333333\n",
            "Batch: 280, Loss: 0.17489638614564848, Accuracy: 0.9078\n",
            "Batch: 290, Loss: 0.1746766822661972, Accuracy: 0.9080833333333334\n",
            "Batch: 300, Loss: 0.17451632648438664, Accuracy: 0.9079666666666667\n",
            "Batch: 310, Loss: 0.17522396476801522, Accuracy: 0.90785\n",
            "Batch: 320, Loss: 0.17456123119961703, Accuracy: 0.9082\n",
            "Batch: 330, Loss: 0.17452464048185384, Accuracy: 0.9076666666666666\n",
            "Batch: 340, Loss: 0.17511232948677025, Accuracy: 0.9075166666666666\n",
            "Batch: 350, Loss: 0.17468836969894316, Accuracy: 0.9078166666666667\n",
            "Batch: 360, Loss: 0.17537363480896104, Accuracy: 0.9074666666666666\n",
            "Batch: 370, Loss: 0.174286286442634, Accuracy: 0.90795\n",
            "Batch: 380, Loss: 0.17412401657988258, Accuracy: 0.9079166666666667\n",
            "Batch: 390, Loss: 0.17415025728254027, Accuracy: 0.9081\n",
            "Batch: 400, Loss: 0.1745508732322698, Accuracy: 0.9072666666666667\n",
            "Batch: 410, Loss: 0.17433621553067363, Accuracy: 0.9074833333333333\n",
            "Batch: 420, Loss: 0.17393408004116204, Accuracy: 0.9077666666666667\n",
            "Batch: 430, Loss: 0.1744296079723063, Accuracy: 0.9075333333333333\n",
            "Batch: 440, Loss: 0.17480105026290477, Accuracy: 0.90775\n",
            "Batch: 450, Loss: 0.17461510283137657, Accuracy: 0.9077\n",
            "Batch: 460, Loss: 0.17464951143277313, Accuracy: 0.9074833333333333\n",
            "Batch: 470, Loss: 0.1742074364652869, Accuracy: 0.9083333333333333\n",
            "Batch: 480, Loss: 0.17416485370154577, Accuracy: 0.9079666666666667\n",
            "Batch: 490, Loss: 0.17398954052823443, Accuracy: 0.9079\n",
            "Batch: 500, Loss: 0.17392067033508132, Accuracy: 0.9079333333333334\n",
            "Batch: 510, Loss: 0.1738908836830607, Accuracy: 0.9077333333333333\n",
            "Batch: 520, Loss: 0.17356517369671004, Accuracy: 0.9082333333333333\n",
            "Batch: 530, Loss: 0.173552474990516, Accuracy: 0.9079666666666667\n",
            "Batch: 540, Loss: 0.17333924840729945, Accuracy: 0.9080833333333334\n",
            "Batch: 550, Loss: 0.17363232938955545, Accuracy: 0.9082333333333333\n",
            "Batch: 560, Loss: 0.17441071958478033, Accuracy: 0.9078666666666667\n",
            "Batch: 570, Loss: 0.1749885577423416, Accuracy: 0.90765\n",
            "Batch: 580, Loss: 0.1747818665536441, Accuracy: 0.9076\n",
            "Batch: 590, Loss: 0.17358296690971217, Accuracy: 0.9080166666666667\n",
            "Batch: 600, Loss: 0.17298591471354482, Accuracy: 0.9083333333333333\n",
            "Batch: 610, Loss: 0.1732516811865434, Accuracy: 0.9082666666666667\n",
            "Batch: 620, Loss: 0.17351474621016663, Accuracy: 0.9081666666666667\n",
            "Batch: 630, Loss: 0.17347947367874852, Accuracy: 0.9082\n",
            "Batch: 640, Loss: 0.17455068326939135, Accuracy: 0.9076\n",
            "Batch: 650, Loss: 0.17358856765341207, Accuracy: 0.9074833333333333\n",
            "Batch: 660, Loss: 0.1736862814703182, Accuracy: 0.9082\n",
            "Batch: 670, Loss: 0.17326983567141838, Accuracy: 0.9081166666666667\n",
            "Batch: 680, Loss: 0.17368725478533845, Accuracy: 0.9075333333333333\n",
            "Batch: 690, Loss: 0.1751178802278696, Accuracy: 0.9066166666666666\n",
            "Batch: 700, Loss: 0.17509042448997097, Accuracy: 0.90685\n",
            "Batch: 710, Loss: 0.17652564091964237, Accuracy: 0.9061833333333333\n",
            "Batch: 720, Loss: 0.17530768443465478, Accuracy: 0.9070833333333334\n",
            "Batch: 730, Loss: 0.17623177366116807, Accuracy: 0.9064\n",
            "Batch: 740, Loss: 0.17599376870986871, Accuracy: 0.9064333333333333\n",
            "Batch: 750, Loss: 0.17654358963164737, Accuracy: 0.90585\n",
            "Batch: 760, Loss: 0.1753269155207471, Accuracy: 0.9062833333333333\n",
            "Batch: 770, Loss: 0.17548596283469253, Accuracy: 0.9065\n",
            "Batch: 780, Loss: 0.17687142058700978, Accuracy: 0.9055\n",
            "Batch: 790, Loss: 0.17619898966980393, Accuracy: 0.9060666666666667\n",
            "Batch: 800, Loss: 0.17678721669640976, Accuracy: 0.90585\n",
            "Batch: 810, Loss: 0.17640327650781146, Accuracy: 0.9062166666666667\n",
            "Batch: 820, Loss: 0.17653596986009631, Accuracy: 0.9059666666666667\n",
            "Batch: 830, Loss: 0.1749456547332492, Accuracy: 0.9063833333333333\n",
            "Batch: 840, Loss: 0.17426972797744855, Accuracy: 0.9067166666666666\n",
            "Batch: 850, Loss: 0.17386972350302776, Accuracy: 0.9069166666666667\n",
            "Batch: 860, Loss: 0.17498452674473955, Accuracy: 0.9065666666666666\n",
            "Batch: 870, Loss: 0.17479582858455395, Accuracy: 0.9066333333333333\n",
            "Batch: 880, Loss: 0.1743176420064224, Accuracy: 0.9069666666666667\n",
            "Batch: 890, Loss: 0.17395587284414796, Accuracy: 0.9071833333333333\n",
            "Batch: 900, Loss: 0.17422151365002733, Accuracy: 0.90695\n",
            "Batch: 910, Loss: 0.17344884381859615, Accuracy: 0.9072833333333333\n",
            "Batch: 920, Loss: 0.1734958878243524, Accuracy: 0.9073\n",
            "Batch: 930, Loss: 0.1743444059144533, Accuracy: 0.9070833333333334\n",
            "Epoch: 26, Loss: 0.1746138880009383, Accuracy: 0.9070666666666667\n",
            "Batch: 0, Loss: 0.17457557080511243, Accuracy: 0.9072166666666667\n",
            "Batch: 10, Loss: 0.1758816702280496, Accuracy: 0.90605\n",
            "Batch: 20, Loss: 0.1748974942861834, Accuracy: 0.9068166666666667\n",
            "Batch: 30, Loss: 0.17430477294515426, Accuracy: 0.9074666666666666\n",
            "Batch: 40, Loss: 0.17349915206987587, Accuracy: 0.90755\n",
            "Batch: 50, Loss: 0.17381049396790205, Accuracy: 0.90765\n",
            "Batch: 60, Loss: 0.17290782176716915, Accuracy: 0.9082333333333333\n",
            "Batch: 70, Loss: 0.17263321344546875, Accuracy: 0.9082666666666667\n",
            "Batch: 80, Loss: 0.17288022303765316, Accuracy: 0.9079666666666667\n",
            "Batch: 90, Loss: 0.1724132590933728, Accuracy: 0.9083166666666667\n",
            "Batch: 100, Loss: 0.1723180494453886, Accuracy: 0.9084166666666667\n",
            "Batch: 110, Loss: 0.17350141267069485, Accuracy: 0.9075\n",
            "Batch: 120, Loss: 0.17271899768997817, Accuracy: 0.9082166666666667\n",
            "Batch: 130, Loss: 0.17409746211799537, Accuracy: 0.90725\n",
            "Batch: 140, Loss: 0.17504053844055376, Accuracy: 0.9067833333333334\n",
            "Batch: 150, Loss: 0.17330913398070522, Accuracy: 0.9075166666666666\n",
            "Batch: 160, Loss: 0.17376658532452327, Accuracy: 0.9075666666666666\n",
            "Batch: 170, Loss: 0.17255133684267904, Accuracy: 0.9080166666666667\n",
            "Batch: 180, Loss: 0.1726869519642688, Accuracy: 0.90845\n",
            "Batch: 190, Loss: 0.17385570379591597, Accuracy: 0.9076833333333333\n",
            "Batch: 200, Loss: 0.1752225932469476, Accuracy: 0.90735\n",
            "Batch: 210, Loss: 0.17533605393971677, Accuracy: 0.9071833333333333\n",
            "Batch: 220, Loss: 0.1763311469584157, Accuracy: 0.9068333333333334\n",
            "Batch: 230, Loss: 0.1750822067867899, Accuracy: 0.9071333333333333\n",
            "Batch: 240, Loss: 0.17509043608911418, Accuracy: 0.9076166666666666\n",
            "Batch: 250, Loss: 0.17438679719275374, Accuracy: 0.9077166666666666\n",
            "Batch: 260, Loss: 0.17431739398614518, Accuracy: 0.9078666666666667\n",
            "Batch: 270, Loss: 0.17289949075173142, Accuracy: 0.9085833333333333\n",
            "Batch: 280, Loss: 0.1718739706075396, Accuracy: 0.9091166666666667\n",
            "Batch: 290, Loss: 0.1716137130251616, Accuracy: 0.9096333333333333\n",
            "Batch: 300, Loss: 0.17154598443295271, Accuracy: 0.9094833333333333\n",
            "Batch: 310, Loss: 0.17224134953994055, Accuracy: 0.9091\n",
            "Batch: 320, Loss: 0.17159493749243016, Accuracy: 0.9093833333333333\n",
            "Batch: 330, Loss: 0.17156294037729333, Accuracy: 0.9091\n",
            "Batch: 340, Loss: 0.17204452356159652, Accuracy: 0.9091166666666667\n",
            "Batch: 350, Loss: 0.17166468425162937, Accuracy: 0.9092\n",
            "Batch: 360, Loss: 0.17239681704550178, Accuracy: 0.9088166666666667\n",
            "Batch: 370, Loss: 0.1714240709363545, Accuracy: 0.9093\n",
            "Batch: 380, Loss: 0.1711919752710333, Accuracy: 0.9093\n",
            "Batch: 390, Loss: 0.1711435839206965, Accuracy: 0.9096166666666666\n",
            "Batch: 400, Loss: 0.17142469083322148, Accuracy: 0.9086333333333333\n",
            "Batch: 410, Loss: 0.17115347177002585, Accuracy: 0.9089666666666667\n",
            "Batch: 420, Loss: 0.17081977787969943, Accuracy: 0.90915\n",
            "Batch: 430, Loss: 0.17132901718399263, Accuracy: 0.90895\n",
            "Batch: 440, Loss: 0.17178789593344201, Accuracy: 0.90925\n",
            "Batch: 450, Loss: 0.1715025053365752, Accuracy: 0.9092666666666667\n",
            "Batch: 460, Loss: 0.17159646817819732, Accuracy: 0.9090333333333334\n",
            "Batch: 470, Loss: 0.17123194265882158, Accuracy: 0.9095666666666666\n",
            "Batch: 480, Loss: 0.17118022888672885, Accuracy: 0.9092833333333333\n",
            "Batch: 490, Loss: 0.17112239278720304, Accuracy: 0.9091333333333333\n",
            "Batch: 500, Loss: 0.1709096185046821, Accuracy: 0.9091666666666667\n",
            "Batch: 510, Loss: 0.17091668049713454, Accuracy: 0.9091333333333333\n",
            "Batch: 520, Loss: 0.17057885031167447, Accuracy: 0.90945\n",
            "Batch: 530, Loss: 0.17057219559200376, Accuracy: 0.9095333333333333\n",
            "Batch: 540, Loss: 0.17028447013482997, Accuracy: 0.90975\n",
            "Batch: 550, Loss: 0.17058388472962893, Accuracy: 0.9096666666666666\n",
            "Batch: 560, Loss: 0.17146212976403977, Accuracy: 0.9095166666666666\n",
            "Batch: 570, Loss: 0.17209858963087352, Accuracy: 0.90905\n",
            "Batch: 580, Loss: 0.17179367733503526, Accuracy: 0.90915\n",
            "Batch: 590, Loss: 0.17051213919127667, Accuracy: 0.9094833333333333\n",
            "Batch: 600, Loss: 0.17003703441962933, Accuracy: 0.9095833333333333\n",
            "Batch: 610, Loss: 0.17029737585491778, Accuracy: 0.9095833333333333\n",
            "Batch: 620, Loss: 0.17068750542330832, Accuracy: 0.9095666666666666\n",
            "Batch: 630, Loss: 0.1704694374356172, Accuracy: 0.90955\n",
            "Batch: 640, Loss: 0.17150336197118196, Accuracy: 0.90885\n",
            "Batch: 650, Loss: 0.17059273766286726, Accuracy: 0.9091333333333333\n",
            "Batch: 660, Loss: 0.1707289601598652, Accuracy: 0.90945\n",
            "Batch: 670, Loss: 0.17029328092061116, Accuracy: 0.9093166666666667\n",
            "Batch: 680, Loss: 0.1706934186715512, Accuracy: 0.90905\n",
            "Batch: 690, Loss: 0.1721510526032277, Accuracy: 0.9081333333333333\n",
            "Batch: 700, Loss: 0.17218017069583386, Accuracy: 0.9080666666666667\n",
            "Batch: 710, Loss: 0.1735825169541687, Accuracy: 0.9075\n",
            "Batch: 720, Loss: 0.1724448985429478, Accuracy: 0.9081833333333333\n",
            "Batch: 730, Loss: 0.1734070906980225, Accuracy: 0.9076333333333333\n",
            "Batch: 740, Loss: 0.1731676261204136, Accuracy: 0.9077333333333333\n",
            "Batch: 750, Loss: 0.17359735733079654, Accuracy: 0.907\n",
            "Batch: 760, Loss: 0.1723576383362803, Accuracy: 0.90755\n",
            "Batch: 770, Loss: 0.17256052989740026, Accuracy: 0.9073833333333333\n",
            "Batch: 780, Loss: 0.17396432488786698, Accuracy: 0.9067666666666667\n",
            "Batch: 790, Loss: 0.1733136816666401, Accuracy: 0.9070833333333334\n",
            "Batch: 800, Loss: 0.17392133356792638, Accuracy: 0.907\n",
            "Batch: 810, Loss: 0.17342411657587442, Accuracy: 0.9071333333333333\n",
            "Batch: 820, Loss: 0.173537703920118, Accuracy: 0.9070333333333334\n",
            "Batch: 830, Loss: 0.17201914175643088, Accuracy: 0.9077666666666667\n",
            "Batch: 840, Loss: 0.17137079578086664, Accuracy: 0.9077666666666667\n",
            "Batch: 850, Loss: 0.1710315482267433, Accuracy: 0.9078166666666667\n",
            "Batch: 860, Loss: 0.172168538296096, Accuracy: 0.90755\n",
            "Batch: 870, Loss: 0.171848448767586, Accuracy: 0.9078333333333334\n",
            "Batch: 880, Loss: 0.17135144298152602, Accuracy: 0.9081333333333333\n",
            "Batch: 890, Loss: 0.1711826661410346, Accuracy: 0.9084166666666667\n",
            "Batch: 900, Loss: 0.17145117770464702, Accuracy: 0.908\n",
            "Batch: 910, Loss: 0.17064958178697706, Accuracy: 0.9085333333333333\n",
            "Batch: 920, Loss: 0.17069278125766096, Accuracy: 0.9084333333333333\n",
            "Batch: 930, Loss: 0.17159615290080374, Accuracy: 0.9082666666666667\n",
            "Epoch: 27, Loss: 0.17185334776406294, Accuracy: 0.90795\n",
            "Batch: 0, Loss: 0.1718185774258345, Accuracy: 0.9080166666666667\n",
            "Batch: 10, Loss: 0.17313254599246766, Accuracy: 0.90715\n",
            "Batch: 20, Loss: 0.17204507456664345, Accuracy: 0.9080166666666667\n",
            "Batch: 30, Loss: 0.17155995601276824, Accuracy: 0.9082166666666667\n",
            "Batch: 40, Loss: 0.1707412419135095, Accuracy: 0.9088833333333334\n",
            "Batch: 50, Loss: 0.17097540276155912, Accuracy: 0.90925\n",
            "Batch: 60, Loss: 0.1701668524676832, Accuracy: 0.9094333333333333\n",
            "Batch: 70, Loss: 0.16984236876276032, Accuracy: 0.9093666666666667\n",
            "Batch: 80, Loss: 0.17005919148641221, Accuracy: 0.9089\n",
            "Batch: 90, Loss: 0.16958509270057465, Accuracy: 0.90945\n",
            "Batch: 100, Loss: 0.16946243156769872, Accuracy: 0.9096333333333333\n",
            "Batch: 110, Loss: 0.17057173890421107, Accuracy: 0.9087333333333333\n",
            "Batch: 120, Loss: 0.1698602191157065, Accuracy: 0.9092833333333333\n",
            "Batch: 130, Loss: 0.17120490721492035, Accuracy: 0.9083\n",
            "Batch: 140, Loss: 0.17206908566460175, Accuracy: 0.9079\n",
            "Batch: 150, Loss: 0.17043163569641623, Accuracy: 0.9087833333333334\n",
            "Batch: 160, Loss: 0.1708619488368016, Accuracy: 0.90885\n",
            "Batch: 170, Loss: 0.16961872962819033, Accuracy: 0.9096166666666666\n",
            "Batch: 180, Loss: 0.16977718634476385, Accuracy: 0.9098\n",
            "Batch: 190, Loss: 0.1711085506975457, Accuracy: 0.9089166666666667\n",
            "Batch: 200, Loss: 0.17263381682439727, Accuracy: 0.9084333333333333\n",
            "Batch: 210, Loss: 0.17277492330888786, Accuracy: 0.90795\n",
            "Batch: 220, Loss: 0.17367810893142774, Accuracy: 0.9077333333333333\n",
            "Batch: 230, Loss: 0.17239977976905177, Accuracy: 0.9084\n",
            "Batch: 240, Loss: 0.17251188024883915, Accuracy: 0.9088833333333334\n",
            "Batch: 250, Loss: 0.17155535985549142, Accuracy: 0.9090166666666667\n",
            "Batch: 260, Loss: 0.17156272147827636, Accuracy: 0.9089833333333334\n",
            "Batch: 270, Loss: 0.17013024351311312, Accuracy: 0.9096166666666666\n",
            "Batch: 280, Loss: 0.16903210020978957, Accuracy: 0.91045\n",
            "Batch: 290, Loss: 0.16878381647892474, Accuracy: 0.9108666666666667\n",
            "Batch: 300, Loss: 0.1687040469540558, Accuracy: 0.9105333333333333\n",
            "Batch: 310, Loss: 0.1693741891350062, Accuracy: 0.9102333333333333\n",
            "Batch: 320, Loss: 0.16879321768641053, Accuracy: 0.9105\n",
            "Batch: 330, Loss: 0.16870626688908014, Accuracy: 0.9106166666666666\n",
            "Batch: 340, Loss: 0.169222146532358, Accuracy: 0.9104333333333333\n",
            "Batch: 350, Loss: 0.16887143172728877, Accuracy: 0.9104333333333333\n",
            "Batch: 360, Loss: 0.16960933027202113, Accuracy: 0.9100333333333334\n",
            "Batch: 370, Loss: 0.16867093290645635, Accuracy: 0.9106833333333333\n",
            "Batch: 380, Loss: 0.16843250476807795, Accuracy: 0.9104666666666666\n",
            "Batch: 390, Loss: 0.16830690164949572, Accuracy: 0.91045\n",
            "Batch: 400, Loss: 0.16852415467936813, Accuracy: 0.9101666666666667\n",
            "Batch: 410, Loss: 0.16819998471171782, Accuracy: 0.9103\n",
            "Batch: 420, Loss: 0.16789416157047174, Accuracy: 0.9107\n",
            "Batch: 430, Loss: 0.16840604977060547, Accuracy: 0.9103666666666667\n",
            "Batch: 440, Loss: 0.16895985531891058, Accuracy: 0.9103333333333333\n",
            "Batch: 450, Loss: 0.16862180923675338, Accuracy: 0.9103333333333333\n",
            "Batch: 460, Loss: 0.16870350198914721, Accuracy: 0.9101833333333333\n",
            "Batch: 470, Loss: 0.1683656154389198, Accuracy: 0.91065\n",
            "Batch: 480, Loss: 0.16832708385408576, Accuracy: 0.91045\n",
            "Batch: 490, Loss: 0.1683856015846807, Accuracy: 0.9105833333333333\n",
            "Batch: 500, Loss: 0.16801259922984924, Accuracy: 0.9105833333333333\n",
            "Batch: 510, Loss: 0.1680350032771504, Accuracy: 0.9101333333333333\n",
            "Batch: 520, Loss: 0.1677333834541747, Accuracy: 0.91065\n",
            "Batch: 530, Loss: 0.16772953659860845, Accuracy: 0.9106666666666666\n",
            "Batch: 540, Loss: 0.167432485888243, Accuracy: 0.9109\n",
            "Batch: 550, Loss: 0.16776226196614297, Accuracy: 0.91095\n",
            "Batch: 560, Loss: 0.1686661445313425, Accuracy: 0.9106166666666666\n",
            "Batch: 570, Loss: 0.16935742164570636, Accuracy: 0.9102666666666667\n",
            "Batch: 580, Loss: 0.16905456061514845, Accuracy: 0.9104833333333333\n",
            "Batch: 590, Loss: 0.1676678593493207, Accuracy: 0.91085\n",
            "Batch: 600, Loss: 0.16734831342172166, Accuracy: 0.9107833333333333\n",
            "Batch: 610, Loss: 0.1675350524544015, Accuracy: 0.9108333333333334\n",
            "Batch: 620, Loss: 0.16792953206455927, Accuracy: 0.91065\n",
            "Batch: 630, Loss: 0.16769710862035325, Accuracy: 0.9109666666666667\n",
            "Batch: 640, Loss: 0.16864810705732347, Accuracy: 0.9099166666666667\n",
            "Batch: 650, Loss: 0.16783584736950707, Accuracy: 0.9106166666666666\n",
            "Batch: 660, Loss: 0.16792113994335392, Accuracy: 0.9108333333333334\n",
            "Batch: 670, Loss: 0.16753174825282824, Accuracy: 0.91095\n",
            "Batch: 680, Loss: 0.16782653070751205, Accuracy: 0.9104\n",
            "Batch: 690, Loss: 0.16934209892085014, Accuracy: 0.9092833333333333\n",
            "Batch: 700, Loss: 0.1693130478085753, Accuracy: 0.9097333333333333\n",
            "Batch: 710, Loss: 0.17065158162493013, Accuracy: 0.9089333333333334\n",
            "Batch: 720, Loss: 0.16953854865621817, Accuracy: 0.9094166666666667\n",
            "Batch: 730, Loss: 0.17055465293778246, Accuracy: 0.9088833333333334\n",
            "Batch: 740, Loss: 0.1703645607038966, Accuracy: 0.9088166666666667\n",
            "Batch: 750, Loss: 0.17077085604733525, Accuracy: 0.9084333333333333\n",
            "Batch: 760, Loss: 0.16946774502331996, Accuracy: 0.9086833333333333\n",
            "Batch: 770, Loss: 0.1697404845752326, Accuracy: 0.9084666666666666\n",
            "Batch: 780, Loss: 0.17114236144034495, Accuracy: 0.9079166666666667\n",
            "Batch: 790, Loss: 0.1704811733152439, Accuracy: 0.9081833333333333\n",
            "Batch: 800, Loss: 0.1711035343495528, Accuracy: 0.9082\n",
            "Batch: 810, Loss: 0.17050056903587338, Accuracy: 0.9084166666666667\n",
            "Batch: 820, Loss: 0.17069368751098404, Accuracy: 0.90805\n",
            "Batch: 830, Loss: 0.16919046872844762, Accuracy: 0.9091\n",
            "Batch: 840, Loss: 0.16854681949264377, Accuracy: 0.9088666666666667\n",
            "Batch: 850, Loss: 0.16824378048065472, Accuracy: 0.9093666666666667\n",
            "Batch: 860, Loss: 0.16937688338136636, Accuracy: 0.9085166666666666\n",
            "Batch: 870, Loss: 0.16895683565908481, Accuracy: 0.9089833333333334\n",
            "Batch: 880, Loss: 0.1684854761026723, Accuracy: 0.9095333333333333\n",
            "Batch: 890, Loss: 0.1684836536619674, Accuracy: 0.9094\n",
            "Batch: 900, Loss: 0.1687587839169253, Accuracy: 0.9091333333333333\n",
            "Batch: 910, Loss: 0.16792073234708513, Accuracy: 0.9096333333333333\n",
            "Batch: 920, Loss: 0.1679740169856213, Accuracy: 0.9098333333333334\n",
            "Batch: 930, Loss: 0.1688063638887569, Accuracy: 0.9093166666666667\n",
            "Epoch: 28, Loss: 0.1691062978598509, Accuracy: 0.9090666666666667\n",
            "Batch: 0, Loss: 0.16907366533948365, Accuracy: 0.9091666666666667\n",
            "Batch: 10, Loss: 0.17039021787880212, Accuracy: 0.9082833333333333\n",
            "Batch: 20, Loss: 0.16922822979045302, Accuracy: 0.909\n",
            "Batch: 30, Loss: 0.16879389422763533, Accuracy: 0.9094166666666667\n",
            "Batch: 40, Loss: 0.16807481480479447, Accuracy: 0.9098833333333334\n",
            "Batch: 50, Loss: 0.1682915100050834, Accuracy: 0.9101833333333333\n",
            "Batch: 60, Loss: 0.16756138971319584, Accuracy: 0.9105833333333333\n",
            "Batch: 70, Loss: 0.1671657670739459, Accuracy: 0.9106166666666666\n",
            "Batch: 80, Loss: 0.167387187084098, Accuracy: 0.9102333333333333\n",
            "Batch: 90, Loss: 0.16686276204078926, Accuracy: 0.9104666666666666\n",
            "Batch: 100, Loss: 0.16680982619434626, Accuracy: 0.91065\n",
            "Batch: 110, Loss: 0.16779280510809472, Accuracy: 0.9100166666666667\n",
            "Batch: 120, Loss: 0.167138618060986, Accuracy: 0.9102833333333333\n",
            "Batch: 130, Loss: 0.16842415813374667, Accuracy: 0.90955\n",
            "Batch: 140, Loss: 0.1693598839809837, Accuracy: 0.9093\n",
            "Batch: 150, Loss: 0.16776656304168583, Accuracy: 0.9100666666666667\n",
            "Batch: 160, Loss: 0.16820163058237494, Accuracy: 0.9100666666666667\n",
            "Batch: 170, Loss: 0.16687993756137323, Accuracy: 0.91085\n",
            "Batch: 180, Loss: 0.16705634544178347, Accuracy: 0.9110166666666667\n",
            "Batch: 190, Loss: 0.16847010793056777, Accuracy: 0.9099\n",
            "Batch: 200, Loss: 0.17008920870005406, Accuracy: 0.90955\n",
            "Batch: 210, Loss: 0.17026624782880195, Accuracy: 0.909\n",
            "Batch: 220, Loss: 0.17096813312985135, Accuracy: 0.9086333333333333\n",
            "Batch: 230, Loss: 0.16972413067452496, Accuracy: 0.9094333333333333\n",
            "Batch: 240, Loss: 0.16990850011195036, Accuracy: 0.9099166666666667\n",
            "Batch: 250, Loss: 0.16880909824590046, Accuracy: 0.9098666666666667\n",
            "Batch: 260, Loss: 0.1689566952185567, Accuracy: 0.9097833333333334\n",
            "Batch: 270, Loss: 0.16744473629991927, Accuracy: 0.9106333333333333\n",
            "Batch: 280, Loss: 0.16624828495617067, Accuracy: 0.9114333333333333\n",
            "Batch: 290, Loss: 0.16597571927893695, Accuracy: 0.9119333333333334\n",
            "Batch: 300, Loss: 0.1659215395410932, Accuracy: 0.91205\n",
            "Batch: 310, Loss: 0.16656865109273955, Accuracy: 0.9114166666666667\n",
            "Batch: 320, Loss: 0.16604985154970361, Accuracy: 0.9118833333333334\n",
            "Batch: 330, Loss: 0.16596251271429388, Accuracy: 0.9117333333333333\n",
            "Batch: 340, Loss: 0.1664794165470353, Accuracy: 0.9116666666666666\n",
            "Batch: 350, Loss: 0.16616561329878726, Accuracy: 0.9113\n",
            "Batch: 360, Loss: 0.1669574883850406, Accuracy: 0.9114333333333333\n",
            "Batch: 370, Loss: 0.1660326502289979, Accuracy: 0.9118\n",
            "Batch: 380, Loss: 0.1658233140380238, Accuracy: 0.9115833333333333\n",
            "Batch: 390, Loss: 0.16558532671123483, Accuracy: 0.9118\n",
            "Batch: 400, Loss: 0.1658190824266607, Accuracy: 0.9116666666666666\n",
            "Batch: 410, Loss: 0.16544985789535954, Accuracy: 0.9118666666666667\n",
            "Batch: 420, Loss: 0.16516455202661268, Accuracy: 0.9119666666666667\n",
            "Batch: 430, Loss: 0.16565570062568696, Accuracy: 0.9115833333333333\n",
            "Batch: 440, Loss: 0.16620072077467002, Accuracy: 0.9116333333333333\n",
            "Batch: 450, Loss: 0.16582154889774256, Accuracy: 0.9116166666666666\n",
            "Batch: 460, Loss: 0.1659305976534555, Accuracy: 0.9114333333333333\n",
            "Batch: 470, Loss: 0.16560249908089628, Accuracy: 0.9115\n",
            "Batch: 480, Loss: 0.16560068918867857, Accuracy: 0.9117\n",
            "Batch: 490, Loss: 0.16576475801303558, Accuracy: 0.9117833333333333\n",
            "Batch: 500, Loss: 0.16528665524255737, Accuracy: 0.9117333333333333\n",
            "Batch: 510, Loss: 0.16529354816871805, Accuracy: 0.9114166666666667\n",
            "Batch: 520, Loss: 0.16504171289725278, Accuracy: 0.9116833333333333\n",
            "Batch: 530, Loss: 0.16505908590476998, Accuracy: 0.9116\n",
            "Batch: 540, Loss: 0.16480071987920192, Accuracy: 0.91205\n",
            "Batch: 550, Loss: 0.16513523113725628, Accuracy: 0.9119666666666667\n",
            "Batch: 560, Loss: 0.16601500378148296, Accuracy: 0.9116833333333333\n",
            "Batch: 570, Loss: 0.16672257920732156, Accuracy: 0.9115666666666666\n",
            "Batch: 580, Loss: 0.1664167897917571, Accuracy: 0.91155\n",
            "Batch: 590, Loss: 0.16503082128654606, Accuracy: 0.9121333333333334\n",
            "Batch: 600, Loss: 0.16482232820637638, Accuracy: 0.9119666666666667\n",
            "Batch: 610, Loss: 0.16493474981625095, Accuracy: 0.9121333333333334\n",
            "Batch: 620, Loss: 0.16536091005688106, Accuracy: 0.9118\n",
            "Batch: 630, Loss: 0.16498648379354103, Accuracy: 0.9119833333333334\n",
            "Batch: 640, Loss: 0.1658571463335719, Accuracy: 0.9109166666666667\n",
            "Batch: 650, Loss: 0.16524989000493626, Accuracy: 0.9117166666666666\n",
            "Batch: 660, Loss: 0.16527964743333734, Accuracy: 0.9119666666666667\n",
            "Batch: 670, Loss: 0.1649503155134207, Accuracy: 0.9122\n",
            "Batch: 680, Loss: 0.16510092542272886, Accuracy: 0.9116666666666666\n",
            "Batch: 690, Loss: 0.16672586944100073, Accuracy: 0.9105166666666666\n",
            "Batch: 700, Loss: 0.16660912378016388, Accuracy: 0.91065\n",
            "Batch: 710, Loss: 0.1678128239827519, Accuracy: 0.91025\n",
            "Batch: 720, Loss: 0.16670052025176105, Accuracy: 0.9104166666666667\n",
            "Batch: 730, Loss: 0.16770771968014375, Accuracy: 0.91035\n",
            "Batch: 740, Loss: 0.16762196254338643, Accuracy: 0.91005\n",
            "Batch: 750, Loss: 0.16806008409702358, Accuracy: 0.9097333333333333\n",
            "Batch: 760, Loss: 0.1666819363691584, Accuracy: 0.91005\n",
            "Batch: 770, Loss: 0.16704962832462503, Accuracy: 0.9096333333333333\n",
            "Batch: 780, Loss: 0.16838823365144, Accuracy: 0.9090833333333334\n",
            "Batch: 790, Loss: 0.1676773543433913, Accuracy: 0.9094833333333333\n",
            "Batch: 800, Loss: 0.1683589454972285, Accuracy: 0.9096166666666666\n",
            "Batch: 810, Loss: 0.16769319394969862, Accuracy: 0.9097166666666666\n",
            "Batch: 820, Loss: 0.1678102314520195, Accuracy: 0.9095\n",
            "Batch: 830, Loss: 0.16631143804536533, Accuracy: 0.9102333333333333\n",
            "Batch: 840, Loss: 0.1657463698650868, Accuracy: 0.91025\n",
            "Batch: 850, Loss: 0.16548414051088195, Accuracy: 0.91075\n",
            "Batch: 860, Loss: 0.16663992642884126, Accuracy: 0.9099166666666667\n",
            "Batch: 870, Loss: 0.16621862402754894, Accuracy: 0.9102166666666667\n",
            "Batch: 880, Loss: 0.16578042693348294, Accuracy: 0.9105833333333333\n",
            "Batch: 890, Loss: 0.16592952261356902, Accuracy: 0.9105666666666666\n",
            "Batch: 900, Loss: 0.16615870483117115, Accuracy: 0.9105833333333333\n",
            "Batch: 910, Loss: 0.1652155000373214, Accuracy: 0.9108833333333334\n",
            "Batch: 920, Loss: 0.1652995884313765, Accuracy: 0.9110833333333334\n",
            "Batch: 930, Loss: 0.1660699359878617, Accuracy: 0.9107\n",
            "Epoch: 29, Loss: 0.16646247743357748, Accuracy: 0.9101333333333333\n",
            "Batch: 0, Loss: 0.16643446515647717, Accuracy: 0.9102333333333333\n",
            "Batch: 10, Loss: 0.16776389038649822, Accuracy: 0.9095333333333333\n",
            "Batch: 20, Loss: 0.16657537448887377, Accuracy: 0.9102333333333333\n",
            "Batch: 30, Loss: 0.1661422605549793, Accuracy: 0.91045\n",
            "Batch: 40, Loss: 0.1655009916182752, Accuracy: 0.9111833333333333\n",
            "Batch: 50, Loss: 0.1656479315549924, Accuracy: 0.9112\n",
            "Batch: 60, Loss: 0.16495407745748905, Accuracy: 0.9117333333333333\n",
            "Batch: 70, Loss: 0.16459577458048735, Accuracy: 0.9118333333333334\n",
            "Batch: 80, Loss: 0.1647067524045154, Accuracy: 0.9113833333333333\n",
            "Batch: 90, Loss: 0.16415960041016858, Accuracy: 0.9117666666666666\n",
            "Batch: 100, Loss: 0.16431711167112945, Accuracy: 0.9118333333333334\n",
            "Batch: 110, Loss: 0.1652623482739359, Accuracy: 0.9110833333333334\n",
            "Batch: 120, Loss: 0.1645419258304109, Accuracy: 0.9114333333333333\n",
            "Batch: 130, Loss: 0.16582723330493288, Accuracy: 0.9108333333333334\n",
            "Batch: 140, Loss: 0.1668413896444129, Accuracy: 0.91015\n",
            "Batch: 150, Loss: 0.16528460194962621, Accuracy: 0.9111666666666667\n",
            "Batch: 160, Loss: 0.16575505758774803, Accuracy: 0.9108333333333334\n",
            "Batch: 170, Loss: 0.1643175326868541, Accuracy: 0.9118\n",
            "Batch: 180, Loss: 0.16450301666101094, Accuracy: 0.91175\n",
            "Batch: 190, Loss: 0.16597442879078197, Accuracy: 0.9113166666666667\n",
            "Batch: 200, Loss: 0.16755468921786573, Accuracy: 0.9105166666666666\n",
            "Batch: 210, Loss: 0.16772468187365688, Accuracy: 0.9103\n",
            "Batch: 220, Loss: 0.16817678926260013, Accuracy: 0.9097833333333334\n",
            "Batch: 230, Loss: 0.1671014956230703, Accuracy: 0.91055\n",
            "Batch: 240, Loss: 0.1673829769141992, Accuracy: 0.9108666666666667\n",
            "Batch: 250, Loss: 0.16625539090104846, Accuracy: 0.91105\n",
            "Batch: 260, Loss: 0.16650270406854276, Accuracy: 0.9108333333333334\n",
            "Batch: 270, Loss: 0.16490040378121432, Accuracy: 0.9116666666666666\n",
            "Batch: 280, Loss: 0.16366695434860026, Accuracy: 0.91235\n",
            "Batch: 290, Loss: 0.1633841829560594, Accuracy: 0.9131166666666667\n",
            "Batch: 300, Loss: 0.1633404156844518, Accuracy: 0.91315\n",
            "Batch: 310, Loss: 0.16398299765189447, Accuracy: 0.9125166666666666\n",
            "Batch: 320, Loss: 0.16351818151983785, Accuracy: 0.91295\n",
            "Batch: 330, Loss: 0.16343674853738666, Accuracy: 0.91285\n",
            "Batch: 340, Loss: 0.16391990715510063, Accuracy: 0.9126166666666666\n",
            "Batch: 350, Loss: 0.16365434393538855, Accuracy: 0.91265\n",
            "Batch: 360, Loss: 0.16446705273676104, Accuracy: 0.9127\n",
            "Batch: 370, Loss: 0.1636156414396791, Accuracy: 0.9125833333333333\n",
            "Batch: 380, Loss: 0.1634188714871496, Accuracy: 0.9126333333333333\n",
            "Batch: 390, Loss: 0.1630778822657211, Accuracy: 0.9130166666666667\n",
            "Batch: 400, Loss: 0.16328973628310342, Accuracy: 0.9128833333333334\n",
            "Batch: 410, Loss: 0.1629124911063334, Accuracy: 0.9130166666666667\n",
            "Batch: 420, Loss: 0.1626028155096585, Accuracy: 0.91295\n",
            "Batch: 430, Loss: 0.16305983591834036, Accuracy: 0.9125666666666666\n",
            "Batch: 440, Loss: 0.16361095976136045, Accuracy: 0.9128\n",
            "Batch: 450, Loss: 0.16315103345946244, Accuracy: 0.9125833333333333\n",
            "Batch: 460, Loss: 0.16325557243752328, Accuracy: 0.91255\n",
            "Batch: 470, Loss: 0.16299306816283182, Accuracy: 0.9126666666666666\n",
            "Batch: 480, Loss: 0.16293797383284012, Accuracy: 0.91265\n",
            "Batch: 490, Loss: 0.16316176552084494, Accuracy: 0.91275\n",
            "Batch: 500, Loss: 0.16267737628404857, Accuracy: 0.91255\n",
            "Batch: 510, Loss: 0.16267274987139008, Accuracy: 0.91245\n",
            "Batch: 520, Loss: 0.16247391992644905, Accuracy: 0.91295\n",
            "Batch: 530, Loss: 0.16250044353826712, Accuracy: 0.9128666666666667\n",
            "Batch: 540, Loss: 0.16228389359180156, Accuracy: 0.9132833333333333\n",
            "Batch: 550, Loss: 0.16261042352855007, Accuracy: 0.9130833333333334\n",
            "Batch: 560, Loss: 0.16352613389539913, Accuracy: 0.9127666666666666\n",
            "Batch: 570, Loss: 0.16418336946473494, Accuracy: 0.9123833333333333\n",
            "Batch: 580, Loss: 0.1639221036176473, Accuracy: 0.9127666666666666\n",
            "Batch: 590, Loss: 0.16257074747992867, Accuracy: 0.91325\n",
            "Batch: 600, Loss: 0.16239658335280469, Accuracy: 0.9132333333333333\n",
            "Batch: 610, Loss: 0.16247874562681944, Accuracy: 0.9132833333333333\n",
            "Batch: 620, Loss: 0.16290867287638378, Accuracy: 0.9130333333333334\n",
            "Batch: 630, Loss: 0.162443288728862, Accuracy: 0.9130666666666667\n",
            "Batch: 640, Loss: 0.16323493829128224, Accuracy: 0.9124666666666666\n",
            "Batch: 650, Loss: 0.1628225347933174, Accuracy: 0.9129333333333334\n",
            "Batch: 660, Loss: 0.1627747986339327, Accuracy: 0.9130166666666667\n",
            "Batch: 670, Loss: 0.16249848855830182, Accuracy: 0.9133333333333333\n",
            "Batch: 680, Loss: 0.16251063555429726, Accuracy: 0.9128666666666667\n",
            "Batch: 690, Loss: 0.16411111346345528, Accuracy: 0.9117\n",
            "Batch: 700, Loss: 0.16403669401561013, Accuracy: 0.9118166666666667\n",
            "Batch: 710, Loss: 0.16507278217713237, Accuracy: 0.9112333333333333\n",
            "Batch: 720, Loss: 0.16397721610222304, Accuracy: 0.91145\n",
            "Batch: 730, Loss: 0.16482837212745252, Accuracy: 0.9113166666666667\n",
            "Batch: 740, Loss: 0.16487484749347175, Accuracy: 0.9111833333333333\n",
            "Batch: 750, Loss: 0.1653170103233593, Accuracy: 0.9108333333333334\n",
            "Batch: 760, Loss: 0.16396174791543533, Accuracy: 0.9116166666666666\n",
            "Batch: 770, Loss: 0.16444948418718344, Accuracy: 0.9109833333333334\n",
            "Batch: 780, Loss: 0.1656951662116004, Accuracy: 0.9105666666666666\n",
            "Batch: 790, Loss: 0.16498469584264466, Accuracy: 0.9107833333333333\n",
            "Batch: 800, Loss: 0.16573302817477467, Accuracy: 0.9106\n",
            "Batch: 810, Loss: 0.16501839803565957, Accuracy: 0.9109666666666667\n",
            "Batch: 820, Loss: 0.16504644287638265, Accuracy: 0.9109833333333334\n",
            "Batch: 830, Loss: 0.16352571229311208, Accuracy: 0.9111333333333334\n",
            "Batch: 840, Loss: 0.16307594339262918, Accuracy: 0.9114833333333333\n",
            "Batch: 850, Loss: 0.16292013313864628, Accuracy: 0.9123166666666667\n",
            "Batch: 860, Loss: 0.164068214254588, Accuracy: 0.9111666666666667\n",
            "Batch: 870, Loss: 0.16351002574370116, Accuracy: 0.9114833333333333\n",
            "Batch: 880, Loss: 0.1631158540134761, Accuracy: 0.9120666666666667\n",
            "Batch: 890, Loss: 0.1633748164326576, Accuracy: 0.91195\n",
            "Batch: 900, Loss: 0.16361950989933516, Accuracy: 0.9118\n",
            "Batch: 910, Loss: 0.16259903926495897, Accuracy: 0.9122666666666667\n",
            "Batch: 920, Loss: 0.1627289934154742, Accuracy: 0.9122333333333333\n",
            "Batch: 930, Loss: 0.16348207452782368, Accuracy: 0.9120333333333334\n",
            "Epoch: 30, Loss: 0.16388910521746775, Accuracy: 0.9116166666666666\n",
            "Batch: 0, Loss: 0.16386723600020342, Accuracy: 0.9116333333333333\n",
            "Batch: 10, Loss: 0.16523329190970756, Accuracy: 0.9109\n",
            "Batch: 20, Loss: 0.16397545415329498, Accuracy: 0.9116\n",
            "Batch: 30, Loss: 0.16358608050885554, Accuracy: 0.9116833333333333\n",
            "Batch: 40, Loss: 0.16298963169427802, Accuracy: 0.9123333333333333\n",
            "Batch: 50, Loss: 0.1630810225581497, Accuracy: 0.9121833333333333\n",
            "Batch: 60, Loss: 0.16240812991139064, Accuracy: 0.9127666666666666\n",
            "Batch: 70, Loss: 0.16210591706898556, Accuracy: 0.9129833333333334\n",
            "Batch: 80, Loss: 0.16210982979018393, Accuracy: 0.9125833333333333\n",
            "Batch: 90, Loss: 0.16158878773448376, Accuracy: 0.9130166666666667\n",
            "Batch: 100, Loss: 0.16190218584804136, Accuracy: 0.9129666666666667\n",
            "Batch: 110, Loss: 0.16282047205266306, Accuracy: 0.912\n",
            "Batch: 120, Loss: 0.16207012295379009, Accuracy: 0.91255\n",
            "Batch: 130, Loss: 0.1633527772498257, Accuracy: 0.9117833333333333\n",
            "Batch: 140, Loss: 0.16440919277696783, Accuracy: 0.9112833333333333\n",
            "Batch: 150, Loss: 0.16311383833852067, Accuracy: 0.9119666666666667\n",
            "Batch: 160, Loss: 0.16364324428757518, Accuracy: 0.9117166666666666\n",
            "Batch: 170, Loss: 0.16196749930158444, Accuracy: 0.9126166666666666\n",
            "Batch: 180, Loss: 0.16214704192367355, Accuracy: 0.91285\n",
            "Batch: 190, Loss: 0.1635607812849467, Accuracy: 0.9125166666666666\n",
            "Batch: 200, Loss: 0.16498981554222933, Accuracy: 0.9116\n",
            "Batch: 210, Loss: 0.16511590746883392, Accuracy: 0.91125\n",
            "Batch: 220, Loss: 0.16537213696764846, Accuracy: 0.91105\n",
            "Batch: 230, Loss: 0.16452154227765323, Accuracy: 0.9116833333333333\n",
            "Batch: 240, Loss: 0.16486431161646292, Accuracy: 0.9119333333333334\n",
            "Batch: 250, Loss: 0.16374883216908065, Accuracy: 0.9121166666666667\n",
            "Batch: 260, Loss: 0.16408260461181995, Accuracy: 0.9115666666666666\n",
            "Batch: 270, Loss: 0.16238849334134914, Accuracy: 0.9128666666666667\n",
            "Batch: 280, Loss: 0.16122059603224265, Accuracy: 0.9135833333333333\n",
            "Batch: 290, Loss: 0.16096838242112763, Accuracy: 0.9143\n",
            "Batch: 300, Loss: 0.16091290854588153, Accuracy: 0.9140833333333334\n",
            "Batch: 310, Loss: 0.16152268584844445, Accuracy: 0.9135333333333333\n",
            "Batch: 320, Loss: 0.1611345297343928, Accuracy: 0.9139833333333334\n",
            "Batch: 330, Loss: 0.16105181678767144, Accuracy: 0.9138833333333334\n",
            "Batch: 340, Loss: 0.1614915584233868, Accuracy: 0.9137\n",
            "Batch: 350, Loss: 0.16129560275257926, Accuracy: 0.9139166666666667\n",
            "Batch: 360, Loss: 0.16215712987772002, Accuracy: 0.9137333333333333\n",
            "Batch: 370, Loss: 0.1612990892646099, Accuracy: 0.91365\n",
            "Batch: 380, Loss: 0.1610894675837302, Accuracy: 0.9138\n",
            "Batch: 390, Loss: 0.16070394370105756, Accuracy: 0.9140666666666667\n",
            "Batch: 400, Loss: 0.1608757858529375, Accuracy: 0.9137\n",
            "Batch: 410, Loss: 0.16050021203050524, Accuracy: 0.9140833333333334\n",
            "Batch: 420, Loss: 0.16018046768770947, Accuracy: 0.91405\n",
            "Batch: 430, Loss: 0.16066362470370332, Accuracy: 0.9136833333333333\n",
            "Batch: 440, Loss: 0.16117651259065746, Accuracy: 0.91375\n",
            "Batch: 450, Loss: 0.16065052114533993, Accuracy: 0.9138666666666667\n",
            "Batch: 460, Loss: 0.160802438415137, Accuracy: 0.9136\n",
            "Batch: 470, Loss: 0.16052848683630278, Accuracy: 0.9136333333333333\n",
            "Batch: 480, Loss: 0.16043174146551908, Accuracy: 0.91385\n",
            "Batch: 490, Loss: 0.16067480294896816, Accuracy: 0.9138833333333334\n",
            "Batch: 500, Loss: 0.16016195008049056, Accuracy: 0.9138833333333334\n",
            "Batch: 510, Loss: 0.1601787073140789, Accuracy: 0.9137833333333333\n",
            "Batch: 520, Loss: 0.16000340615196795, Accuracy: 0.91405\n",
            "Batch: 530, Loss: 0.16010406112440395, Accuracy: 0.9141333333333334\n",
            "Batch: 540, Loss: 0.15996229827307634, Accuracy: 0.9142\n",
            "Batch: 550, Loss: 0.1602553087675765, Accuracy: 0.9139166666666667\n",
            "Batch: 560, Loss: 0.1611967896974445, Accuracy: 0.9135\n",
            "Batch: 570, Loss: 0.16183618389480556, Accuracy: 0.91345\n",
            "Batch: 580, Loss: 0.16155074073526973, Accuracy: 0.9137\n",
            "Batch: 590, Loss: 0.1602156535619053, Accuracy: 0.91435\n",
            "Batch: 600, Loss: 0.1600229134085858, Accuracy: 0.9140166666666667\n",
            "Batch: 610, Loss: 0.160152446715316, Accuracy: 0.9145666666666666\n",
            "Batch: 620, Loss: 0.1605038173497153, Accuracy: 0.91405\n",
            "Batch: 630, Loss: 0.1600854774197799, Accuracy: 0.9140833333333334\n",
            "Batch: 640, Loss: 0.16072977403568642, Accuracy: 0.9134333333333333\n",
            "Batch: 650, Loss: 0.1604543861665926, Accuracy: 0.9138666666666667\n",
            "Batch: 660, Loss: 0.16035524301531112, Accuracy: 0.9140833333333334\n",
            "Batch: 670, Loss: 0.16012015848719785, Accuracy: 0.91425\n",
            "Batch: 680, Loss: 0.1600395210876888, Accuracy: 0.9140666666666667\n",
            "Batch: 690, Loss: 0.1615146578099365, Accuracy: 0.91285\n",
            "Batch: 700, Loss: 0.16150406266195652, Accuracy: 0.9129833333333334\n",
            "Batch: 710, Loss: 0.1624727432295337, Accuracy: 0.9122666666666667\n",
            "Batch: 720, Loss: 0.16143065068296245, Accuracy: 0.9126166666666666\n",
            "Batch: 730, Loss: 0.16209516014326847, Accuracy: 0.9125166666666666\n",
            "Batch: 740, Loss: 0.16220399429913412, Accuracy: 0.9126666666666666\n",
            "Batch: 750, Loss: 0.1626432519100145, Accuracy: 0.9119333333333334\n",
            "Batch: 760, Loss: 0.1613740940722707, Accuracy: 0.9127666666666666\n",
            "Batch: 770, Loss: 0.16191293189967054, Accuracy: 0.91235\n",
            "Batch: 780, Loss: 0.16310480927306623, Accuracy: 0.9115833333333333\n",
            "Batch: 790, Loss: 0.16242320434122687, Accuracy: 0.91195\n",
            "Batch: 800, Loss: 0.16321041100723946, Accuracy: 0.9119333333333334\n",
            "Batch: 810, Loss: 0.16244552609063825, Accuracy: 0.9119333333333334\n",
            "Batch: 820, Loss: 0.16241772197626872, Accuracy: 0.91215\n",
            "Batch: 830, Loss: 0.16088352337305167, Accuracy: 0.91255\n",
            "Batch: 840, Loss: 0.1605435231450779, Accuracy: 0.9127833333333333\n",
            "Batch: 850, Loss: 0.1604945293832942, Accuracy: 0.9132166666666667\n",
            "Batch: 860, Loss: 0.1616114557817579, Accuracy: 0.91225\n",
            "Batch: 870, Loss: 0.16091497521037168, Accuracy: 0.9128\n",
            "Batch: 880, Loss: 0.16055694206484053, Accuracy: 0.9131166666666667\n",
            "Batch: 890, Loss: 0.16088093140120466, Accuracy: 0.91295\n",
            "Batch: 900, Loss: 0.16116260475090552, Accuracy: 0.9128166666666667\n",
            "Batch: 910, Loss: 0.16011592279360293, Accuracy: 0.9134\n",
            "Batch: 920, Loss: 0.16023889437096528, Accuracy: 0.9132833333333333\n",
            "Batch: 930, Loss: 0.16104377160082675, Accuracy: 0.913\n",
            "Epoch: 31, Loss: 0.16145278365250074, Accuracy: 0.9127333333333333\n",
            "Batch: 0, Loss: 0.16142888448312184, Accuracy: 0.9128833333333334\n",
            "Batch: 10, Loss: 0.16274107512085717, Accuracy: 0.912\n",
            "Batch: 20, Loss: 0.1614177514155576, Accuracy: 0.9131333333333334\n",
            "Batch: 30, Loss: 0.16110527518650633, Accuracy: 0.9129\n",
            "Batch: 40, Loss: 0.16048351225874713, Accuracy: 0.91345\n",
            "Batch: 50, Loss: 0.16058736088930786, Accuracy: 0.9133666666666667\n",
            "Batch: 60, Loss: 0.1599461774888513, Accuracy: 0.9139166666666667\n",
            "Batch: 70, Loss: 0.15967746588417453, Accuracy: 0.9141166666666667\n",
            "Batch: 80, Loss: 0.15966066237113494, Accuracy: 0.91375\n",
            "Batch: 90, Loss: 0.15917804910376984, Accuracy: 0.9139833333333334\n",
            "Batch: 100, Loss: 0.15950249974666086, Accuracy: 0.9138833333333334\n",
            "Batch: 110, Loss: 0.16034042886491923, Accuracy: 0.9130333333333334\n",
            "Batch: 120, Loss: 0.1596189083595655, Accuracy: 0.9135833333333333\n",
            "Batch: 130, Loss: 0.1609134500073335, Accuracy: 0.9129666666666667\n",
            "Batch: 140, Loss: 0.16201728910194788, Accuracy: 0.9124666666666666\n",
            "Batch: 150, Loss: 0.16076413646117685, Accuracy: 0.9129166666666667\n",
            "Batch: 160, Loss: 0.1613491578438091, Accuracy: 0.9127833333333333\n",
            "Batch: 170, Loss: 0.15958322909653916, Accuracy: 0.91355\n",
            "Batch: 180, Loss: 0.15972440920090056, Accuracy: 0.9135833333333333\n",
            "Batch: 190, Loss: 0.161179998318257, Accuracy: 0.9133333333333333\n",
            "Batch: 200, Loss: 0.16239701861284409, Accuracy: 0.9125333333333333\n",
            "Batch: 210, Loss: 0.16249882849799585, Accuracy: 0.9125\n",
            "Batch: 220, Loss: 0.162852070115779, Accuracy: 0.91235\n",
            "Batch: 230, Loss: 0.1620852195466069, Accuracy: 0.9129166666666667\n",
            "Batch: 240, Loss: 0.162459489614679, Accuracy: 0.91295\n",
            "Batch: 250, Loss: 0.16132872496057243, Accuracy: 0.9131666666666667\n",
            "Batch: 260, Loss: 0.16179579339716582, Accuracy: 0.9129333333333334\n",
            "Batch: 270, Loss: 0.15995626912409652, Accuracy: 0.9138166666666667\n",
            "Batch: 280, Loss: 0.15881033341737436, Accuracy: 0.9148166666666666\n",
            "Batch: 290, Loss: 0.1586355880350209, Accuracy: 0.9151166666666667\n",
            "Batch: 300, Loss: 0.15855811278836474, Accuracy: 0.91505\n",
            "Batch: 310, Loss: 0.15909179397660245, Accuracy: 0.9148\n",
            "Batch: 320, Loss: 0.15883403931619272, Accuracy: 0.9148166666666666\n",
            "Batch: 330, Loss: 0.15870089204823104, Accuracy: 0.9148666666666667\n",
            "Batch: 340, Loss: 0.15920041451549433, Accuracy: 0.9145666666666666\n",
            "Batch: 350, Loss: 0.15902719840149016, Accuracy: 0.9147833333333333\n",
            "Batch: 360, Loss: 0.15994067194054223, Accuracy: 0.9147\n",
            "Batch: 370, Loss: 0.15903663865312326, Accuracy: 0.9148\n",
            "Batch: 380, Loss: 0.15878553267578802, Accuracy: 0.91475\n",
            "Batch: 390, Loss: 0.15839368072515342, Accuracy: 0.9150666666666667\n",
            "Batch: 400, Loss: 0.1585310987852338, Accuracy: 0.9146166666666666\n",
            "Batch: 410, Loss: 0.1581744927187536, Accuracy: 0.915\n",
            "Batch: 420, Loss: 0.15784335639012023, Accuracy: 0.9149833333333334\n",
            "Batch: 430, Loss: 0.15843016413681346, Accuracy: 0.9145333333333333\n",
            "Batch: 440, Loss: 0.15887243783402197, Accuracy: 0.9146333333333333\n",
            "Batch: 450, Loss: 0.15828881189580776, Accuracy: 0.9149833333333334\n",
            "Batch: 460, Loss: 0.15845992098617867, Accuracy: 0.9146666666666666\n",
            "Batch: 470, Loss: 0.15811533044384685, Accuracy: 0.9148\n",
            "Batch: 480, Loss: 0.15801357874094957, Accuracy: 0.9149666666666667\n",
            "Batch: 490, Loss: 0.15824427162106416, Accuracy: 0.9149166666666667\n",
            "Batch: 500, Loss: 0.15773465116819685, Accuracy: 0.9150666666666667\n",
            "Batch: 510, Loss: 0.15781384536900556, Accuracy: 0.91475\n",
            "Batch: 520, Loss: 0.15766700521626034, Accuracy: 0.9151333333333334\n",
            "Batch: 530, Loss: 0.15776198996479265, Accuracy: 0.9149166666666667\n",
            "Batch: 540, Loss: 0.15763172258680938, Accuracy: 0.9152166666666667\n",
            "Batch: 550, Loss: 0.15789717846990015, Accuracy: 0.91515\n",
            "Batch: 560, Loss: 0.1588614396230165, Accuracy: 0.9147666666666666\n",
            "Batch: 570, Loss: 0.15953327553687127, Accuracy: 0.91445\n",
            "Batch: 580, Loss: 0.15924163111210507, Accuracy: 0.9146833333333333\n",
            "Batch: 590, Loss: 0.15790610144373432, Accuracy: 0.9152833333333333\n",
            "Batch: 600, Loss: 0.15771196605776067, Accuracy: 0.9154666666666667\n",
            "Batch: 610, Loss: 0.1578642702806788, Accuracy: 0.9152333333333333\n",
            "Batch: 620, Loss: 0.15817044490112322, Accuracy: 0.915\n",
            "Batch: 630, Loss: 0.15775747865141293, Accuracy: 0.9150833333333334\n",
            "Batch: 640, Loss: 0.15831876302322231, Accuracy: 0.9144\n",
            "Batch: 650, Loss: 0.15815398085906382, Accuracy: 0.9149166666666667\n",
            "Batch: 660, Loss: 0.15802331837484793, Accuracy: 0.9150666666666667\n",
            "Batch: 670, Loss: 0.15782710741714603, Accuracy: 0.9152\n",
            "Batch: 680, Loss: 0.15770048918092436, Accuracy: 0.9149666666666667\n",
            "Batch: 690, Loss: 0.15907135050313384, Accuracy: 0.9140833333333334\n",
            "Batch: 700, Loss: 0.15910253715408074, Accuracy: 0.9141666666666667\n",
            "Batch: 710, Loss: 0.16010046361155839, Accuracy: 0.9134333333333333\n",
            "Batch: 720, Loss: 0.15908871164926544, Accuracy: 0.91405\n",
            "Batch: 730, Loss: 0.15962129764218339, Accuracy: 0.9138\n",
            "Batch: 740, Loss: 0.15972749781981307, Accuracy: 0.91385\n",
            "Batch: 750, Loss: 0.15997747730727688, Accuracy: 0.9136166666666666\n",
            "Batch: 760, Loss: 0.15885469321390588, Accuracy: 0.91375\n",
            "Batch: 770, Loss: 0.15944151582622915, Accuracy: 0.9136166666666666\n",
            "Batch: 780, Loss: 0.1605013375224097, Accuracy: 0.9126\n",
            "Batch: 790, Loss: 0.1599163853958641, Accuracy: 0.91305\n",
            "Batch: 800, Loss: 0.16075502783024903, Accuracy: 0.9128\n",
            "Batch: 810, Loss: 0.1599323013280201, Accuracy: 0.91275\n",
            "Batch: 820, Loss: 0.15989417326176544, Accuracy: 0.91315\n",
            "Batch: 830, Loss: 0.15840791691553516, Accuracy: 0.9134833333333333\n",
            "Batch: 840, Loss: 0.15812594762782917, Accuracy: 0.9138333333333334\n",
            "Batch: 850, Loss: 0.15814350806410687, Accuracy: 0.9140166666666667\n",
            "Batch: 860, Loss: 0.15927979959946947, Accuracy: 0.9134833333333333\n",
            "Batch: 870, Loss: 0.15847082805181295, Accuracy: 0.91365\n",
            "Batch: 880, Loss: 0.1581441930874112, Accuracy: 0.9139333333333334\n",
            "Batch: 890, Loss: 0.15842135723085493, Accuracy: 0.9139\n",
            "Batch: 900, Loss: 0.1587796653044166, Accuracy: 0.9137166666666666\n",
            "Batch: 910, Loss: 0.15770680289156444, Accuracy: 0.9145833333333333\n",
            "Batch: 920, Loss: 0.15784623495782324, Accuracy: 0.9142166666666667\n",
            "Batch: 930, Loss: 0.1586215929168075, Accuracy: 0.91415\n",
            "Epoch: 32, Loss: 0.15902230071852017, Accuracy: 0.9138833333333334\n",
            "Batch: 0, Loss: 0.15899569187244564, Accuracy: 0.9139666666666667\n",
            "Batch: 10, Loss: 0.16022632552514854, Accuracy: 0.91315\n",
            "Batch: 20, Loss: 0.15887550855821406, Accuracy: 0.9140333333333334\n",
            "Batch: 30, Loss: 0.15865001661590522, Accuracy: 0.91415\n",
            "Batch: 40, Loss: 0.1579778264725069, Accuracy: 0.9145666666666666\n",
            "Batch: 50, Loss: 0.1581194323057159, Accuracy: 0.91435\n",
            "Batch: 60, Loss: 0.15757401890798267, Accuracy: 0.9149166666666667\n",
            "Batch: 70, Loss: 0.15731496014206134, Accuracy: 0.9150166666666667\n",
            "Batch: 80, Loss: 0.15730353770264538, Accuracy: 0.9146333333333333\n",
            "Batch: 90, Loss: 0.15683285377820447, Accuracy: 0.9151\n",
            "Batch: 100, Loss: 0.157103190099054, Accuracy: 0.91485\n",
            "Batch: 110, Loss: 0.15789176151549683, Accuracy: 0.9141166666666667\n",
            "Batch: 120, Loss: 0.15721185071408345, Accuracy: 0.91445\n",
            "Batch: 130, Loss: 0.15849303301641193, Accuracy: 0.91405\n",
            "Batch: 140, Loss: 0.15965035600854954, Accuracy: 0.9133\n",
            "Batch: 150, Loss: 0.15841620899902747, Accuracy: 0.9141\n",
            "Batch: 160, Loss: 0.15890859542255212, Accuracy: 0.9137833333333333\n",
            "Batch: 170, Loss: 0.15720435193924742, Accuracy: 0.9147666666666666\n",
            "Batch: 180, Loss: 0.15729371876757653, Accuracy: 0.9147\n",
            "Batch: 190, Loss: 0.15875152636544004, Accuracy: 0.91455\n",
            "Batch: 200, Loss: 0.1597632294375353, Accuracy: 0.9135666666666666\n",
            "Batch: 210, Loss: 0.15993356403301204, Accuracy: 0.9138166666666667\n",
            "Batch: 220, Loss: 0.16040472331984182, Accuracy: 0.91345\n",
            "Batch: 230, Loss: 0.1596686667534287, Accuracy: 0.9139666666666667\n",
            "Batch: 240, Loss: 0.16008100926283927, Accuracy: 0.914\n",
            "Batch: 250, Loss: 0.15896348860716208, Accuracy: 0.9145\n",
            "Batch: 260, Loss: 0.15954512519950223, Accuracy: 0.9139833333333334\n",
            "Batch: 270, Loss: 0.1576346353482762, Accuracy: 0.9150833333333334\n",
            "Batch: 280, Loss: 0.1564827470290687, Accuracy: 0.9158666666666667\n",
            "Batch: 290, Loss: 0.15635954739275662, Accuracy: 0.9161\n",
            "Batch: 300, Loss: 0.15626153289613084, Accuracy: 0.91595\n",
            "Batch: 310, Loss: 0.1567469375193974, Accuracy: 0.9156333333333333\n",
            "Batch: 320, Loss: 0.15657040046586138, Accuracy: 0.91565\n",
            "Batch: 330, Loss: 0.1564086591274326, Accuracy: 0.91585\n",
            "Batch: 340, Loss: 0.1569818024037194, Accuracy: 0.9155666666666666\n",
            "Batch: 350, Loss: 0.15677887886114109, Accuracy: 0.91595\n",
            "Batch: 360, Loss: 0.15774512012861908, Accuracy: 0.91565\n",
            "Batch: 370, Loss: 0.1567971185755474, Accuracy: 0.9157833333333333\n",
            "Batch: 380, Loss: 0.1564900258116855, Accuracy: 0.91575\n",
            "Batch: 390, Loss: 0.1561203612070112, Accuracy: 0.91595\n",
            "Batch: 400, Loss: 0.15625240375534657, Accuracy: 0.9154666666666667\n",
            "Batch: 410, Loss: 0.15589445440118158, Accuracy: 0.9157333333333333\n",
            "Batch: 420, Loss: 0.15557486729612952, Accuracy: 0.9158166666666666\n",
            "Batch: 430, Loss: 0.1562349941013131, Accuracy: 0.9156\n",
            "Batch: 440, Loss: 0.15660712451918465, Accuracy: 0.9157666666666666\n",
            "Batch: 450, Loss: 0.15597709943638213, Accuracy: 0.9156833333333333\n",
            "Batch: 460, Loss: 0.15617609270913393, Accuracy: 0.9157666666666666\n",
            "Batch: 470, Loss: 0.15576285625168457, Accuracy: 0.9158166666666666\n",
            "Batch: 480, Loss: 0.15563017284041336, Accuracy: 0.9159833333333334\n",
            "Batch: 490, Loss: 0.1558502784097256, Accuracy: 0.9159\n",
            "Batch: 500, Loss: 0.15542685677646834, Accuracy: 0.9162166666666667\n",
            "Batch: 510, Loss: 0.1555015316868652, Accuracy: 0.9156333333333333\n",
            "Batch: 520, Loss: 0.15541621921172216, Accuracy: 0.9160666666666667\n",
            "Batch: 530, Loss: 0.15543406208481886, Accuracy: 0.9161166666666667\n",
            "Batch: 540, Loss: 0.15532880838697063, Accuracy: 0.9162666666666667\n",
            "Batch: 550, Loss: 0.15558064608863592, Accuracy: 0.91635\n",
            "Batch: 560, Loss: 0.15654819192914313, Accuracy: 0.9158833333333334\n",
            "Batch: 570, Loss: 0.1572283875060741, Accuracy: 0.9153\n",
            "Batch: 580, Loss: 0.1570458707907994, Accuracy: 0.9156333333333333\n",
            "Batch: 590, Loss: 0.1557082631942108, Accuracy: 0.91615\n",
            "Batch: 600, Loss: 0.15555905549221852, Accuracy: 0.9162333333333333\n",
            "Batch: 610, Loss: 0.15567686274748757, Accuracy: 0.9161833333333333\n",
            "Batch: 620, Loss: 0.15596557429833308, Accuracy: 0.9159833333333334\n",
            "Batch: 630, Loss: 0.15552498173939455, Accuracy: 0.9162666666666667\n",
            "Batch: 640, Loss: 0.15601813578391407, Accuracy: 0.9157666666666666\n",
            "Batch: 650, Loss: 0.15588740402090473, Accuracy: 0.91585\n",
            "Batch: 660, Loss: 0.1557455855754873, Accuracy: 0.9159666666666667\n",
            "Batch: 670, Loss: 0.15559284576383794, Accuracy: 0.9162333333333333\n",
            "Batch: 680, Loss: 0.15543980650647005, Accuracy: 0.9158333333333334\n",
            "Batch: 690, Loss: 0.15670710980403194, Accuracy: 0.9150333333333334\n",
            "Batch: 700, Loss: 0.15678463763560357, Accuracy: 0.9152\n",
            "Batch: 710, Loss: 0.15781641863319035, Accuracy: 0.9144\n",
            "Batch: 720, Loss: 0.15680304711251541, Accuracy: 0.915\n",
            "Batch: 730, Loss: 0.1572119421559052, Accuracy: 0.9148333333333334\n",
            "Batch: 740, Loss: 0.15729620688400123, Accuracy: 0.9148833333333334\n",
            "Batch: 750, Loss: 0.15753838585006072, Accuracy: 0.9147333333333333\n",
            "Batch: 760, Loss: 0.15646644673007074, Accuracy: 0.9147666666666666\n",
            "Batch: 770, Loss: 0.157074313947563, Accuracy: 0.9146\n",
            "Batch: 780, Loss: 0.1579938450278886, Accuracy: 0.9135833333333333\n",
            "Batch: 790, Loss: 0.1574630495387591, Accuracy: 0.9139833333333334\n",
            "Batch: 800, Loss: 0.15836704802270649, Accuracy: 0.9137666666666666\n",
            "Batch: 810, Loss: 0.15751268672081786, Accuracy: 0.9137\n",
            "Batch: 820, Loss: 0.1574705720766666, Accuracy: 0.9141833333333333\n",
            "Batch: 830, Loss: 0.15605207190370346, Accuracy: 0.9148166666666666\n",
            "Batch: 840, Loss: 0.15578021786594562, Accuracy: 0.9150333333333334\n",
            "Batch: 850, Loss: 0.15582340618035878, Accuracy: 0.9152\n",
            "Batch: 860, Loss: 0.156974489647354, Accuracy: 0.9143666666666667\n",
            "Batch: 870, Loss: 0.15603904080853878, Accuracy: 0.91445\n",
            "Batch: 880, Loss: 0.1557887491882591, Accuracy: 0.9147666666666666\n",
            "Batch: 890, Loss: 0.1559955254548787, Accuracy: 0.9147333333333333\n",
            "Batch: 900, Loss: 0.1563583765943734, Accuracy: 0.9147\n",
            "Batch: 910, Loss: 0.15529452688853662, Accuracy: 0.9154833333333333\n",
            "Batch: 920, Loss: 0.15547689954787833, Accuracy: 0.91505\n",
            "Batch: 930, Loss: 0.1562178514345413, Accuracy: 0.9150666666666667\n",
            "Epoch: 33, Loss: 0.15660541595352861, Accuracy: 0.9147166666666666\n",
            "Batch: 0, Loss: 0.15657978429294542, Accuracy: 0.9148666666666667\n",
            "Batch: 10, Loss: 0.15778116725280653, Accuracy: 0.9143833333333333\n",
            "Batch: 20, Loss: 0.15643873743333905, Accuracy: 0.9150833333333334\n",
            "Batch: 30, Loss: 0.1562438056731871, Accuracy: 0.9151666666666667\n",
            "Batch: 40, Loss: 0.15553126527446326, Accuracy: 0.9157\n",
            "Batch: 50, Loss: 0.1557453226734997, Accuracy: 0.9156\n",
            "Batch: 60, Loss: 0.1552182525860029, Accuracy: 0.9158833333333334\n",
            "Batch: 70, Loss: 0.15496056277587603, Accuracy: 0.9159333333333334\n",
            "Batch: 80, Loss: 0.15490616528148743, Accuracy: 0.9156666666666666\n",
            "Batch: 90, Loss: 0.15447829771040622, Accuracy: 0.9162166666666667\n",
            "Batch: 100, Loss: 0.15467657197054302, Accuracy: 0.9157166666666666\n",
            "Batch: 110, Loss: 0.15541061621798072, Accuracy: 0.9150166666666667\n",
            "Batch: 120, Loss: 0.15486773283025954, Accuracy: 0.9156\n",
            "Batch: 130, Loss: 0.15611063370544406, Accuracy: 0.9148833333333334\n",
            "Batch: 140, Loss: 0.15735328485137617, Accuracy: 0.9141833333333333\n",
            "Batch: 150, Loss: 0.15616938849010695, Accuracy: 0.9148333333333334\n",
            "Batch: 160, Loss: 0.15654364077082986, Accuracy: 0.91465\n",
            "Batch: 170, Loss: 0.1549233761146809, Accuracy: 0.9157\n",
            "Batch: 180, Loss: 0.15497945435477165, Accuracy: 0.9156\n",
            "Batch: 190, Loss: 0.15633182695608752, Accuracy: 0.9155\n",
            "Batch: 200, Loss: 0.15717411262391992, Accuracy: 0.9144666666666666\n",
            "Batch: 210, Loss: 0.1574572569800575, Accuracy: 0.9149833333333334\n",
            "Batch: 220, Loss: 0.15797373560068395, Accuracy: 0.9147666666666666\n",
            "Batch: 230, Loss: 0.15730507469757518, Accuracy: 0.9147833333333333\n",
            "Batch: 240, Loss: 0.15772603249553332, Accuracy: 0.9151166666666667\n",
            "Batch: 250, Loss: 0.1566774609646255, Accuracy: 0.9156833333333333\n",
            "Batch: 260, Loss: 0.15732555713481464, Accuracy: 0.9153666666666667\n",
            "Batch: 270, Loss: 0.15536981398839186, Accuracy: 0.91605\n",
            "Batch: 280, Loss: 0.15423715100351312, Accuracy: 0.9165333333333333\n",
            "Batch: 290, Loss: 0.15415502420394256, Accuracy: 0.9171333333333334\n",
            "Batch: 300, Loss: 0.15402844973069707, Accuracy: 0.917\n",
            "Batch: 310, Loss: 0.15444973810801887, Accuracy: 0.91665\n",
            "Batch: 320, Loss: 0.15433610447119203, Accuracy: 0.91655\n",
            "Batch: 330, Loss: 0.1541959659171092, Accuracy: 0.9169166666666667\n",
            "Batch: 340, Loss: 0.1548101750989373, Accuracy: 0.9165333333333333\n",
            "Batch: 350, Loss: 0.15459696938349066, Accuracy: 0.9169833333333334\n",
            "Batch: 360, Loss: 0.15559105137495716, Accuracy: 0.9164666666666667\n",
            "Batch: 370, Loss: 0.15462434698644428, Accuracy: 0.9170833333333334\n",
            "Batch: 380, Loss: 0.1542653938141648, Accuracy: 0.9166\n",
            "Batch: 390, Loss: 0.15391577974335355, Accuracy: 0.9171333333333334\n",
            "Batch: 400, Loss: 0.15403954120379687, Accuracy: 0.9164833333333333\n",
            "Batch: 410, Loss: 0.1536909931848371, Accuracy: 0.9167833333333333\n",
            "Batch: 420, Loss: 0.15339785874602446, Accuracy: 0.9167833333333333\n",
            "Batch: 430, Loss: 0.1540959976576969, Accuracy: 0.9164833333333333\n",
            "Batch: 440, Loss: 0.15444623314757816, Accuracy: 0.9169\n",
            "Batch: 450, Loss: 0.15376093303417998, Accuracy: 0.9168333333333333\n",
            "Batch: 460, Loss: 0.15400015395307184, Accuracy: 0.9165666666666666\n",
            "Batch: 470, Loss: 0.15357630742330305, Accuracy: 0.917\n",
            "Batch: 480, Loss: 0.1533589512446552, Accuracy: 0.9172833333333333\n",
            "Batch: 490, Loss: 0.15358582388070455, Accuracy: 0.9171333333333334\n",
            "Batch: 500, Loss: 0.15322087573364618, Accuracy: 0.91715\n",
            "Batch: 510, Loss: 0.15325139871147947, Accuracy: 0.9165833333333333\n",
            "Batch: 520, Loss: 0.1532606633685096, Accuracy: 0.9171333333333334\n",
            "Batch: 530, Loss: 0.15316695388317514, Accuracy: 0.9173166666666667\n",
            "Batch: 540, Loss: 0.15307488130205288, Accuracy: 0.9174833333333333\n",
            "Batch: 550, Loss: 0.15331348628053268, Accuracy: 0.9173333333333333\n",
            "Batch: 560, Loss: 0.15429086052426386, Accuracy: 0.9169\n",
            "Batch: 570, Loss: 0.1549940023321634, Accuracy: 0.9163666666666667\n",
            "Batch: 580, Loss: 0.15486223796331955, Accuracy: 0.9165333333333333\n",
            "Batch: 590, Loss: 0.1535023701623277, Accuracy: 0.9171833333333334\n",
            "Batch: 600, Loss: 0.15349476223049638, Accuracy: 0.9170333333333334\n",
            "Batch: 610, Loss: 0.15356906074279475, Accuracy: 0.9173166666666667\n",
            "Batch: 620, Loss: 0.15379143194464254, Accuracy: 0.9168\n",
            "Batch: 630, Loss: 0.15333031553288265, Accuracy: 0.9169333333333334\n",
            "Batch: 640, Loss: 0.15376464641611218, Accuracy: 0.9167666666666666\n",
            "Batch: 650, Loss: 0.15362068253292274, Accuracy: 0.917\n",
            "Batch: 660, Loss: 0.15347646008169163, Accuracy: 0.9169\n",
            "Batch: 670, Loss: 0.15338377297721695, Accuracy: 0.9170166666666667\n",
            "Batch: 680, Loss: 0.1532462445326165, Accuracy: 0.9168333333333333\n",
            "Batch: 690, Loss: 0.15442927719575475, Accuracy: 0.9160833333333334\n",
            "Batch: 700, Loss: 0.15451334404660658, Accuracy: 0.9159166666666667\n",
            "Batch: 710, Loss: 0.15557084270227145, Accuracy: 0.9153833333333333\n",
            "Batch: 720, Loss: 0.1545665904763235, Accuracy: 0.9158333333333334\n",
            "Batch: 730, Loss: 0.15494855062902443, Accuracy: 0.9157833333333333\n",
            "Batch: 740, Loss: 0.1549566907080984, Accuracy: 0.9158\n",
            "Batch: 750, Loss: 0.15527570133962568, Accuracy: 0.9155833333333333\n",
            "Batch: 760, Loss: 0.1541695866720809, Accuracy: 0.9159\n",
            "Batch: 770, Loss: 0.15476020372527255, Accuracy: 0.9154166666666667\n",
            "Batch: 780, Loss: 0.15562934386773813, Accuracy: 0.9148\n",
            "Batch: 790, Loss: 0.15510933060374202, Accuracy: 0.91495\n",
            "Batch: 800, Loss: 0.15593829212501167, Accuracy: 0.9148\n",
            "Batch: 810, Loss: 0.15507827306056984, Accuracy: 0.9149166666666667\n",
            "Batch: 820, Loss: 0.15508376476593813, Accuracy: 0.9151666666666667\n",
            "Batch: 830, Loss: 0.1537463386154175, Accuracy: 0.9160166666666667\n",
            "Batch: 840, Loss: 0.15347772283859504, Accuracy: 0.9161666666666667\n",
            "Batch: 850, Loss: 0.1535321907879734, Accuracy: 0.9161\n",
            "Batch: 860, Loss: 0.1547070310096716, Accuracy: 0.9153833333333333\n",
            "Batch: 870, Loss: 0.15368529185987412, Accuracy: 0.9157166666666666\n",
            "Batch: 880, Loss: 0.15352204511684134, Accuracy: 0.9158666666666667\n",
            "Batch: 890, Loss: 0.15373846559686402, Accuracy: 0.9157833333333333\n",
            "Batch: 900, Loss: 0.15402788864734887, Accuracy: 0.9156666666666666\n",
            "Batch: 910, Loss: 0.1529200074966452, Accuracy: 0.9164\n",
            "Batch: 920, Loss: 0.1531235569500042, Accuracy: 0.9163833333333333\n",
            "Batch: 930, Loss: 0.15387259968248443, Accuracy: 0.9161\n",
            "Epoch: 34, Loss: 0.15422158454346072, Accuracy: 0.91575\n",
            "Batch: 0, Loss: 0.15419951021276918, Accuracy: 0.9159\n",
            "Batch: 10, Loss: 0.15537300235432341, Accuracy: 0.9152166666666667\n",
            "Batch: 20, Loss: 0.15404348349446498, Accuracy: 0.916\n",
            "Batch: 30, Loss: 0.15386443677033415, Accuracy: 0.9160666666666667\n",
            "Batch: 40, Loss: 0.153139256520367, Accuracy: 0.9167333333333333\n",
            "Batch: 50, Loss: 0.15341215728372598, Accuracy: 0.9164\n",
            "Batch: 60, Loss: 0.15289024715002453, Accuracy: 0.9169166666666667\n",
            "Batch: 70, Loss: 0.15263912742182595, Accuracy: 0.9168166666666666\n",
            "Batch: 80, Loss: 0.15250455515822342, Accuracy: 0.9170166666666667\n",
            "Batch: 90, Loss: 0.1521590994570052, Accuracy: 0.9171\n",
            "Batch: 100, Loss: 0.15232790525580478, Accuracy: 0.9166333333333333\n",
            "Batch: 110, Loss: 0.1529459389805639, Accuracy: 0.91605\n",
            "Batch: 120, Loss: 0.15260281778117726, Accuracy: 0.9167\n",
            "Batch: 130, Loss: 0.15387403532085872, Accuracy: 0.9157166666666666\n",
            "Batch: 140, Loss: 0.15514458015770147, Accuracy: 0.9150833333333334\n",
            "Batch: 150, Loss: 0.15395500926958453, Accuracy: 0.9159\n",
            "Batch: 160, Loss: 0.15426725968704297, Accuracy: 0.9157166666666666\n",
            "Batch: 170, Loss: 0.15272021759696622, Accuracy: 0.9167666666666666\n",
            "Batch: 180, Loss: 0.15274927378136688, Accuracy: 0.9164333333333333\n",
            "Batch: 190, Loss: 0.15394613565977447, Accuracy: 0.9164666666666667\n",
            "Batch: 200, Loss: 0.15462104089857534, Accuracy: 0.91575\n",
            "Batch: 210, Loss: 0.1550197863213966, Accuracy: 0.91585\n",
            "Batch: 220, Loss: 0.15555913862065263, Accuracy: 0.9157833333333333\n",
            "Batch: 230, Loss: 0.15497391601657498, Accuracy: 0.9160333333333334\n",
            "Batch: 240, Loss: 0.15534679419750305, Accuracy: 0.9164166666666667\n",
            "Batch: 250, Loss: 0.1543772948629004, Accuracy: 0.9165666666666666\n",
            "Batch: 260, Loss: 0.15504234385703827, Accuracy: 0.91655\n",
            "Batch: 270, Loss: 0.15306579760609082, Accuracy: 0.91715\n",
            "Batch: 280, Loss: 0.15198617367981895, Accuracy: 0.9176166666666666\n",
            "Batch: 290, Loss: 0.15200758941887998, Accuracy: 0.9181\n",
            "Batch: 300, Loss: 0.15184226991448435, Accuracy: 0.9179\n",
            "Batch: 310, Loss: 0.15215488092423618, Accuracy: 0.9178666666666667\n",
            "Batch: 320, Loss: 0.1521262820588189, Accuracy: 0.9177333333333333\n",
            "Batch: 330, Loss: 0.15208756503371365, Accuracy: 0.91805\n",
            "Batch: 340, Loss: 0.1527092677859405, Accuracy: 0.9175833333333333\n",
            "Batch: 350, Loss: 0.15244394169014513, Accuracy: 0.9179166666666667\n",
            "Batch: 360, Loss: 0.1534269003145925, Accuracy: 0.9174166666666667\n",
            "Batch: 370, Loss: 0.15246405789189574, Accuracy: 0.9181666666666667\n",
            "Batch: 380, Loss: 0.15206171933162785, Accuracy: 0.9176333333333333\n",
            "Batch: 390, Loss: 0.15174083108836142, Accuracy: 0.9182\n",
            "Batch: 400, Loss: 0.15184412843843229, Accuracy: 0.9174166666666667\n",
            "Batch: 410, Loss: 0.15153215712008627, Accuracy: 0.9176\n",
            "Batch: 420, Loss: 0.15129780021161288, Accuracy: 0.9179666666666667\n",
            "Batch: 430, Loss: 0.1520172324447719, Accuracy: 0.9172166666666667\n",
            "Batch: 440, Loss: 0.15236952024757186, Accuracy: 0.9177333333333333\n",
            "Batch: 450, Loss: 0.1516360917261404, Accuracy: 0.9179166666666667\n",
            "Batch: 460, Loss: 0.1518948489906292, Accuracy: 0.9173833333333333\n",
            "Batch: 470, Loss: 0.15145583104540894, Accuracy: 0.918\n",
            "Batch: 480, Loss: 0.1511500346053066, Accuracy: 0.9181833333333334\n",
            "Batch: 490, Loss: 0.15140631231000165, Accuracy: 0.9180666666666667\n",
            "Batch: 500, Loss: 0.15106708110728254, Accuracy: 0.9183166666666667\n",
            "Batch: 510, Loss: 0.1510930807217405, Accuracy: 0.9178\n",
            "Batch: 520, Loss: 0.15116357634086744, Accuracy: 0.9180333333333334\n",
            "Batch: 530, Loss: 0.1510028979214073, Accuracy: 0.9185833333333333\n",
            "Batch: 540, Loss: 0.1508921966800536, Accuracy: 0.9185\n",
            "Batch: 550, Loss: 0.15112952441815644, Accuracy: 0.9182833333333333\n",
            "Batch: 560, Loss: 0.15209665229172706, Accuracy: 0.9175833333333333\n",
            "Batch: 570, Loss: 0.15284652758629963, Accuracy: 0.9171333333333334\n",
            "Batch: 580, Loss: 0.15271923876873594, Accuracy: 0.9175166666666666\n",
            "Batch: 590, Loss: 0.151340971646937, Accuracy: 0.91795\n",
            "Batch: 600, Loss: 0.15146502802852285, Accuracy: 0.9177333333333333\n",
            "Batch: 610, Loss: 0.15150339763805482, Accuracy: 0.91795\n",
            "Batch: 620, Loss: 0.15167007210533512, Accuracy: 0.9175166666666666\n",
            "Batch: 630, Loss: 0.15113885424590787, Accuracy: 0.9176\n",
            "Batch: 640, Loss: 0.1515483116975342, Accuracy: 0.9177666666666666\n",
            "Batch: 650, Loss: 0.15140919321186552, Accuracy: 0.9177166666666666\n",
            "Batch: 660, Loss: 0.1512747198161531, Accuracy: 0.9177166666666666\n",
            "Batch: 670, Loss: 0.15116511913182448, Accuracy: 0.9175333333333333\n",
            "Batch: 680, Loss: 0.15106546323946252, Accuracy: 0.9177833333333333\n",
            "Batch: 690, Loss: 0.15221900188545232, Accuracy: 0.91695\n",
            "Batch: 700, Loss: 0.15216838551174566, Accuracy: 0.91715\n",
            "Batch: 710, Loss: 0.15332834793813646, Accuracy: 0.9164166666666667\n",
            "Batch: 720, Loss: 0.1523053461582658, Accuracy: 0.9168\n",
            "Batch: 730, Loss: 0.15272709715601493, Accuracy: 0.9167\n",
            "Batch: 740, Loss: 0.1526393965235639, Accuracy: 0.9167666666666666\n",
            "Batch: 750, Loss: 0.15303348214133258, Accuracy: 0.9164\n",
            "Batch: 760, Loss: 0.15200719023010548, Accuracy: 0.9166666666666666\n",
            "Batch: 770, Loss: 0.15253256480470873, Accuracy: 0.9163833333333333\n",
            "Batch: 780, Loss: 0.15339862486570574, Accuracy: 0.9158833333333334\n",
            "Batch: 790, Loss: 0.15288109478121345, Accuracy: 0.9164333333333333\n",
            "Batch: 800, Loss: 0.15361931581693894, Accuracy: 0.9158666666666667\n",
            "Batch: 810, Loss: 0.1527301195916107, Accuracy: 0.9162166666666667\n",
            "Batch: 820, Loss: 0.15278736544422628, Accuracy: 0.91615\n",
            "Batch: 830, Loss: 0.15152348347255992, Accuracy: 0.9171333333333334\n",
            "Batch: 840, Loss: 0.15124671247160518, Accuracy: 0.9170666666666667\n",
            "Batch: 850, Loss: 0.15128448049544516, Accuracy: 0.9169\n",
            "Batch: 860, Loss: 0.15243934914216187, Accuracy: 0.9162666666666667\n",
            "Batch: 870, Loss: 0.1514056899982749, Accuracy: 0.9166\n",
            "Batch: 880, Loss: 0.1513074418094256, Accuracy: 0.9168833333333334\n",
            "Batch: 890, Loss: 0.15158821338667658, Accuracy: 0.91665\n",
            "Batch: 900, Loss: 0.15181824881096576, Accuracy: 0.9164\n",
            "Batch: 910, Loss: 0.15065332464012263, Accuracy: 0.9173666666666667\n",
            "Batch: 920, Loss: 0.15086374866250632, Accuracy: 0.9173333333333333\n",
            "Batch: 930, Loss: 0.15163090287294462, Accuracy: 0.9170166666666667\n",
            "Epoch: 35, Loss: 0.15192315019345115, Accuracy: 0.91685\n",
            "Batch: 0, Loss: 0.1519010382019206, Accuracy: 0.9168333333333333\n",
            "Batch: 10, Loss: 0.15304954589977562, Accuracy: 0.9161166666666667\n",
            "Batch: 20, Loss: 0.15173456271720126, Accuracy: 0.9171\n",
            "Batch: 30, Loss: 0.15156817712232998, Accuracy: 0.9173666666666667\n",
            "Batch: 40, Loss: 0.15084323935570224, Accuracy: 0.9174166666666667\n",
            "Batch: 50, Loss: 0.15116224601125186, Accuracy: 0.9175833333333333\n",
            "Batch: 60, Loss: 0.15069112521400113, Accuracy: 0.9179\n",
            "Batch: 70, Loss: 0.15042504542189636, Accuracy: 0.91795\n",
            "Batch: 80, Loss: 0.1501716561068345, Accuracy: 0.9179833333333334\n",
            "Batch: 90, Loss: 0.14990451118548484, Accuracy: 0.9182666666666667\n",
            "Batch: 100, Loss: 0.1500764638023692, Accuracy: 0.9177666666666666\n",
            "Batch: 110, Loss: 0.15059804547737804, Accuracy: 0.9173\n",
            "Batch: 120, Loss: 0.15036936010146346, Accuracy: 0.91775\n",
            "Batch: 130, Loss: 0.15167163290083, Accuracy: 0.9169833333333334\n",
            "Batch: 140, Loss: 0.15297762166095213, Accuracy: 0.91615\n",
            "Batch: 150, Loss: 0.1518123816776843, Accuracy: 0.9167666666666666\n",
            "Batch: 160, Loss: 0.15202759139911964, Accuracy: 0.9165833333333333\n",
            "Batch: 170, Loss: 0.1505404858536573, Accuracy: 0.9178333333333333\n",
            "Batch: 180, Loss: 0.15054605142736752, Accuracy: 0.9174\n",
            "Batch: 190, Loss: 0.1516824434802848, Accuracy: 0.9175833333333333\n",
            "Batch: 200, Loss: 0.15219731057698968, Accuracy: 0.9168833333333334\n",
            "Batch: 210, Loss: 0.15258518336677554, Accuracy: 0.917\n",
            "Batch: 220, Loss: 0.15311556044644403, Accuracy: 0.9167166666666666\n",
            "Batch: 230, Loss: 0.15260656543869783, Accuracy: 0.9172166666666667\n",
            "Batch: 240, Loss: 0.15295273043086222, Accuracy: 0.91735\n",
            "Batch: 250, Loss: 0.15207330879893952, Accuracy: 0.9176166666666666\n",
            "Batch: 260, Loss: 0.15276395039773186, Accuracy: 0.9176333333333333\n",
            "Batch: 270, Loss: 0.15077500055052526, Accuracy: 0.91815\n",
            "Batch: 280, Loss: 0.1497652667703613, Accuracy: 0.9187\n",
            "Batch: 290, Loss: 0.14987318928272186, Accuracy: 0.919\n",
            "Batch: 300, Loss: 0.14966795149797843, Accuracy: 0.9188\n",
            "Batch: 310, Loss: 0.14998483160141857, Accuracy: 0.91905\n",
            "Batch: 320, Loss: 0.14997974263803404, Accuracy: 0.9185833333333333\n",
            "Batch: 330, Loss: 0.15000450327903686, Accuracy: 0.9189666666666667\n",
            "Batch: 340, Loss: 0.15059777769941285, Accuracy: 0.9186166666666666\n",
            "Batch: 350, Loss: 0.15029497886477822, Accuracy: 0.9188666666666667\n",
            "Batch: 360, Loss: 0.15126217838424408, Accuracy: 0.9183166666666667\n",
            "Batch: 370, Loss: 0.150326861228094, Accuracy: 0.9189\n",
            "Batch: 380, Loss: 0.14986602120570028, Accuracy: 0.9187666666666666\n",
            "Batch: 390, Loss: 0.14952596118519598, Accuracy: 0.9188833333333334\n",
            "Batch: 400, Loss: 0.149652797383325, Accuracy: 0.9187166666666666\n",
            "Batch: 410, Loss: 0.14937640923529483, Accuracy: 0.9187833333333333\n",
            "Batch: 420, Loss: 0.14922806362183766, Accuracy: 0.9191166666666667\n",
            "Batch: 430, Loss: 0.14997090463616727, Accuracy: 0.91805\n",
            "Batch: 440, Loss: 0.15032991628794867, Accuracy: 0.9186333333333333\n",
            "Batch: 450, Loss: 0.14957780814347776, Accuracy: 0.9187\n",
            "Batch: 460, Loss: 0.14980693431555597, Accuracy: 0.9184833333333333\n",
            "Batch: 470, Loss: 0.14934688370315413, Accuracy: 0.9189\n",
            "Batch: 480, Loss: 0.14898673748583469, Accuracy: 0.919\n",
            "Batch: 490, Loss: 0.14925049600590778, Accuracy: 0.9190166666666667\n",
            "Batch: 500, Loss: 0.14897591630157136, Accuracy: 0.9194333333333333\n",
            "Batch: 510, Loss: 0.14904008968780993, Accuracy: 0.9188333333333333\n",
            "Batch: 520, Loss: 0.14911866973140284, Accuracy: 0.91895\n",
            "Batch: 530, Loss: 0.14892265186205195, Accuracy: 0.9194166666666667\n",
            "Batch: 540, Loss: 0.14876330482873834, Accuracy: 0.9195166666666666\n",
            "Batch: 550, Loss: 0.14897219977113813, Accuracy: 0.9192166666666667\n",
            "Batch: 560, Loss: 0.14994489058645596, Accuracy: 0.91845\n",
            "Batch: 570, Loss: 0.15070623591394006, Accuracy: 0.9179833333333334\n",
            "Batch: 580, Loss: 0.15060841017995927, Accuracy: 0.9184\n",
            "Batch: 590, Loss: 0.1492161799108859, Accuracy: 0.9189\n",
            "Batch: 600, Loss: 0.14940768384295566, Accuracy: 0.9183666666666667\n",
            "Batch: 610, Loss: 0.1494113730246011, Accuracy: 0.9184666666666667\n",
            "Batch: 620, Loss: 0.14958693353311386, Accuracy: 0.9184333333333333\n",
            "Batch: 630, Loss: 0.14896281345174908, Accuracy: 0.9186333333333333\n",
            "Batch: 640, Loss: 0.14934803138305897, Accuracy: 0.91865\n",
            "Batch: 650, Loss: 0.1492774461842239, Accuracy: 0.9187\n",
            "Batch: 660, Loss: 0.14912948745506827, Accuracy: 0.91845\n",
            "Batch: 670, Loss: 0.14897688907634007, Accuracy: 0.9183833333333333\n",
            "Batch: 680, Loss: 0.14889716350101584, Accuracy: 0.9184333333333333\n",
            "Batch: 690, Loss: 0.15005003270914744, Accuracy: 0.9176833333333333\n",
            "Batch: 700, Loss: 0.14994614336800594, Accuracy: 0.9180833333333334\n",
            "Batch: 710, Loss: 0.15115734883883045, Accuracy: 0.9171833333333334\n",
            "Batch: 720, Loss: 0.15006792189699195, Accuracy: 0.9177666666666666\n",
            "Batch: 730, Loss: 0.15052784639486633, Accuracy: 0.9175666666666666\n",
            "Batch: 740, Loss: 0.1504167082073473, Accuracy: 0.9175833333333333\n",
            "Batch: 750, Loss: 0.1508512944769428, Accuracy: 0.91715\n",
            "Batch: 760, Loss: 0.1498758556748623, Accuracy: 0.9178333333333333\n",
            "Batch: 770, Loss: 0.15033059183736272, Accuracy: 0.9174333333333333\n",
            "Batch: 780, Loss: 0.15117710662584302, Accuracy: 0.9169666666666667\n",
            "Batch: 790, Loss: 0.15072380153461415, Accuracy: 0.9173\n",
            "Batch: 800, Loss: 0.15146911895389825, Accuracy: 0.9168\n",
            "Batch: 810, Loss: 0.15053571336860996, Accuracy: 0.9172833333333333\n",
            "Batch: 820, Loss: 0.15056676197995986, Accuracy: 0.9172166666666667\n",
            "Batch: 830, Loss: 0.14932951907676745, Accuracy: 0.9178833333333334\n",
            "Batch: 840, Loss: 0.1490455845124716, Accuracy: 0.91805\n",
            "Batch: 850, Loss: 0.14909440263901563, Accuracy: 0.91785\n",
            "Batch: 860, Loss: 0.15019618199074555, Accuracy: 0.9172666666666667\n",
            "Batch: 870, Loss: 0.1492141426751398, Accuracy: 0.9173833333333333\n",
            "Batch: 880, Loss: 0.14915224969982493, Accuracy: 0.9178333333333333\n",
            "Batch: 890, Loss: 0.14949107355136018, Accuracy: 0.9176333333333333\n",
            "Batch: 900, Loss: 0.14969380791508177, Accuracy: 0.9175\n",
            "Batch: 910, Loss: 0.14853524309155394, Accuracy: 0.9182\n",
            "Batch: 920, Loss: 0.148729861482365, Accuracy: 0.9180833333333334\n",
            "Batch: 930, Loss: 0.14947060289626962, Accuracy: 0.9180333333333334\n",
            "Epoch: 36, Loss: 0.1497155951273317, Accuracy: 0.9177333333333333\n",
            "Batch: 0, Loss: 0.1496895867486649, Accuracy: 0.9177666666666666\n",
            "Batch: 10, Loss: 0.15082777320924065, Accuracy: 0.9170833333333334\n",
            "Batch: 20, Loss: 0.14954619730290009, Accuracy: 0.9182666666666667\n",
            "Batch: 30, Loss: 0.14936997001981372, Accuracy: 0.9181166666666667\n",
            "Batch: 40, Loss: 0.14864638134212965, Accuracy: 0.9185\n",
            "Batch: 50, Loss: 0.14898960438973272, Accuracy: 0.9185\n",
            "Batch: 60, Loss: 0.14856696209864603, Accuracy: 0.9187666666666666\n",
            "Batch: 70, Loss: 0.1482630634260387, Accuracy: 0.9187833333333333\n",
            "Batch: 80, Loss: 0.14796578011989261, Accuracy: 0.91905\n",
            "Batch: 90, Loss: 0.14778548638097805, Accuracy: 0.91915\n",
            "Batch: 100, Loss: 0.1479155591246892, Accuracy: 0.91875\n",
            "Batch: 110, Loss: 0.1483669951153507, Accuracy: 0.9183833333333333\n",
            "Batch: 120, Loss: 0.14819093401557415, Accuracy: 0.9185833333333333\n",
            "Batch: 130, Loss: 0.1494796226464589, Accuracy: 0.9178833333333334\n",
            "Batch: 140, Loss: 0.15087061502288385, Accuracy: 0.9173166666666667\n",
            "Batch: 150, Loss: 0.14974511376217317, Accuracy: 0.9176833333333333\n",
            "Batch: 160, Loss: 0.1498553098971016, Accuracy: 0.9173666666666667\n",
            "Batch: 170, Loss: 0.14839328235087804, Accuracy: 0.9184666666666667\n",
            "Batch: 180, Loss: 0.14835347823717882, Accuracy: 0.9185166666666666\n",
            "Batch: 190, Loss: 0.14947648799720015, Accuracy: 0.9184666666666667\n",
            "Batch: 200, Loss: 0.1498952241759842, Accuracy: 0.9176666666666666\n",
            "Batch: 210, Loss: 0.1502406455890331, Accuracy: 0.9179\n",
            "Batch: 220, Loss: 0.15077461243878806, Accuracy: 0.9178333333333333\n",
            "Batch: 230, Loss: 0.1502881133375045, Accuracy: 0.9181\n",
            "Batch: 240, Loss: 0.15064261130688197, Accuracy: 0.9181333333333334\n",
            "Batch: 250, Loss: 0.1498074727066931, Accuracy: 0.91875\n",
            "Batch: 260, Loss: 0.15051884711735578, Accuracy: 0.9185\n",
            "Batch: 270, Loss: 0.14853016111787096, Accuracy: 0.9192833333333333\n",
            "Batch: 280, Loss: 0.14759775860621013, Accuracy: 0.91955\n",
            "Batch: 290, Loss: 0.1477675899184014, Accuracy: 0.9199166666666667\n",
            "Batch: 300, Loss: 0.1475422982984724, Accuracy: 0.9196\n",
            "Batch: 310, Loss: 0.14786173262782243, Accuracy: 0.9197833333333333\n",
            "Batch: 320, Loss: 0.1478963974226407, Accuracy: 0.91955\n",
            "Batch: 330, Loss: 0.1479460857368791, Accuracy: 0.92\n",
            "Batch: 340, Loss: 0.14853986570546196, Accuracy: 0.9196333333333333\n",
            "Batch: 350, Loss: 0.1482089150258903, Accuracy: 0.9197333333333333\n",
            "Batch: 360, Loss: 0.14918056511183259, Accuracy: 0.9193833333333333\n",
            "Batch: 370, Loss: 0.14828280761350737, Accuracy: 0.9198833333333334\n",
            "Batch: 380, Loss: 0.14776857503700047, Accuracy: 0.91945\n",
            "Batch: 390, Loss: 0.14737178695492292, Accuracy: 0.91995\n",
            "Batch: 400, Loss: 0.1475358309534966, Accuracy: 0.9197333333333333\n",
            "Batch: 410, Loss: 0.14729088615713565, Accuracy: 0.9199333333333334\n",
            "Batch: 420, Loss: 0.14718991014196106, Accuracy: 0.9199333333333334\n",
            "Batch: 430, Loss: 0.1479528407665585, Accuracy: 0.9191666666666667\n",
            "Batch: 440, Loss: 0.1482979835076141, Accuracy: 0.9195833333333333\n",
            "Batch: 450, Loss: 0.14755825863283323, Accuracy: 0.9197666666666666\n",
            "Batch: 460, Loss: 0.1477764705339427, Accuracy: 0.9191666666666667\n",
            "Batch: 470, Loss: 0.147265082117251, Accuracy: 0.9198666666666667\n",
            "Batch: 480, Loss: 0.14689079659010815, Accuracy: 0.9199166666666667\n",
            "Batch: 490, Loss: 0.14715268229368708, Accuracy: 0.9197333333333333\n",
            "Batch: 500, Loss: 0.1469684937646043, Accuracy: 0.92045\n",
            "Batch: 510, Loss: 0.14709985139686982, Accuracy: 0.91965\n",
            "Batch: 520, Loss: 0.1471172398641632, Accuracy: 0.9197166666666666\n",
            "Batch: 530, Loss: 0.14692907513609238, Accuracy: 0.92025\n",
            "Batch: 540, Loss: 0.14672022705600232, Accuracy: 0.9203\n",
            "Batch: 550, Loss: 0.1468381620214994, Accuracy: 0.9200666666666667\n",
            "Batch: 560, Loss: 0.14781773508290505, Accuracy: 0.9192333333333333\n",
            "Batch: 570, Loss: 0.14854969169623894, Accuracy: 0.9188833333333334\n",
            "Batch: 580, Loss: 0.14851613653660095, Accuracy: 0.9194333333333333\n",
            "Batch: 590, Loss: 0.1471595321477747, Accuracy: 0.9197833333333333\n",
            "Batch: 600, Loss: 0.14737518200593905, Accuracy: 0.9194\n",
            "Batch: 610, Loss: 0.14731467383196944, Accuracy: 0.9193\n",
            "Batch: 620, Loss: 0.1475010533198338, Accuracy: 0.9192833333333333\n",
            "Batch: 630, Loss: 0.14687819373514108, Accuracy: 0.9197333333333333\n",
            "Batch: 640, Loss: 0.147210038901381, Accuracy: 0.9196166666666666\n",
            "Batch: 650, Loss: 0.1472240403247537, Accuracy: 0.9195666666666666\n",
            "Batch: 660, Loss: 0.1470080138248024, Accuracy: 0.91925\n",
            "Batch: 670, Loss: 0.14687801624024424, Accuracy: 0.9195166666666666\n",
            "Batch: 680, Loss: 0.1467565101533866, Accuracy: 0.9191333333333334\n",
            "Batch: 690, Loss: 0.14784803645259267, Accuracy: 0.9185833333333333\n",
            "Batch: 700, Loss: 0.14771884536805208, Accuracy: 0.9191\n",
            "Batch: 710, Loss: 0.1489194939401159, Accuracy: 0.9179333333333334\n",
            "Batch: 720, Loss: 0.1478482553220534, Accuracy: 0.91865\n",
            "Batch: 730, Loss: 0.14833470368391588, Accuracy: 0.9183666666666667\n",
            "Batch: 740, Loss: 0.14825507522875722, Accuracy: 0.9186\n",
            "Batch: 750, Loss: 0.14873352607199078, Accuracy: 0.9182166666666667\n",
            "Batch: 760, Loss: 0.1477860252912323, Accuracy: 0.9189333333333334\n",
            "Batch: 770, Loss: 0.14816071838349995, Accuracy: 0.9184666666666667\n",
            "Batch: 780, Loss: 0.1489701232494262, Accuracy: 0.9179333333333334\n",
            "Batch: 790, Loss: 0.14856520986089622, Accuracy: 0.9181833333333334\n",
            "Batch: 800, Loss: 0.14935996594020046, Accuracy: 0.9177666666666666\n",
            "Batch: 810, Loss: 0.1483970516443633, Accuracy: 0.9183166666666667\n",
            "Batch: 820, Loss: 0.14838085466489295, Accuracy: 0.9182\n",
            "Batch: 830, Loss: 0.14710385598067144, Accuracy: 0.91875\n",
            "Batch: 840, Loss: 0.14686375971080196, Accuracy: 0.91885\n",
            "Batch: 850, Loss: 0.14697381676058557, Accuracy: 0.9190333333333334\n",
            "Batch: 860, Loss: 0.1480494434611876, Accuracy: 0.9179833333333334\n",
            "Batch: 870, Loss: 0.1471096223294953, Accuracy: 0.9183333333333333\n",
            "Batch: 880, Loss: 0.1470581034509453, Accuracy: 0.9188333333333333\n",
            "Batch: 890, Loss: 0.1474492780481793, Accuracy: 0.9188\n",
            "Batch: 900, Loss: 0.14761804745023, Accuracy: 0.9184333333333333\n",
            "Batch: 910, Loss: 0.1465531710399709, Accuracy: 0.91895\n",
            "Batch: 920, Loss: 0.14670862191409778, Accuracy: 0.91885\n",
            "Batch: 930, Loss: 0.14741360330379857, Accuracy: 0.9186\n",
            "Epoch: 37, Loss: 0.14763726862975796, Accuracy: 0.9185333333333333\n",
            "Batch: 0, Loss: 0.14760257550834704, Accuracy: 0.9186\n",
            "Batch: 10, Loss: 0.14874898960669247, Accuracy: 0.91795\n",
            "Batch: 20, Loss: 0.14747621468326327, Accuracy: 0.9188666666666667\n",
            "Batch: 30, Loss: 0.147273755278569, Accuracy: 0.9190666666666667\n",
            "Batch: 40, Loss: 0.14655062261577806, Accuracy: 0.91945\n",
            "Batch: 50, Loss: 0.14688782632277525, Accuracy: 0.9195\n",
            "Batch: 60, Loss: 0.14649006032366033, Accuracy: 0.9196833333333333\n",
            "Batch: 70, Loss: 0.14612202105685726, Accuracy: 0.9196833333333333\n",
            "Batch: 80, Loss: 0.14587404513829316, Accuracy: 0.9197666666666666\n",
            "Batch: 90, Loss: 0.14574263795104458, Accuracy: 0.9199166666666667\n",
            "Batch: 100, Loss: 0.14581160743338525, Accuracy: 0.9194666666666667\n",
            "Batch: 110, Loss: 0.14621711308315283, Accuracy: 0.9195\n",
            "Batch: 120, Loss: 0.14606412314193487, Accuracy: 0.9197166666666666\n",
            "Batch: 130, Loss: 0.1473213114996358, Accuracy: 0.9188333333333333\n",
            "Batch: 140, Loss: 0.1487809334320703, Accuracy: 0.9183833333333333\n",
            "Batch: 150, Loss: 0.14764079750364614, Accuracy: 0.9186\n",
            "Batch: 160, Loss: 0.147740289840759, Accuracy: 0.9182666666666667\n",
            "Batch: 170, Loss: 0.14623643660542235, Accuracy: 0.9191166666666667\n",
            "Batch: 180, Loss: 0.14611673636737021, Accuracy: 0.9192833333333333\n",
            "Batch: 190, Loss: 0.14710871774358225, Accuracy: 0.9196333333333333\n",
            "Batch: 200, Loss: 0.14756263578536585, Accuracy: 0.9187\n",
            "Batch: 210, Loss: 0.147877873123094, Accuracy: 0.9188\n",
            "Batch: 220, Loss: 0.14842249820254216, Accuracy: 0.91895\n",
            "Batch: 230, Loss: 0.14800166620768868, Accuracy: 0.9190166666666667\n",
            "Batch: 240, Loss: 0.14833007411414287, Accuracy: 0.9191833333333334\n",
            "Batch: 250, Loss: 0.14753867192046305, Accuracy: 0.9197166666666666\n",
            "Batch: 260, Loss: 0.1482646389563537, Accuracy: 0.9193166666666667\n",
            "Batch: 270, Loss: 0.1463059239781555, Accuracy: 0.9203333333333333\n",
            "Batch: 280, Loss: 0.14547738185989223, Accuracy: 0.9205333333333333\n",
            "Batch: 290, Loss: 0.1456921030874475, Accuracy: 0.92065\n",
            "Batch: 300, Loss: 0.14543505302615353, Accuracy: 0.9205333333333333\n",
            "Batch: 310, Loss: 0.14574910926760826, Accuracy: 0.9204833333333333\n",
            "Batch: 320, Loss: 0.14581097409100072, Accuracy: 0.9205666666666666\n",
            "Batch: 330, Loss: 0.14589132123329526, Accuracy: 0.9209333333333334\n",
            "Batch: 340, Loss: 0.146495409797597, Accuracy: 0.9207166666666666\n",
            "Batch: 350, Loss: 0.14611956741776097, Accuracy: 0.92095\n",
            "Batch: 360, Loss: 0.14714778743834417, Accuracy: 0.9202833333333333\n",
            "Batch: 370, Loss: 0.14622836664109182, Accuracy: 0.9205166666666666\n",
            "Batch: 380, Loss: 0.14567398559554795, Accuracy: 0.9205833333333333\n",
            "Batch: 390, Loss: 0.14527479261703855, Accuracy: 0.92075\n",
            "Batch: 400, Loss: 0.14547328813069166, Accuracy: 0.9206166666666666\n",
            "Batch: 410, Loss: 0.14526948670526876, Accuracy: 0.9207666666666666\n",
            "Batch: 420, Loss: 0.1451557112822026, Accuracy: 0.9208666666666666\n",
            "Batch: 430, Loss: 0.14587229812853653, Accuracy: 0.9202166666666667\n",
            "Batch: 440, Loss: 0.14624098950022463, Accuracy: 0.92055\n",
            "Batch: 450, Loss: 0.14553745129025247, Accuracy: 0.92075\n",
            "Batch: 460, Loss: 0.14577542962650633, Accuracy: 0.9204\n",
            "Batch: 470, Loss: 0.14518071893111795, Accuracy: 0.9209166666666667\n",
            "Batch: 480, Loss: 0.1448335909726859, Accuracy: 0.9210333333333334\n",
            "Batch: 490, Loss: 0.1451312202692186, Accuracy: 0.9208\n",
            "Batch: 500, Loss: 0.1450044648617521, Accuracy: 0.9210666666666667\n",
            "Batch: 510, Loss: 0.14515905776130417, Accuracy: 0.9204333333333333\n",
            "Batch: 520, Loss: 0.14510828312849594, Accuracy: 0.92095\n",
            "Batch: 530, Loss: 0.14496023308191194, Accuracy: 0.9212833333333333\n",
            "Batch: 540, Loss: 0.14475349003008653, Accuracy: 0.9214333333333333\n",
            "Batch: 550, Loss: 0.14477547244078678, Accuracy: 0.9210333333333334\n",
            "Batch: 560, Loss: 0.1457377029180991, Accuracy: 0.9203666666666667\n",
            "Batch: 570, Loss: 0.14643401518257224, Accuracy: 0.9195833333333333\n",
            "Batch: 580, Loss: 0.14644916854795875, Accuracy: 0.9202166666666667\n",
            "Batch: 590, Loss: 0.14515257882270308, Accuracy: 0.9208166666666666\n",
            "Batch: 600, Loss: 0.1454139735588366, Accuracy: 0.9203333333333333\n",
            "Batch: 610, Loss: 0.14527829613467233, Accuracy: 0.9202\n",
            "Batch: 620, Loss: 0.14544024536851666, Accuracy: 0.9203166666666667\n",
            "Batch: 630, Loss: 0.1447701226868748, Accuracy: 0.92065\n",
            "Batch: 640, Loss: 0.1450969639907947, Accuracy: 0.9205833333333333\n",
            "Batch: 650, Loss: 0.1452158740213428, Accuracy: 0.9204833333333333\n",
            "Batch: 660, Loss: 0.14490991308229692, Accuracy: 0.9202666666666667\n",
            "Batch: 670, Loss: 0.14482163645921833, Accuracy: 0.9204333333333333\n",
            "Batch: 680, Loss: 0.14462195531541075, Accuracy: 0.9203\n",
            "Batch: 690, Loss: 0.1456036754266248, Accuracy: 0.9196666666666666\n",
            "Batch: 700, Loss: 0.14544858925586962, Accuracy: 0.92025\n",
            "Batch: 710, Loss: 0.14658659288339682, Accuracy: 0.9189833333333334\n",
            "Batch: 720, Loss: 0.1456069815978112, Accuracy: 0.91985\n",
            "Batch: 730, Loss: 0.14612477437765775, Accuracy: 0.9196166666666666\n",
            "Batch: 740, Loss: 0.1460767580968438, Accuracy: 0.9195833333333333\n",
            "Batch: 750, Loss: 0.14662321511901044, Accuracy: 0.9192333333333333\n",
            "Batch: 760, Loss: 0.14574538835865508, Accuracy: 0.9197\n",
            "Batch: 770, Loss: 0.14601810285599934, Accuracy: 0.9196333333333333\n",
            "Batch: 780, Loss: 0.1467840479210166, Accuracy: 0.9188333333333333\n",
            "Batch: 790, Loss: 0.146456328958867, Accuracy: 0.9191833333333334\n",
            "Batch: 800, Loss: 0.14729832987852545, Accuracy: 0.91875\n",
            "Batch: 810, Loss: 0.14636674851071138, Accuracy: 0.9192\n",
            "Batch: 820, Loss: 0.14630681468681891, Accuracy: 0.9190166666666667\n",
            "Batch: 830, Loss: 0.14503296561557313, Accuracy: 0.91985\n",
            "Batch: 840, Loss: 0.1447804270932035, Accuracy: 0.9197833333333333\n",
            "Batch: 850, Loss: 0.14495220403842551, Accuracy: 0.9198333333333333\n",
            "Batch: 860, Loss: 0.1460207256467485, Accuracy: 0.9188\n",
            "Batch: 870, Loss: 0.14510338470906395, Accuracy: 0.9194833333333333\n",
            "Batch: 880, Loss: 0.14504729777530445, Accuracy: 0.92005\n",
            "Batch: 890, Loss: 0.1454572014556133, Accuracy: 0.9196833333333333\n",
            "Batch: 900, Loss: 0.14559004476137186, Accuracy: 0.91945\n",
            "Batch: 910, Loss: 0.1446006607965995, Accuracy: 0.9198\n",
            "Batch: 920, Loss: 0.1447598976820423, Accuracy: 0.9201\n",
            "Batch: 930, Loss: 0.14543056405970184, Accuracy: 0.91945\n",
            "Epoch: 38, Loss: 0.14565956787450096, Accuracy: 0.9194166666666667\n",
            "Batch: 0, Loss: 0.14561424647487206, Accuracy: 0.9195666666666666\n",
            "Batch: 10, Loss: 0.14678062468451517, Accuracy: 0.9189166666666667\n",
            "Batch: 20, Loss: 0.14550258756139103, Accuracy: 0.9198\n",
            "Batch: 30, Loss: 0.14527061778648004, Accuracy: 0.9198166666666666\n",
            "Batch: 40, Loss: 0.1445227224913712, Accuracy: 0.92015\n",
            "Batch: 50, Loss: 0.14481826161085617, Accuracy: 0.9205\n",
            "Batch: 60, Loss: 0.14445344075844857, Accuracy: 0.9204\n",
            "Batch: 70, Loss: 0.1440502517222048, Accuracy: 0.9208\n",
            "Batch: 80, Loss: 0.1438456117883998, Accuracy: 0.9207666666666666\n",
            "Batch: 90, Loss: 0.14367344223799094, Accuracy: 0.9209833333333334\n",
            "Batch: 100, Loss: 0.14371027114675472, Accuracy: 0.9203\n",
            "Batch: 110, Loss: 0.14412912530000385, Accuracy: 0.9202333333333333\n",
            "Batch: 120, Loss: 0.14400127868292986, Accuracy: 0.9206\n",
            "Batch: 130, Loss: 0.14523522961578733, Accuracy: 0.91995\n",
            "Batch: 140, Loss: 0.1467051170251386, Accuracy: 0.9191166666666667\n",
            "Batch: 150, Loss: 0.1455283432646156, Accuracy: 0.9196833333333333\n",
            "Batch: 160, Loss: 0.14562645092342988, Accuracy: 0.9191833333333334\n",
            "Batch: 170, Loss: 0.1440605713513265, Accuracy: 0.9200166666666667\n",
            "Batch: 180, Loss: 0.143993373624882, Accuracy: 0.9204166666666667\n",
            "Batch: 190, Loss: 0.1448308794919114, Accuracy: 0.9204333333333333\n",
            "Batch: 200, Loss: 0.1453498152433858, Accuracy: 0.9196666666666666\n",
            "Batch: 210, Loss: 0.1455301717944591, Accuracy: 0.9196333333333333\n",
            "Batch: 220, Loss: 0.14610101082110177, Accuracy: 0.9200666666666667\n",
            "Batch: 230, Loss: 0.14581337909393194, Accuracy: 0.9200333333333334\n",
            "Batch: 240, Loss: 0.1461264628734955, Accuracy: 0.9200666666666667\n",
            "Batch: 250, Loss: 0.1453567700439067, Accuracy: 0.9204833333333333\n",
            "Batch: 260, Loss: 0.14604411776712503, Accuracy: 0.9199666666666667\n",
            "Batch: 270, Loss: 0.14414357353220666, Accuracy: 0.9213333333333333\n",
            "Batch: 280, Loss: 0.14342015055694637, Accuracy: 0.9215833333333333\n",
            "Batch: 290, Loss: 0.143650593876994, Accuracy: 0.9215\n",
            "Batch: 300, Loss: 0.1433492681039419, Accuracy: 0.9213666666666667\n",
            "Batch: 310, Loss: 0.14364204732348793, Accuracy: 0.9214\n",
            "Batch: 320, Loss: 0.1437406111148364, Accuracy: 0.9215166666666667\n",
            "Batch: 330, Loss: 0.14386012260274533, Accuracy: 0.922\n",
            "Batch: 340, Loss: 0.14447687384472926, Accuracy: 0.9217333333333333\n",
            "Batch: 350, Loss: 0.14404543668337674, Accuracy: 0.9218666666666666\n",
            "Batch: 360, Loss: 0.1451654804757725, Accuracy: 0.92095\n",
            "Batch: 370, Loss: 0.14419313095436076, Accuracy: 0.9214666666666667\n",
            "Batch: 380, Loss: 0.14362877612677694, Accuracy: 0.9212666666666667\n",
            "Batch: 390, Loss: 0.14324672037565364, Accuracy: 0.9217333333333333\n",
            "Batch: 400, Loss: 0.1434503781845024, Accuracy: 0.9216666666666666\n",
            "Batch: 410, Loss: 0.1432690404010236, Accuracy: 0.9215833333333333\n",
            "Batch: 420, Loss: 0.1431426491143971, Accuracy: 0.9218166666666666\n",
            "Batch: 430, Loss: 0.143785084879448, Accuracy: 0.9210666666666667\n",
            "Batch: 440, Loss: 0.14417364708375083, Accuracy: 0.92165\n",
            "Batch: 450, Loss: 0.14350999708700224, Accuracy: 0.9217\n",
            "Batch: 460, Loss: 0.14378306437903499, Accuracy: 0.9215666666666666\n",
            "Batch: 470, Loss: 0.1431449202469704, Accuracy: 0.9220166666666667\n",
            "Batch: 480, Loss: 0.14281243933182422, Accuracy: 0.92215\n",
            "Batch: 490, Loss: 0.1431109202676583, Accuracy: 0.9218833333333334\n",
            "Batch: 500, Loss: 0.14303256912894183, Accuracy: 0.92185\n",
            "Batch: 510, Loss: 0.14316887797937564, Accuracy: 0.9213333333333333\n",
            "Batch: 520, Loss: 0.14310453428427677, Accuracy: 0.9218166666666666\n",
            "Batch: 530, Loss: 0.1430139905824594, Accuracy: 0.9223166666666667\n",
            "Batch: 540, Loss: 0.14280556801989652, Accuracy: 0.9224333333333333\n",
            "Batch: 550, Loss: 0.1427810030163804, Accuracy: 0.9220666666666667\n",
            "Batch: 560, Loss: 0.14371549402467682, Accuracy: 0.92115\n",
            "Batch: 570, Loss: 0.14437892407364558, Accuracy: 0.92065\n",
            "Batch: 580, Loss: 0.14439935618253205, Accuracy: 0.9209666666666667\n",
            "Batch: 590, Loss: 0.14315690879897164, Accuracy: 0.9217\n",
            "Batch: 600, Loss: 0.14342086057556694, Accuracy: 0.92115\n",
            "Batch: 610, Loss: 0.14324040292332213, Accuracy: 0.9209666666666667\n",
            "Batch: 620, Loss: 0.14341968877879596, Accuracy: 0.9211666666666667\n",
            "Batch: 630, Loss: 0.1427230645920043, Accuracy: 0.9216333333333333\n",
            "Batch: 640, Loss: 0.1430683101196946, Accuracy: 0.9212333333333333\n",
            "Batch: 650, Loss: 0.14324902452613145, Accuracy: 0.9213333333333333\n",
            "Batch: 660, Loss: 0.1429603333523992, Accuracy: 0.92145\n",
            "Batch: 670, Loss: 0.14285945554542184, Accuracy: 0.9212833333333333\n",
            "Batch: 680, Loss: 0.1426331331042726, Accuracy: 0.92125\n",
            "Batch: 690, Loss: 0.14355837602717578, Accuracy: 0.9207333333333333\n",
            "Batch: 700, Loss: 0.1433317226584583, Accuracy: 0.9210166666666667\n",
            "Batch: 710, Loss: 0.1443585068600516, Accuracy: 0.9200833333333334\n",
            "Batch: 720, Loss: 0.14347113624739674, Accuracy: 0.92085\n",
            "Batch: 730, Loss: 0.14400435184193724, Accuracy: 0.9206\n",
            "Batch: 740, Loss: 0.14397004431523316, Accuracy: 0.9206\n",
            "Batch: 750, Loss: 0.14454929743871298, Accuracy: 0.9201833333333334\n",
            "Batch: 760, Loss: 0.14376506978517303, Accuracy: 0.9206\n",
            "Batch: 770, Loss: 0.14395672046506353, Accuracy: 0.9206166666666666\n",
            "Batch: 780, Loss: 0.14473503156328005, Accuracy: 0.9201166666666667\n",
            "Batch: 790, Loss: 0.14445760727360907, Accuracy: 0.9199333333333334\n",
            "Batch: 800, Loss: 0.14533545943566223, Accuracy: 0.9198\n",
            "Batch: 810, Loss: 0.14442321957972826, Accuracy: 0.92\n",
            "Batch: 820, Loss: 0.14429729752509737, Accuracy: 0.9200833333333334\n",
            "Batch: 830, Loss: 0.14304816626944747, Accuracy: 0.9208333333333333\n",
            "Batch: 840, Loss: 0.14275608313235685, Accuracy: 0.9208833333333334\n",
            "Batch: 850, Loss: 0.14303015657426893, Accuracy: 0.9208\n",
            "Batch: 860, Loss: 0.14409415286741203, Accuracy: 0.9198166666666666\n",
            "Batch: 870, Loss: 0.1432108769323977, Accuracy: 0.9205\n",
            "Batch: 880, Loss: 0.1431542164681001, Accuracy: 0.9210833333333334\n",
            "Batch: 890, Loss: 0.14355552144743225, Accuracy: 0.9204166666666667\n",
            "Batch: 900, Loss: 0.1436510974139121, Accuracy: 0.92045\n",
            "Batch: 910, Loss: 0.1426892100160547, Accuracy: 0.92105\n",
            "Batch: 920, Loss: 0.14286801609584607, Accuracy: 0.9212\n",
            "Batch: 930, Loss: 0.14353100908779373, Accuracy: 0.9203833333333333\n",
            "Epoch: 39, Loss: 0.14373601868600586, Accuracy: 0.92015\n",
            "Batch: 0, Loss: 0.14368498030844212, Accuracy: 0.9204166666666667\n",
            "Batch: 10, Loss: 0.1448857457314979, Accuracy: 0.9198\n",
            "Batch: 20, Loss: 0.14357516851429258, Accuracy: 0.9206666666666666\n",
            "Batch: 30, Loss: 0.14332771238958866, Accuracy: 0.9205833333333333\n",
            "Batch: 40, Loss: 0.14253694713428056, Accuracy: 0.9212333333333333\n",
            "Batch: 50, Loss: 0.1427862219887254, Accuracy: 0.9211833333333334\n",
            "Batch: 60, Loss: 0.14248487655256747, Accuracy: 0.9214166666666667\n",
            "Batch: 70, Loss: 0.14204931688622136, Accuracy: 0.9218833333333334\n",
            "Batch: 80, Loss: 0.14184953323220711, Accuracy: 0.9217333333333333\n",
            "Batch: 90, Loss: 0.14164831559704105, Accuracy: 0.9218333333333333\n",
            "Batch: 100, Loss: 0.14168398559179549, Accuracy: 0.9212333333333333\n",
            "Batch: 110, Loss: 0.14209701507339567, Accuracy: 0.9213\n",
            "Batch: 120, Loss: 0.1420032100509165, Accuracy: 0.9215166666666667\n",
            "Batch: 130, Loss: 0.1432151992174173, Accuracy: 0.9211833333333334\n",
            "Batch: 140, Loss: 0.14464265495381126, Accuracy: 0.9199833333333334\n",
            "Batch: 150, Loss: 0.14338557619189068, Accuracy: 0.9205333333333333\n",
            "Batch: 160, Loss: 0.14345186216404693, Accuracy: 0.9200166666666667\n",
            "Batch: 170, Loss: 0.14192532483839138, Accuracy: 0.9211\n",
            "Batch: 180, Loss: 0.14198273519316387, Accuracy: 0.9212333333333333\n",
            "Batch: 190, Loss: 0.14276783289697956, Accuracy: 0.9213666666666667\n",
            "Batch: 200, Loss: 0.14329059719379303, Accuracy: 0.9206\n",
            "Batch: 210, Loss: 0.14341568958322484, Accuracy: 0.9207166666666666\n",
            "Batch: 220, Loss: 0.14397507383698926, Accuracy: 0.9209833333333334\n",
            "Batch: 230, Loss: 0.14374594395435913, Accuracy: 0.9210166666666667\n",
            "Batch: 240, Loss: 0.14411315696689989, Accuracy: 0.9212166666666667\n",
            "Batch: 250, Loss: 0.14334444143111016, Accuracy: 0.9216333333333333\n",
            "Batch: 260, Loss: 0.1439680257079323, Accuracy: 0.9208166666666666\n",
            "Batch: 270, Loss: 0.14212130762419803, Accuracy: 0.9223166666666667\n",
            "Batch: 280, Loss: 0.14143378445531157, Accuracy: 0.9226666666666666\n",
            "Batch: 290, Loss: 0.14167137605864455, Accuracy: 0.9221666666666667\n",
            "Batch: 300, Loss: 0.14136241184704082, Accuracy: 0.9222833333333333\n",
            "Batch: 310, Loss: 0.14163183484690467, Accuracy: 0.92235\n",
            "Batch: 320, Loss: 0.14176231751850898, Accuracy: 0.9221333333333334\n",
            "Batch: 330, Loss: 0.14187349432856664, Accuracy: 0.9227666666666666\n",
            "Batch: 340, Loss: 0.14247293041041792, Accuracy: 0.9225833333333333\n",
            "Batch: 350, Loss: 0.1420689404055992, Accuracy: 0.9227166666666666\n",
            "Batch: 360, Loss: 0.14323419797725012, Accuracy: 0.9218\n",
            "Batch: 370, Loss: 0.14220633323004625, Accuracy: 0.9220833333333334\n",
            "Batch: 380, Loss: 0.14164328505649967, Accuracy: 0.9221666666666667\n",
            "Batch: 390, Loss: 0.14129448408184936, Accuracy: 0.9226\n",
            "Batch: 400, Loss: 0.14149654835227268, Accuracy: 0.9224666666666667\n",
            "Batch: 410, Loss: 0.14131908381882627, Accuracy: 0.9224333333333333\n",
            "Batch: 420, Loss: 0.14118503876910818, Accuracy: 0.9228666666666666\n",
            "Batch: 430, Loss: 0.14177393105402505, Accuracy: 0.9220333333333334\n",
            "Batch: 440, Loss: 0.14220364314194228, Accuracy: 0.9223333333333333\n",
            "Batch: 450, Loss: 0.1415733952007987, Accuracy: 0.9225333333333333\n",
            "Batch: 460, Loss: 0.14186227171646248, Accuracy: 0.9222833333333333\n",
            "Batch: 470, Loss: 0.14119522022470352, Accuracy: 0.92285\n",
            "Batch: 480, Loss: 0.14085305540693005, Accuracy: 0.9229833333333334\n",
            "Batch: 490, Loss: 0.14112494856078878, Accuracy: 0.9226666666666666\n",
            "Batch: 500, Loss: 0.14109357084582855, Accuracy: 0.9224833333333333\n",
            "Batch: 510, Loss: 0.14121857703023785, Accuracy: 0.9221333333333334\n",
            "Batch: 520, Loss: 0.1411732079523388, Accuracy: 0.9224333333333333\n",
            "Batch: 530, Loss: 0.1411173790402073, Accuracy: 0.9230333333333334\n",
            "Batch: 540, Loss: 0.14089318770315393, Accuracy: 0.9233\n",
            "Batch: 550, Loss: 0.14086710181424916, Accuracy: 0.92265\n",
            "Batch: 560, Loss: 0.14176092307851648, Accuracy: 0.9218666666666666\n",
            "Batch: 570, Loss: 0.142385020617456, Accuracy: 0.92145\n",
            "Batch: 580, Loss: 0.14245610811685877, Accuracy: 0.92175\n",
            "Batch: 590, Loss: 0.1412588797582403, Accuracy: 0.92215\n",
            "Batch: 600, Loss: 0.1414935571495017, Accuracy: 0.9219166666666667\n",
            "Batch: 610, Loss: 0.14129051151392755, Accuracy: 0.9219166666666667\n",
            "Batch: 620, Loss: 0.14147379308413038, Accuracy: 0.9220666666666667\n",
            "Batch: 630, Loss: 0.14079650256657048, Accuracy: 0.9223333333333333\n",
            "Batch: 640, Loss: 0.14112707585970652, Accuracy: 0.9219833333333334\n",
            "Batch: 650, Loss: 0.14133745711463336, Accuracy: 0.9221166666666667\n",
            "Batch: 660, Loss: 0.14107529350683856, Accuracy: 0.9221\n",
            "Batch: 670, Loss: 0.14091783008373052, Accuracy: 0.9222833333333333\n",
            "Batch: 680, Loss: 0.1407162818993782, Accuracy: 0.9222666666666667\n",
            "Batch: 690, Loss: 0.14165696692367757, Accuracy: 0.9214\n",
            "Batch: 700, Loss: 0.14136712631248843, Accuracy: 0.92185\n",
            "Batch: 710, Loss: 0.14231482483798702, Accuracy: 0.9211333333333334\n",
            "Batch: 720, Loss: 0.14147902704430676, Accuracy: 0.92185\n",
            "Batch: 730, Loss: 0.14200387356978914, Accuracy: 0.9214333333333333\n",
            "Batch: 740, Loss: 0.141964441052882, Accuracy: 0.9216666666666666\n",
            "Batch: 750, Loss: 0.142552389448749, Accuracy: 0.9209833333333334\n",
            "Batch: 760, Loss: 0.1418546250462785, Accuracy: 0.9214833333333333\n",
            "Batch: 770, Loss: 0.14196934886009435, Accuracy: 0.9215833333333333\n",
            "Batch: 780, Loss: 0.14278082645992643, Accuracy: 0.9207166666666666\n",
            "Batch: 790, Loss: 0.14251897815924894, Accuracy: 0.92085\n",
            "Batch: 800, Loss: 0.1433909010343832, Accuracy: 0.9204333333333333\n",
            "Batch: 810, Loss: 0.1424774072708223, Accuracy: 0.9209333333333334\n",
            "Batch: 820, Loss: 0.14231731402699666, Accuracy: 0.921\n",
            "Batch: 830, Loss: 0.14114309950409473, Accuracy: 0.9218166666666666\n",
            "Batch: 840, Loss: 0.14081028248288138, Accuracy: 0.92185\n",
            "Batch: 850, Loss: 0.14111900253956394, Accuracy: 0.9217666666666666\n",
            "Batch: 860, Loss: 0.14222858724790977, Accuracy: 0.9208833333333334\n",
            "Batch: 870, Loss: 0.14140627240075715, Accuracy: 0.9215\n",
            "Batch: 880, Loss: 0.14132676586885004, Accuracy: 0.9217333333333333\n",
            "Batch: 890, Loss: 0.14173544500617358, Accuracy: 0.9215166666666667\n",
            "Batch: 900, Loss: 0.14179161758214173, Accuracy: 0.92135\n",
            "Batch: 910, Loss: 0.14085529256282855, Accuracy: 0.9219666666666667\n",
            "Batch: 920, Loss: 0.14101425434452006, Accuracy: 0.92205\n",
            "Batch: 930, Loss: 0.14169071873833078, Accuracy: 0.9210166666666667\n",
            "Epoch: 40, Loss: 0.14185589461657058, Accuracy: 0.9209666666666667\n",
            "Batch: 0, Loss: 0.14180433187444938, Accuracy: 0.9210833333333334\n",
            "Batch: 10, Loss: 0.14302169244492044, Accuracy: 0.9207166666666666\n",
            "Batch: 20, Loss: 0.1416601053620987, Accuracy: 0.9214833333333333\n",
            "Batch: 30, Loss: 0.1414134786439132, Accuracy: 0.9214\n",
            "Batch: 40, Loss: 0.1406034053337835, Accuracy: 0.9222666666666667\n",
            "Batch: 50, Loss: 0.1408386880989034, Accuracy: 0.92185\n",
            "Batch: 60, Loss: 0.14061416293472703, Accuracy: 0.9224166666666667\n",
            "Batch: 70, Loss: 0.14014026686112904, Accuracy: 0.9226333333333333\n",
            "Batch: 80, Loss: 0.13991219235889157, Accuracy: 0.92275\n",
            "Batch: 90, Loss: 0.13970606879887804, Accuracy: 0.9225666666666666\n",
            "Batch: 100, Loss: 0.13970943992411508, Accuracy: 0.9224833333333333\n",
            "Batch: 110, Loss: 0.14010042948266557, Accuracy: 0.9220833333333334\n",
            "Batch: 120, Loss: 0.14003353910959185, Accuracy: 0.9225666666666666\n",
            "Batch: 130, Loss: 0.14124174262673794, Accuracy: 0.922\n",
            "Batch: 140, Loss: 0.14259601476685943, Accuracy: 0.9208333333333333\n",
            "Batch: 150, Loss: 0.1412496183455789, Accuracy: 0.9214\n",
            "Batch: 160, Loss: 0.1412481821090558, Accuracy: 0.9212333333333333\n",
            "Batch: 170, Loss: 0.13985869314306887, Accuracy: 0.9220833333333334\n",
            "Batch: 180, Loss: 0.1400508674654445, Accuracy: 0.9219833333333334\n",
            "Batch: 190, Loss: 0.1408447433072623, Accuracy: 0.9221833333333334\n",
            "Batch: 200, Loss: 0.14135336060735484, Accuracy: 0.92145\n",
            "Batch: 210, Loss: 0.1414312218912502, Accuracy: 0.92175\n",
            "Batch: 220, Loss: 0.14198089888617904, Accuracy: 0.9218833333333334\n",
            "Batch: 230, Loss: 0.14178297914492513, Accuracy: 0.9219333333333334\n",
            "Batch: 240, Loss: 0.14218888900258794, Accuracy: 0.92185\n",
            "Batch: 250, Loss: 0.14139789785157664, Accuracy: 0.9222666666666667\n",
            "Batch: 260, Loss: 0.14193973816329158, Accuracy: 0.9216\n",
            "Batch: 270, Loss: 0.14014128104711346, Accuracy: 0.9230833333333334\n",
            "Batch: 280, Loss: 0.1394883081341314, Accuracy: 0.9233666666666667\n",
            "Batch: 290, Loss: 0.13975494187558932, Accuracy: 0.9231666666666667\n",
            "Batch: 300, Loss: 0.13946234526169482, Accuracy: 0.92315\n",
            "Batch: 310, Loss: 0.1397098254644947, Accuracy: 0.92345\n",
            "Batch: 320, Loss: 0.13982755616026984, Accuracy: 0.9229\n",
            "Batch: 330, Loss: 0.13991417968957373, Accuracy: 0.9235\n",
            "Batch: 340, Loss: 0.14049052772095616, Accuracy: 0.9231666666666667\n",
            "Batch: 350, Loss: 0.14013691119725563, Accuracy: 0.92365\n",
            "Batch: 360, Loss: 0.14135123419331985, Accuracy: 0.9224666666666667\n",
            "Batch: 370, Loss: 0.14028518395156442, Accuracy: 0.9228333333333333\n",
            "Batch: 380, Loss: 0.13973146158528174, Accuracy: 0.9230833333333334\n",
            "Batch: 390, Loss: 0.13940639545915573, Accuracy: 0.9234333333333333\n",
            "Batch: 400, Loss: 0.13960424330094115, Accuracy: 0.92315\n",
            "Batch: 410, Loss: 0.13941754744501414, Accuracy: 0.92295\n",
            "Batch: 420, Loss: 0.13928322718390718, Accuracy: 0.9235666666666666\n",
            "Batch: 430, Loss: 0.13978337120515708, Accuracy: 0.9229333333333334\n",
            "Batch: 440, Loss: 0.14032607041984285, Accuracy: 0.9231333333333334\n",
            "Batch: 450, Loss: 0.13968796216179902, Accuracy: 0.9233\n",
            "Batch: 460, Loss: 0.1399742718887221, Accuracy: 0.92305\n",
            "Batch: 470, Loss: 0.1393075594888137, Accuracy: 0.9237166666666666\n",
            "Batch: 480, Loss: 0.13894233501642939, Accuracy: 0.9240333333333334\n",
            "Batch: 490, Loss: 0.13916573776253746, Accuracy: 0.9235666666666666\n",
            "Batch: 500, Loss: 0.139191812579901, Accuracy: 0.92355\n",
            "Batch: 510, Loss: 0.13933101755682606, Accuracy: 0.9229166666666667\n",
            "Batch: 520, Loss: 0.13929295158595364, Accuracy: 0.9233333333333333\n",
            "Batch: 530, Loss: 0.13924485172714235, Accuracy: 0.9237666666666666\n",
            "Batch: 540, Loss: 0.13899252125452413, Accuracy: 0.9242166666666667\n",
            "Batch: 550, Loss: 0.13897327646323232, Accuracy: 0.9235333333333333\n",
            "Batch: 560, Loss: 0.13981663881326, Accuracy: 0.9227166666666666\n",
            "Batch: 570, Loss: 0.14039095246773636, Accuracy: 0.92215\n",
            "Batch: 580, Loss: 0.14054050214461172, Accuracy: 0.9225\n",
            "Batch: 590, Loss: 0.1394447667869014, Accuracy: 0.9228166666666666\n",
            "Batch: 600, Loss: 0.1396140011939551, Accuracy: 0.9226333333333333\n",
            "Batch: 610, Loss: 0.13942789157341184, Accuracy: 0.9229\n",
            "Batch: 620, Loss: 0.13958863162272575, Accuracy: 0.9228833333333334\n",
            "Batch: 630, Loss: 0.13893040898544737, Accuracy: 0.9232666666666667\n",
            "Batch: 640, Loss: 0.1392300338672693, Accuracy: 0.9228\n",
            "Batch: 650, Loss: 0.13947415295690913, Accuracy: 0.92305\n",
            "Batch: 660, Loss: 0.1392312433009906, Accuracy: 0.92305\n",
            "Batch: 670, Loss: 0.13898496916839845, Accuracy: 0.92305\n",
            "Batch: 680, Loss: 0.13881777444999036, Accuracy: 0.9230666666666667\n",
            "Batch: 690, Loss: 0.13982851900586382, Accuracy: 0.9221666666666667\n",
            "Batch: 700, Loss: 0.13955944364338124, Accuracy: 0.92295\n",
            "Batch: 710, Loss: 0.14043159473476863, Accuracy: 0.92195\n",
            "Batch: 720, Loss: 0.1396033572795002, Accuracy: 0.9227333333333333\n",
            "Batch: 730, Loss: 0.1401159876142841, Accuracy: 0.9224666666666667\n",
            "Batch: 740, Loss: 0.14009220908149292, Accuracy: 0.9224666666666667\n",
            "Batch: 750, Loss: 0.14069238407676649, Accuracy: 0.9218\n",
            "Batch: 760, Loss: 0.14003034576203996, Accuracy: 0.9222\n",
            "Batch: 770, Loss: 0.14003156000861763, Accuracy: 0.9225\n",
            "Batch: 780, Loss: 0.14088216346661084, Accuracy: 0.92155\n",
            "Batch: 790, Loss: 0.14065559471685393, Accuracy: 0.9215833333333333\n",
            "Batch: 800, Loss: 0.1415112528446137, Accuracy: 0.9212333333333333\n",
            "Batch: 810, Loss: 0.14059299604815573, Accuracy: 0.9216833333333333\n",
            "Batch: 820, Loss: 0.14042387527439854, Accuracy: 0.9217\n",
            "Batch: 830, Loss: 0.13934024795808833, Accuracy: 0.9228\n",
            "Batch: 840, Loss: 0.13898082773692866, Accuracy: 0.9228\n",
            "Batch: 850, Loss: 0.13924773721733336, Accuracy: 0.9227833333333333\n",
            "Batch: 860, Loss: 0.14042090291188852, Accuracy: 0.92175\n",
            "Batch: 870, Loss: 0.13966258723749936, Accuracy: 0.92255\n",
            "Batch: 880, Loss: 0.1395527113927533, Accuracy: 0.92255\n",
            "Batch: 890, Loss: 0.13994910226638976, Accuracy: 0.9222333333333333\n",
            "Batch: 900, Loss: 0.13998131682359224, Accuracy: 0.9222833333333333\n",
            "Batch: 910, Loss: 0.13904014515444027, Accuracy: 0.9229166666666667\n",
            "Batch: 920, Loss: 0.1391765387806553, Accuracy: 0.92285\n",
            "Batch: 930, Loss: 0.13986807866095402, Accuracy: 0.9220166666666667\n",
            "Epoch: 41, Loss: 0.14000285413711552, Accuracy: 0.92185\n",
            "Batch: 0, Loss: 0.139952019424985, Accuracy: 0.9219666666666667\n",
            "Batch: 10, Loss: 0.1411882498744035, Accuracy: 0.9215333333333333\n",
            "Batch: 20, Loss: 0.1397547779131394, Accuracy: 0.92245\n",
            "Batch: 30, Loss: 0.13951259854599818, Accuracy: 0.9224666666666667\n",
            "Batch: 40, Loss: 0.13870327792617573, Accuracy: 0.92315\n",
            "Batch: 50, Loss: 0.1389599777944174, Accuracy: 0.9226166666666666\n",
            "Batch: 60, Loss: 0.1387897979165721, Accuracy: 0.9232666666666667\n",
            "Batch: 70, Loss: 0.13829616097385436, Accuracy: 0.92345\n",
            "Batch: 80, Loss: 0.13806353458148404, Accuracy: 0.9234\n",
            "Batch: 90, Loss: 0.13782952814873237, Accuracy: 0.9232833333333333\n",
            "Batch: 100, Loss: 0.13775584832794024, Accuracy: 0.92335\n",
            "Batch: 110, Loss: 0.13814914032464928, Accuracy: 0.9229333333333334\n",
            "Batch: 120, Loss: 0.138084310495363, Accuracy: 0.9235166666666667\n",
            "Batch: 130, Loss: 0.13931815738640985, Accuracy: 0.9228\n",
            "Batch: 140, Loss: 0.14060556471675648, Accuracy: 0.92195\n",
            "Batch: 150, Loss: 0.13920929530837337, Accuracy: 0.9222666666666667\n",
            "Batch: 160, Loss: 0.13917671297781636, Accuracy: 0.9221666666666667\n",
            "Batch: 170, Loss: 0.13788063702904355, Accuracy: 0.9229\n",
            "Batch: 180, Loss: 0.1382099146814911, Accuracy: 0.9230666666666667\n",
            "Batch: 190, Loss: 0.13903883071607442, Accuracy: 0.9228\n",
            "Batch: 200, Loss: 0.13950049103518242, Accuracy: 0.9222333333333333\n",
            "Batch: 210, Loss: 0.13953828870348634, Accuracy: 0.92245\n",
            "Batch: 220, Loss: 0.14012464872259955, Accuracy: 0.9228333333333333\n",
            "Batch: 230, Loss: 0.1399578040786352, Accuracy: 0.9227\n",
            "Batch: 240, Loss: 0.1403651444032739, Accuracy: 0.9227166666666666\n",
            "Batch: 250, Loss: 0.13951183367694794, Accuracy: 0.9232333333333334\n",
            "Batch: 260, Loss: 0.1399379330817831, Accuracy: 0.92275\n",
            "Batch: 270, Loss: 0.13820544809717825, Accuracy: 0.9239333333333334\n",
            "Batch: 280, Loss: 0.1375957208198911, Accuracy: 0.9241333333333334\n",
            "Batch: 290, Loss: 0.13790791307902786, Accuracy: 0.9240166666666667\n",
            "Batch: 300, Loss: 0.13764346365683225, Accuracy: 0.9240333333333334\n",
            "Batch: 310, Loss: 0.13786144960288804, Accuracy: 0.9242\n",
            "Batch: 320, Loss: 0.1379518564826212, Accuracy: 0.9238333333333333\n",
            "Batch: 330, Loss: 0.13795387445321022, Accuracy: 0.92435\n",
            "Batch: 340, Loss: 0.13849325498780807, Accuracy: 0.9239666666666667\n",
            "Batch: 350, Loss: 0.13819510926717088, Accuracy: 0.9241666666666667\n",
            "Batch: 360, Loss: 0.13945919060876522, Accuracy: 0.923\n",
            "Batch: 370, Loss: 0.13840422276651265, Accuracy: 0.9232833333333333\n",
            "Batch: 380, Loss: 0.1378787562385809, Accuracy: 0.9239\n",
            "Batch: 390, Loss: 0.1375589664043605, Accuracy: 0.9239833333333334\n",
            "Batch: 400, Loss: 0.13773962986941446, Accuracy: 0.9236\n",
            "Batch: 410, Loss: 0.13756134233869563, Accuracy: 0.9238833333333333\n",
            "Batch: 420, Loss: 0.13743474163457034, Accuracy: 0.9243666666666667\n",
            "Batch: 430, Loss: 0.13781372186935328, Accuracy: 0.9236666666666666\n",
            "Batch: 440, Loss: 0.13851500431993355, Accuracy: 0.92395\n",
            "Batch: 450, Loss: 0.13784153133843813, Accuracy: 0.9241666666666667\n",
            "Batch: 460, Loss: 0.13809536406075656, Accuracy: 0.9237\n",
            "Batch: 470, Loss: 0.13747777670131625, Accuracy: 0.9241666666666667\n",
            "Batch: 480, Loss: 0.13708810245517894, Accuracy: 0.9247166666666666\n",
            "Batch: 490, Loss: 0.13726887737219443, Accuracy: 0.9243\n",
            "Batch: 500, Loss: 0.13734951567311482, Accuracy: 0.9243333333333333\n",
            "Batch: 510, Loss: 0.13748530299591152, Accuracy: 0.9237333333333333\n",
            "Batch: 520, Loss: 0.13745909105015178, Accuracy: 0.9241666666666667\n",
            "Batch: 530, Loss: 0.13740954199854855, Accuracy: 0.9246666666666666\n",
            "Batch: 540, Loss: 0.13710116559453417, Accuracy: 0.9248666666666666\n",
            "Batch: 550, Loss: 0.13710665093400748, Accuracy: 0.9243666666666667\n",
            "Batch: 560, Loss: 0.13792308182006163, Accuracy: 0.9234166666666667\n",
            "Batch: 570, Loss: 0.13846398594763834, Accuracy: 0.9229\n",
            "Batch: 580, Loss: 0.13861571172591486, Accuracy: 0.9232833333333333\n",
            "Batch: 590, Loss: 0.13763590943260243, Accuracy: 0.9236\n",
            "Batch: 600, Loss: 0.13776534155324532, Accuracy: 0.9234666666666667\n",
            "Batch: 610, Loss: 0.13760440922037329, Accuracy: 0.9236333333333333\n",
            "Batch: 620, Loss: 0.137725823335057, Accuracy: 0.9236333333333333\n",
            "Batch: 630, Loss: 0.13709006810764487, Accuracy: 0.9239833333333334\n",
            "Batch: 640, Loss: 0.13734750622171363, Accuracy: 0.9235666666666666\n",
            "Batch: 650, Loss: 0.1376236242920186, Accuracy: 0.92375\n",
            "Batch: 660, Loss: 0.1374141729864456, Accuracy: 0.9238666666666666\n",
            "Batch: 670, Loss: 0.13712160470544305, Accuracy: 0.92385\n",
            "Batch: 680, Loss: 0.1369616934580865, Accuracy: 0.92405\n",
            "Batch: 690, Loss: 0.1379932572116391, Accuracy: 0.9231166666666667\n",
            "Batch: 700, Loss: 0.13777391668180852, Accuracy: 0.9234\n",
            "Batch: 710, Loss: 0.13852697848139023, Accuracy: 0.9227333333333333\n",
            "Batch: 720, Loss: 0.13775237778021604, Accuracy: 0.9233833333333333\n",
            "Batch: 730, Loss: 0.13828539042056506, Accuracy: 0.92325\n",
            "Batch: 740, Loss: 0.13830844268331619, Accuracy: 0.9231333333333334\n",
            "Batch: 750, Loss: 0.1389633142934011, Accuracy: 0.9224333333333333\n",
            "Batch: 760, Loss: 0.13828588178256634, Accuracy: 0.9229833333333334\n",
            "Batch: 770, Loss: 0.1381355798139674, Accuracy: 0.9232666666666667\n",
            "Batch: 780, Loss: 0.13903088436025704, Accuracy: 0.9224666666666667\n",
            "Batch: 790, Loss: 0.1388544623821355, Accuracy: 0.9224666666666667\n",
            "Batch: 800, Loss: 0.13970835629844452, Accuracy: 0.9217166666666666\n",
            "Batch: 810, Loss: 0.13876667042015547, Accuracy: 0.9227833333333333\n",
            "Batch: 820, Loss: 0.13858958467845273, Accuracy: 0.9225166666666667\n",
            "Batch: 830, Loss: 0.13754825561860473, Accuracy: 0.92335\n",
            "Batch: 840, Loss: 0.13718233188910975, Accuracy: 0.92355\n",
            "Batch: 850, Loss: 0.13744052435375614, Accuracy: 0.9237166666666666\n",
            "Batch: 860, Loss: 0.13862934736345817, Accuracy: 0.9225166666666667\n",
            "Batch: 870, Loss: 0.13793462821526717, Accuracy: 0.9232333333333334\n",
            "Batch: 880, Loss: 0.13781155387838276, Accuracy: 0.92335\n",
            "Batch: 890, Loss: 0.13817922437282573, Accuracy: 0.923\n",
            "Batch: 900, Loss: 0.13820448643785602, Accuracy: 0.9228\n",
            "Batch: 910, Loss: 0.13723311543971808, Accuracy: 0.92365\n",
            "Batch: 920, Loss: 0.13736054489090718, Accuracy: 0.9235166666666667\n",
            "Batch: 930, Loss: 0.13806347603775945, Accuracy: 0.92285\n",
            "Epoch: 42, Loss: 0.1381843540069502, Accuracy: 0.9227833333333333\n",
            "Batch: 0, Loss: 0.13813699513194228, Accuracy: 0.9229333333333334\n",
            "Batch: 10, Loss: 0.1393930936602841, Accuracy: 0.9224166666666667\n",
            "Batch: 20, Loss: 0.1378861114417882, Accuracy: 0.92315\n",
            "Batch: 30, Loss: 0.13760467439565013, Accuracy: 0.9231\n",
            "Batch: 40, Loss: 0.1368467224987828, Accuracy: 0.9238833333333333\n",
            "Batch: 50, Loss: 0.13713829041606201, Accuracy: 0.9235\n",
            "Batch: 60, Loss: 0.13699957831958465, Accuracy: 0.9239333333333334\n",
            "Batch: 70, Loss: 0.1365095143457544, Accuracy: 0.9242833333333333\n",
            "Batch: 80, Loss: 0.13631466413567112, Accuracy: 0.9241333333333334\n",
            "Batch: 90, Loss: 0.13601758282509438, Accuracy: 0.9241333333333334\n",
            "Batch: 100, Loss: 0.1359202591889827, Accuracy: 0.9241\n",
            "Batch: 110, Loss: 0.1362712726440484, Accuracy: 0.9239833333333334\n",
            "Batch: 120, Loss: 0.1361799316676324, Accuracy: 0.9242833333333333\n",
            "Batch: 130, Loss: 0.13742579489982273, Accuracy: 0.92365\n",
            "Batch: 140, Loss: 0.13867075669531664, Accuracy: 0.9228\n",
            "Batch: 150, Loss: 0.13728485947038369, Accuracy: 0.9232333333333334\n",
            "Batch: 160, Loss: 0.13720189474573685, Accuracy: 0.92315\n",
            "Batch: 170, Loss: 0.13594181299706098, Accuracy: 0.9239\n",
            "Batch: 180, Loss: 0.1363893878184753, Accuracy: 0.9240833333333334\n",
            "Batch: 190, Loss: 0.13724361941763838, Accuracy: 0.9236166666666666\n",
            "Batch: 200, Loss: 0.13763655144268847, Accuracy: 0.92305\n",
            "Batch: 210, Loss: 0.1377365214413309, Accuracy: 0.9233\n",
            "Batch: 220, Loss: 0.1383304134160408, Accuracy: 0.9235833333333333\n",
            "Batch: 230, Loss: 0.13819634768227304, Accuracy: 0.92355\n",
            "Batch: 240, Loss: 0.13860978127160095, Accuracy: 0.9235\n",
            "Batch: 250, Loss: 0.13771985802917913, Accuracy: 0.9240166666666667\n",
            "Batch: 260, Loss: 0.13804888356726622, Accuracy: 0.9235666666666666\n",
            "Batch: 270, Loss: 0.13635153219147206, Accuracy: 0.9244833333333333\n",
            "Batch: 280, Loss: 0.13577397064116706, Accuracy: 0.9248666666666666\n",
            "Batch: 290, Loss: 0.13614136524360246, Accuracy: 0.9245333333333333\n",
            "Batch: 300, Loss: 0.13589955672040738, Accuracy: 0.9244833333333333\n",
            "Batch: 310, Loss: 0.1360902691419629, Accuracy: 0.9247166666666666\n",
            "Batch: 320, Loss: 0.13613955483902773, Accuracy: 0.92475\n",
            "Batch: 330, Loss: 0.1360987022917406, Accuracy: 0.9247666666666666\n",
            "Batch: 340, Loss: 0.1365914960053128, Accuracy: 0.9246833333333333\n",
            "Batch: 350, Loss: 0.13632216447079817, Accuracy: 0.92495\n",
            "Batch: 360, Loss: 0.13762775828719592, Accuracy: 0.9235166666666667\n",
            "Batch: 370, Loss: 0.13657835622700376, Accuracy: 0.92395\n",
            "Batch: 380, Loss: 0.1360877556119584, Accuracy: 0.9244833333333333\n",
            "Batch: 390, Loss: 0.13575769409419955, Accuracy: 0.9247333333333333\n",
            "Batch: 400, Loss: 0.13591863796982856, Accuracy: 0.9243333333333333\n",
            "Batch: 410, Loss: 0.1357530019711164, Accuracy: 0.9245333333333333\n",
            "Batch: 420, Loss: 0.1356503931436914, Accuracy: 0.9249666666666667\n",
            "Batch: 430, Loss: 0.13590617093339183, Accuracy: 0.9245166666666667\n",
            "Batch: 440, Loss: 0.13672623121649505, Accuracy: 0.9247333333333333\n",
            "Batch: 450, Loss: 0.13603423986458016, Accuracy: 0.9247666666666666\n",
            "Batch: 460, Loss: 0.1362316006794717, Accuracy: 0.9244666666666667\n",
            "Batch: 470, Loss: 0.1356964193916394, Accuracy: 0.9248666666666666\n",
            "Batch: 480, Loss: 0.1352847055757127, Accuracy: 0.9254166666666667\n",
            "Batch: 490, Loss: 0.13547073443488436, Accuracy: 0.9249833333333334\n",
            "Batch: 500, Loss: 0.13557368449991195, Accuracy: 0.9248833333333333\n",
            "Batch: 510, Loss: 0.13566860211405035, Accuracy: 0.9244833333333333\n",
            "Batch: 520, Loss: 0.13565047096034147, Accuracy: 0.9249833333333334\n",
            "Batch: 530, Loss: 0.1356173222985252, Accuracy: 0.9251\n",
            "Batch: 540, Loss: 0.13524532763490807, Accuracy: 0.9254333333333333\n",
            "Batch: 550, Loss: 0.13529553681113324, Accuracy: 0.9251\n",
            "Batch: 560, Loss: 0.13611191343319004, Accuracy: 0.9241833333333334\n",
            "Batch: 570, Loss: 0.1366329289638986, Accuracy: 0.9236833333333333\n",
            "Batch: 580, Loss: 0.1367361448651964, Accuracy: 0.9240166666666667\n",
            "Batch: 590, Loss: 0.13584607041775493, Accuracy: 0.9245166666666667\n",
            "Batch: 600, Loss: 0.13593614967161974, Accuracy: 0.9242666666666667\n",
            "Batch: 610, Loss: 0.13580881610986373, Accuracy: 0.9242333333333334\n",
            "Batch: 620, Loss: 0.13591740245729012, Accuracy: 0.92445\n",
            "Batch: 630, Loss: 0.13527623895566257, Accuracy: 0.9246666666666666\n",
            "Batch: 640, Loss: 0.13552047431518224, Accuracy: 0.92435\n",
            "Batch: 650, Loss: 0.13581276797576794, Accuracy: 0.9247833333333333\n",
            "Batch: 660, Loss: 0.13566489134814164, Accuracy: 0.92465\n",
            "Batch: 670, Loss: 0.1353478341462858, Accuracy: 0.9246833333333333\n",
            "Batch: 680, Loss: 0.13518908251831538, Accuracy: 0.9250166666666667\n",
            "Batch: 690, Loss: 0.13616408104553182, Accuracy: 0.92405\n",
            "Batch: 700, Loss: 0.1359862683132381, Accuracy: 0.9240833333333334\n",
            "Batch: 710, Loss: 0.13662817313167608, Accuracy: 0.92375\n",
            "Batch: 720, Loss: 0.13589352555372142, Accuracy: 0.92435\n",
            "Batch: 730, Loss: 0.1364674854637116, Accuracy: 0.9242333333333334\n",
            "Batch: 740, Loss: 0.13649303970825533, Accuracy: 0.9239333333333334\n",
            "Batch: 750, Loss: 0.13724377300524937, Accuracy: 0.92335\n",
            "Batch: 760, Loss: 0.13653446266531075, Accuracy: 0.9238833333333333\n",
            "Batch: 770, Loss: 0.13627363447372423, Accuracy: 0.9241166666666667\n",
            "Batch: 780, Loss: 0.13720779763398186, Accuracy: 0.9233\n",
            "Batch: 790, Loss: 0.1370680095448021, Accuracy: 0.9233\n",
            "Batch: 800, Loss: 0.13795737007501294, Accuracy: 0.9225833333333333\n",
            "Batch: 810, Loss: 0.13696398170100238, Accuracy: 0.92385\n",
            "Batch: 820, Loss: 0.13683222776735326, Accuracy: 0.9235666666666666\n",
            "Batch: 830, Loss: 0.13578675140332427, Accuracy: 0.9241333333333334\n",
            "Batch: 840, Loss: 0.13542053926062497, Accuracy: 0.9242666666666667\n",
            "Batch: 850, Loss: 0.13572023557242766, Accuracy: 0.9245\n",
            "Batch: 860, Loss: 0.1368978514574959, Accuracy: 0.9234\n",
            "Batch: 870, Loss: 0.13622633613268856, Accuracy: 0.9239666666666667\n",
            "Batch: 880, Loss: 0.13608738340061838, Accuracy: 0.9241666666666667\n",
            "Batch: 890, Loss: 0.13641114651341715, Accuracy: 0.92375\n",
            "Batch: 900, Loss: 0.13646638789463214, Accuracy: 0.9235333333333333\n",
            "Batch: 910, Loss: 0.13546324884220193, Accuracy: 0.9245666666666666\n",
            "Batch: 920, Loss: 0.13555783573054375, Accuracy: 0.9242833333333333\n",
            "Batch: 930, Loss: 0.1362703012935179, Accuracy: 0.9235833333333333\n",
            "Epoch: 43, Loss: 0.13638541827239373, Accuracy: 0.9234833333333333\n",
            "Batch: 0, Loss: 0.13634856926528488, Accuracy: 0.9235333333333333\n",
            "Batch: 10, Loss: 0.1375801047129319, Accuracy: 0.9231333333333334\n",
            "Batch: 20, Loss: 0.13601378579588858, Accuracy: 0.92405\n",
            "Batch: 30, Loss: 0.13566911425362085, Accuracy: 0.9242166666666667\n",
            "Batch: 40, Loss: 0.13500793545443943, Accuracy: 0.92475\n",
            "Batch: 50, Loss: 0.13530293580244657, Accuracy: 0.9243333333333333\n",
            "Batch: 60, Loss: 0.13515337820328727, Accuracy: 0.9247666666666666\n",
            "Batch: 70, Loss: 0.13470798223225444, Accuracy: 0.9249833333333334\n",
            "Batch: 80, Loss: 0.13457922441355125, Accuracy: 0.9250166666666667\n",
            "Batch: 90, Loss: 0.13422096040874526, Accuracy: 0.9249\n",
            "Batch: 100, Loss: 0.1341522815738584, Accuracy: 0.9248666666666666\n",
            "Batch: 110, Loss: 0.13449287284089353, Accuracy: 0.9245666666666666\n",
            "Batch: 120, Loss: 0.13435933970964672, Accuracy: 0.9249666666666667\n",
            "Batch: 130, Loss: 0.13561462189870707, Accuracy: 0.9243333333333333\n",
            "Batch: 140, Loss: 0.13676086435196322, Accuracy: 0.9235833333333333\n",
            "Batch: 150, Loss: 0.135400687787023, Accuracy: 0.92415\n",
            "Batch: 160, Loss: 0.13524183527309655, Accuracy: 0.9240166666666667\n",
            "Batch: 170, Loss: 0.13405979465123, Accuracy: 0.92475\n",
            "Batch: 180, Loss: 0.13459801041237984, Accuracy: 0.9247666666666666\n",
            "Batch: 190, Loss: 0.13544481341740036, Accuracy: 0.92465\n",
            "Batch: 200, Loss: 0.13573636281711504, Accuracy: 0.92395\n",
            "Batch: 210, Loss: 0.13600679627742152, Accuracy: 0.9243\n",
            "Batch: 220, Loss: 0.13659023940567797, Accuracy: 0.9243666666666667\n",
            "Batch: 230, Loss: 0.1364502437497199, Accuracy: 0.9242833333333333\n",
            "Batch: 240, Loss: 0.13689980982969271, Accuracy: 0.9242833333333333\n",
            "Batch: 250, Loss: 0.13598507623628792, Accuracy: 0.9247833333333333\n",
            "Batch: 260, Loss: 0.13626115112464368, Accuracy: 0.9245333333333333\n",
            "Batch: 270, Loss: 0.1345689059535538, Accuracy: 0.9254666666666667\n",
            "Batch: 280, Loss: 0.1340013296861836, Accuracy: 0.9257333333333333\n",
            "Batch: 290, Loss: 0.13441871412264858, Accuracy: 0.9254833333333333\n",
            "Batch: 300, Loss: 0.134194914733671, Accuracy: 0.9252666666666667\n",
            "Batch: 310, Loss: 0.13437456888294216, Accuracy: 0.9253833333333333\n",
            "Batch: 320, Loss: 0.13436633471744522, Accuracy: 0.9254833333333333\n",
            "Batch: 330, Loss: 0.1342926300571054, Accuracy: 0.92545\n",
            "Batch: 340, Loss: 0.13472806889731948, Accuracy: 0.92545\n",
            "Batch: 350, Loss: 0.1344944111088192, Accuracy: 0.9254333333333333\n",
            "Batch: 360, Loss: 0.1358501851580009, Accuracy: 0.9240166666666667\n",
            "Batch: 370, Loss: 0.1347977673001435, Accuracy: 0.9249833333333334\n",
            "Batch: 380, Loss: 0.1343185507866627, Accuracy: 0.9251166666666667\n",
            "Batch: 390, Loss: 0.13399239167537239, Accuracy: 0.9255166666666667\n",
            "Batch: 400, Loss: 0.13411682022397056, Accuracy: 0.9251666666666667\n",
            "Batch: 410, Loss: 0.13397700229499518, Accuracy: 0.9253833333333333\n",
            "Batch: 420, Loss: 0.1338846132508176, Accuracy: 0.9255833333333333\n",
            "Batch: 430, Loss: 0.1340545692198339, Accuracy: 0.92535\n",
            "Batch: 440, Loss: 0.1349365860773902, Accuracy: 0.9254\n",
            "Batch: 450, Loss: 0.13425025233395013, Accuracy: 0.9255\n",
            "Batch: 460, Loss: 0.1344011002356768, Accuracy: 0.92515\n",
            "Batch: 470, Loss: 0.13393691421225457, Accuracy: 0.92555\n",
            "Batch: 480, Loss: 0.13351943658809262, Accuracy: 0.9262\n",
            "Batch: 490, Loss: 0.13373534982727056, Accuracy: 0.9259\n",
            "Batch: 500, Loss: 0.13388465846168693, Accuracy: 0.9257\n",
            "Batch: 510, Loss: 0.13391049253308657, Accuracy: 0.92525\n",
            "Batch: 520, Loss: 0.1338929445777394, Accuracy: 0.9258166666666666\n",
            "Batch: 530, Loss: 0.1338725748720796, Accuracy: 0.92575\n",
            "Batch: 540, Loss: 0.13347888581350922, Accuracy: 0.9261833333333334\n",
            "Batch: 550, Loss: 0.1335244679199726, Accuracy: 0.9258333333333333\n",
            "Batch: 560, Loss: 0.13434026197488544, Accuracy: 0.9249833333333334\n",
            "Batch: 570, Loss: 0.13482960261521745, Accuracy: 0.9245166666666667\n",
            "Batch: 580, Loss: 0.13486411532493006, Accuracy: 0.9248833333333333\n",
            "Batch: 590, Loss: 0.13407358954166004, Accuracy: 0.9252833333333333\n",
            "Batch: 600, Loss: 0.13407932025167105, Accuracy: 0.92495\n",
            "Batch: 610, Loss: 0.133945958001244, Accuracy: 0.9251\n",
            "Batch: 620, Loss: 0.1341555826569864, Accuracy: 0.9251833333333334\n",
            "Batch: 630, Loss: 0.13343684163421968, Accuracy: 0.9255666666666666\n",
            "Batch: 640, Loss: 0.13370923757452333, Accuracy: 0.9253666666666667\n",
            "Batch: 650, Loss: 0.13401610639456232, Accuracy: 0.9254833333333333\n",
            "Batch: 660, Loss: 0.13395456874047898, Accuracy: 0.9255\n",
            "Batch: 670, Loss: 0.1336404198194759, Accuracy: 0.9253833333333333\n",
            "Batch: 680, Loss: 0.1334637484176367, Accuracy: 0.9257\n",
            "Batch: 690, Loss: 0.13440688037461404, Accuracy: 0.92515\n",
            "Batch: 700, Loss: 0.13425212309268883, Accuracy: 0.92515\n",
            "Batch: 710, Loss: 0.13486185095190797, Accuracy: 0.9244666666666667\n",
            "Batch: 720, Loss: 0.13410406303659805, Accuracy: 0.9250666666666667\n",
            "Batch: 730, Loss: 0.13471461791649564, Accuracy: 0.92495\n",
            "Batch: 740, Loss: 0.1346785237747425, Accuracy: 0.9246666666666666\n",
            "Batch: 750, Loss: 0.13552653505582093, Accuracy: 0.9238833333333333\n",
            "Batch: 760, Loss: 0.13475946881979853, Accuracy: 0.9246166666666666\n",
            "Batch: 770, Loss: 0.1344460514744021, Accuracy: 0.9249666666666667\n",
            "Batch: 780, Loss: 0.13535051409324858, Accuracy: 0.9241333333333334\n",
            "Batch: 790, Loss: 0.13525335393044352, Accuracy: 0.9240833333333334\n",
            "Batch: 800, Loss: 0.13622334819681287, Accuracy: 0.9234666666666667\n",
            "Batch: 810, Loss: 0.13516883491450332, Accuracy: 0.9243\n",
            "Batch: 820, Loss: 0.13513582680062378, Accuracy: 0.9242333333333334\n",
            "Batch: 830, Loss: 0.13407200620161971, Accuracy: 0.92495\n",
            "Batch: 840, Loss: 0.13371123647943106, Accuracy: 0.9251666666666667\n",
            "Batch: 850, Loss: 0.1340826958050056, Accuracy: 0.92515\n",
            "Batch: 860, Loss: 0.13524951532551432, Accuracy: 0.9240833333333334\n",
            "Batch: 870, Loss: 0.13450912662842807, Accuracy: 0.9247666666666666\n",
            "Batch: 880, Loss: 0.13435295244576922, Accuracy: 0.9248166666666666\n",
            "Batch: 890, Loss: 0.13463602147202453, Accuracy: 0.9246166666666666\n",
            "Batch: 900, Loss: 0.13474591177102724, Accuracy: 0.9243666666666667\n",
            "Batch: 910, Loss: 0.13373457641482447, Accuracy: 0.9254666666666667\n",
            "Batch: 920, Loss: 0.13377198619946293, Accuracy: 0.9252\n",
            "Batch: 930, Loss: 0.13450724297069383, Accuracy: 0.9246666666666666\n",
            "Epoch: 44, Loss: 0.13461931326342658, Accuracy: 0.9243\n",
            "Batch: 0, Loss: 0.13461379347955624, Accuracy: 0.9243666666666667\n",
            "Batch: 10, Loss: 0.13579747572141046, Accuracy: 0.9239333333333334\n",
            "Batch: 20, Loss: 0.13418576552031136, Accuracy: 0.9251666666666667\n",
            "Batch: 30, Loss: 0.1338041529953981, Accuracy: 0.92525\n",
            "Batch: 40, Loss: 0.1332177100380503, Accuracy: 0.92535\n",
            "Batch: 50, Loss: 0.1335025349374398, Accuracy: 0.9253\n",
            "Batch: 60, Loss: 0.1333289457407009, Accuracy: 0.9254166666666667\n",
            "Batch: 70, Loss: 0.13295247555666997, Accuracy: 0.9256666666666666\n",
            "Batch: 80, Loss: 0.1328909637049957, Accuracy: 0.9259\n",
            "Batch: 90, Loss: 0.13247925021772403, Accuracy: 0.9260333333333334\n",
            "Batch: 100, Loss: 0.13244592465370672, Accuracy: 0.92545\n",
            "Batch: 110, Loss: 0.1327671970635486, Accuracy: 0.9253666666666667\n",
            "Batch: 120, Loss: 0.1325823045749844, Accuracy: 0.9257666666666666\n",
            "Batch: 130, Loss: 0.13387249845720808, Accuracy: 0.9251\n",
            "Batch: 140, Loss: 0.13494411360810715, Accuracy: 0.92445\n",
            "Batch: 150, Loss: 0.13359908750019772, Accuracy: 0.92505\n",
            "Batch: 160, Loss: 0.13335393629740233, Accuracy: 0.92505\n",
            "Batch: 170, Loss: 0.13224540584278316, Accuracy: 0.9256\n",
            "Batch: 180, Loss: 0.13285921137664078, Accuracy: 0.9255\n",
            "Batch: 190, Loss: 0.1336971724673424, Accuracy: 0.92525\n",
            "Batch: 200, Loss: 0.133895847868363, Accuracy: 0.9248166666666666\n",
            "Batch: 210, Loss: 0.13431233655092722, Accuracy: 0.9247833333333333\n",
            "Batch: 220, Loss: 0.13484496676304378, Accuracy: 0.9251666666666667\n",
            "Batch: 230, Loss: 0.1347400316698483, Accuracy: 0.9251833333333334\n",
            "Batch: 240, Loss: 0.13523149792403913, Accuracy: 0.9247333333333333\n",
            "Batch: 250, Loss: 0.13428490972211776, Accuracy: 0.9255\n",
            "Batch: 260, Loss: 0.13458144807880917, Accuracy: 0.9252833333333333\n",
            "Batch: 270, Loss: 0.13289318406100553, Accuracy: 0.9261833333333334\n",
            "Batch: 280, Loss: 0.13228600845890864, Accuracy: 0.9263666666666667\n",
            "Batch: 290, Loss: 0.13270674093851778, Accuracy: 0.9260166666666667\n",
            "Batch: 300, Loss: 0.13249173599052091, Accuracy: 0.9260833333333334\n",
            "Batch: 310, Loss: 0.13269251925021375, Accuracy: 0.9262333333333334\n",
            "Batch: 320, Loss: 0.1326070325357469, Accuracy: 0.92625\n",
            "Batch: 330, Loss: 0.132498658283689, Accuracy: 0.9261833333333334\n",
            "Batch: 340, Loss: 0.13290036782969894, Accuracy: 0.9263166666666667\n",
            "Batch: 350, Loss: 0.13269198245368705, Accuracy: 0.9261\n",
            "Batch: 360, Loss: 0.13427824297451135, Accuracy: 0.92485\n",
            "Batch: 370, Loss: 0.13315174442085895, Accuracy: 0.9254166666666667\n",
            "Batch: 380, Loss: 0.13259834605430304, Accuracy: 0.9258833333333333\n",
            "Batch: 390, Loss: 0.1322869539429127, Accuracy: 0.9260666666666667\n",
            "Batch: 400, Loss: 0.13236052859900493, Accuracy: 0.9259166666666667\n",
            "Batch: 410, Loss: 0.13224547227529984, Accuracy: 0.92605\n",
            "Batch: 420, Loss: 0.13215018498985254, Accuracy: 0.9263833333333333\n",
            "Batch: 430, Loss: 0.1322287658494321, Accuracy: 0.9262666666666667\n",
            "Batch: 440, Loss: 0.13314941139853972, Accuracy: 0.9261166666666667\n",
            "Batch: 450, Loss: 0.13246614770876367, Accuracy: 0.92615\n",
            "Batch: 460, Loss: 0.13258633655801075, Accuracy: 0.926\n",
            "Batch: 470, Loss: 0.13218755557313352, Accuracy: 0.9263666666666667\n",
            "Batch: 480, Loss: 0.13178391040900964, Accuracy: 0.9269333333333334\n",
            "Batch: 490, Loss: 0.1320437846257208, Accuracy: 0.9267\n",
            "Batch: 500, Loss: 0.13221297511443938, Accuracy: 0.9265333333333333\n",
            "Batch: 510, Loss: 0.13223659373634541, Accuracy: 0.9260166666666667\n",
            "Batch: 520, Loss: 0.13218758883177253, Accuracy: 0.9262666666666667\n",
            "Batch: 530, Loss: 0.13218246409102039, Accuracy: 0.92645\n",
            "Batch: 540, Loss: 0.13180533968980399, Accuracy: 0.9265833333333333\n",
            "Batch: 550, Loss: 0.13179726392685198, Accuracy: 0.9264166666666667\n",
            "Batch: 560, Loss: 0.13260131440695463, Accuracy: 0.9257833333333333\n",
            "Batch: 570, Loss: 0.13306264549496957, Accuracy: 0.9254\n",
            "Batch: 580, Loss: 0.13309770883622113, Accuracy: 0.9258\n",
            "Batch: 590, Loss: 0.13234148759476236, Accuracy: 0.9259\n",
            "Batch: 600, Loss: 0.1323232705723659, Accuracy: 0.9258\n",
            "Batch: 610, Loss: 0.13219643912992682, Accuracy: 0.9257333333333333\n",
            "Batch: 620, Loss: 0.13247126785563504, Accuracy: 0.9259166666666667\n",
            "Batch: 630, Loss: 0.1316476174079913, Accuracy: 0.9262833333333333\n",
            "Batch: 640, Loss: 0.131945637099393, Accuracy: 0.9261\n",
            "Batch: 650, Loss: 0.13234281347059054, Accuracy: 0.9262666666666667\n",
            "Batch: 660, Loss: 0.13227128356346987, Accuracy: 0.9261666666666667\n",
            "Batch: 670, Loss: 0.13196844896688228, Accuracy: 0.9262166666666667\n",
            "Batch: 680, Loss: 0.1317348821663705, Accuracy: 0.9264\n",
            "Batch: 690, Loss: 0.13265092091148245, Accuracy: 0.9259\n",
            "Batch: 700, Loss: 0.13249719156918482, Accuracy: 0.9259333333333334\n",
            "Batch: 710, Loss: 0.13309460438027756, Accuracy: 0.9251833333333334\n",
            "Batch: 720, Loss: 0.13234590694692772, Accuracy: 0.9259666666666667\n",
            "Batch: 730, Loss: 0.1329873863524611, Accuracy: 0.9256333333333333\n",
            "Batch: 740, Loss: 0.13293318185233705, Accuracy: 0.9252333333333334\n",
            "Batch: 750, Loss: 0.13381913302795337, Accuracy: 0.9247833333333333\n",
            "Batch: 760, Loss: 0.13306287527211166, Accuracy: 0.9253\n",
            "Batch: 770, Loss: 0.13268398346457153, Accuracy: 0.9256166666666666\n",
            "Batch: 780, Loss: 0.13353406953256383, Accuracy: 0.9249833333333334\n",
            "Batch: 790, Loss: 0.1335085818132246, Accuracy: 0.9251166666666667\n",
            "Batch: 800, Loss: 0.1345352274779965, Accuracy: 0.9244166666666667\n",
            "Batch: 810, Loss: 0.1334294688959346, Accuracy: 0.9250833333333334\n",
            "Batch: 820, Loss: 0.13349131310931453, Accuracy: 0.92505\n",
            "Batch: 830, Loss: 0.13241669391517688, Accuracy: 0.9257\n",
            "Batch: 840, Loss: 0.13205805964234263, Accuracy: 0.9261166666666667\n",
            "Batch: 850, Loss: 0.1325222949965274, Accuracy: 0.9259666666666667\n",
            "Batch: 860, Loss: 0.13366767308150174, Accuracy: 0.9249\n",
            "Batch: 870, Loss: 0.1328780424507371, Accuracy: 0.9253333333333333\n",
            "Batch: 880, Loss: 0.132689685052895, Accuracy: 0.9255666666666666\n",
            "Batch: 890, Loss: 0.1329404659634556, Accuracy: 0.9256\n",
            "Batch: 900, Loss: 0.13308966393581081, Accuracy: 0.92535\n",
            "Batch: 910, Loss: 0.13208719789315176, Accuracy: 0.9261833333333334\n",
            "Batch: 920, Loss: 0.13206780469156873, Accuracy: 0.9261333333333334\n",
            "Batch: 930, Loss: 0.1328393880610697, Accuracy: 0.9253666666666667\n",
            "Epoch: 45, Loss: 0.1329577012760372, Accuracy: 0.9252666666666667\n",
            "Batch: 0, Loss: 0.13300052717492963, Accuracy: 0.9251333333333334\n",
            "Batch: 10, Loss: 0.13420500673168226, Accuracy: 0.9249333333333334\n",
            "Batch: 20, Loss: 0.13250932367265067, Accuracy: 0.9259666666666667\n",
            "Batch: 30, Loss: 0.13207720793436728, Accuracy: 0.9261166666666667\n",
            "Batch: 40, Loss: 0.13153481251976673, Accuracy: 0.9264166666666667\n",
            "Batch: 50, Loss: 0.13178078650710554, Accuracy: 0.9258833333333333\n",
            "Batch: 60, Loss: 0.13162928114538316, Accuracy: 0.9262666666666667\n",
            "Batch: 70, Loss: 0.13129332773323799, Accuracy: 0.9264\n",
            "Batch: 80, Loss: 0.131253651609934, Accuracy: 0.9265666666666666\n",
            "Batch: 90, Loss: 0.1308149161887882, Accuracy: 0.9270166666666667\n",
            "Batch: 100, Loss: 0.13079083160029267, Accuracy: 0.9262666666666667\n",
            "Batch: 110, Loss: 0.1310696434580378, Accuracy: 0.9260166666666667\n",
            "Batch: 120, Loss: 0.1308441061314122, Accuracy: 0.9266\n",
            "Batch: 130, Loss: 0.1321691786094575, Accuracy: 0.9257833333333333\n",
            "Batch: 140, Loss: 0.13319600042135293, Accuracy: 0.9250333333333334\n",
            "Batch: 150, Loss: 0.13188636702052473, Accuracy: 0.9255833333333333\n",
            "Batch: 160, Loss: 0.13156409518744122, Accuracy: 0.9258833333333333\n",
            "Batch: 170, Loss: 0.13049584273282508, Accuracy: 0.9264833333333333\n",
            "Batch: 180, Loss: 0.13118422635598936, Accuracy: 0.9262166666666667\n",
            "Batch: 190, Loss: 0.13198899229757016, Accuracy: 0.9259\n",
            "Batch: 200, Loss: 0.132111635789231, Accuracy: 0.9255333333333333\n",
            "Batch: 210, Loss: 0.1325706464979788, Accuracy: 0.92545\n",
            "Batch: 220, Loss: 0.1330329087587434, Accuracy: 0.9257333333333333\n",
            "Batch: 230, Loss: 0.13302709749324193, Accuracy: 0.9260833333333334\n",
            "Batch: 240, Loss: 0.13358631178415595, Accuracy: 0.92545\n",
            "Batch: 250, Loss: 0.13260465849715686, Accuracy: 0.9264\n",
            "Batch: 260, Loss: 0.1329141804469476, Accuracy: 0.9260666666666667\n",
            "Batch: 270, Loss: 0.13124654898566573, Accuracy: 0.9268666666666666\n",
            "Batch: 280, Loss: 0.1306065212655844, Accuracy: 0.9270833333333334\n",
            "Batch: 290, Loss: 0.13098831719739606, Accuracy: 0.9268666666666666\n",
            "Batch: 300, Loss: 0.1307801306876549, Accuracy: 0.92675\n",
            "Batch: 310, Loss: 0.1309897254165011, Accuracy: 0.9270666666666667\n",
            "Batch: 320, Loss: 0.13083012349397694, Accuracy: 0.9270166666666667\n",
            "Batch: 330, Loss: 0.13069484210633792, Accuracy: 0.9271\n",
            "Batch: 340, Loss: 0.13108520071592458, Accuracy: 0.927\n",
            "Batch: 350, Loss: 0.13090449416421285, Accuracy: 0.9266666666666666\n",
            "Batch: 360, Loss: 0.132571888711596, Accuracy: 0.9256666666666666\n",
            "Batch: 370, Loss: 0.13148848438212424, Accuracy: 0.92605\n",
            "Batch: 380, Loss: 0.1309168989755304, Accuracy: 0.9266666666666666\n",
            "Batch: 390, Loss: 0.1305866820824911, Accuracy: 0.9268666666666666\n",
            "Batch: 400, Loss: 0.1306453780950151, Accuracy: 0.9266333333333333\n",
            "Batch: 410, Loss: 0.13054376162287717, Accuracy: 0.9269\n",
            "Batch: 420, Loss: 0.1304150167921806, Accuracy: 0.9272833333333333\n",
            "Batch: 430, Loss: 0.13044578464451306, Accuracy: 0.9270666666666667\n",
            "Batch: 440, Loss: 0.13137545594442201, Accuracy: 0.9267333333333333\n",
            "Batch: 450, Loss: 0.13067297557376806, Accuracy: 0.9269\n",
            "Batch: 460, Loss: 0.13079764272338862, Accuracy: 0.92695\n",
            "Batch: 470, Loss: 0.13048099541125124, Accuracy: 0.9272833333333333\n",
            "Batch: 480, Loss: 0.13008400446974547, Accuracy: 0.92765\n",
            "Batch: 490, Loss: 0.13038431876664658, Accuracy: 0.9273\n",
            "Batch: 500, Loss: 0.13055900166420917, Accuracy: 0.9271666666666667\n",
            "Batch: 510, Loss: 0.130600146768829, Accuracy: 0.9268166666666666\n",
            "Batch: 520, Loss: 0.1304998148090364, Accuracy: 0.9270333333333334\n",
            "Batch: 530, Loss: 0.1305368402115184, Accuracy: 0.9274333333333333\n",
            "Batch: 540, Loss: 0.13020415677531608, Accuracy: 0.9274333333333333\n",
            "Batch: 550, Loss: 0.13011299758049752, Accuracy: 0.9271333333333334\n",
            "Batch: 560, Loss: 0.13091985137245646, Accuracy: 0.9264666666666667\n",
            "Batch: 570, Loss: 0.13136826627886186, Accuracy: 0.9262833333333333\n",
            "Batch: 580, Loss: 0.13143907081134978, Accuracy: 0.9264166666666667\n",
            "Batch: 590, Loss: 0.13067051962250195, Accuracy: 0.9266833333333333\n",
            "Batch: 600, Loss: 0.1306578888165386, Accuracy: 0.9263833333333333\n",
            "Batch: 610, Loss: 0.1305218947637548, Accuracy: 0.9264\n",
            "Batch: 620, Loss: 0.13083240178425895, Accuracy: 0.9266\n",
            "Batch: 630, Loss: 0.1299334643856305, Accuracy: 0.9268166666666666\n",
            "Batch: 640, Loss: 0.13023800645486783, Accuracy: 0.92695\n",
            "Batch: 650, Loss: 0.13075796471376538, Accuracy: 0.9267166666666666\n",
            "Batch: 660, Loss: 0.13065030726123045, Accuracy: 0.9268\n",
            "Batch: 670, Loss: 0.13035959397725436, Accuracy: 0.9268333333333333\n",
            "Batch: 680, Loss: 0.1300439690940817, Accuracy: 0.927\n",
            "Batch: 690, Loss: 0.13092688981760192, Accuracy: 0.9268\n",
            "Batch: 700, Loss: 0.1307605959540733, Accuracy: 0.9267166666666666\n",
            "Batch: 710, Loss: 0.1313563423880091, Accuracy: 0.9258833333333333\n",
            "Batch: 720, Loss: 0.13062813536664755, Accuracy: 0.92655\n",
            "Batch: 730, Loss: 0.13131128652176194, Accuracy: 0.9262166666666667\n",
            "Batch: 740, Loss: 0.13126295250819228, Accuracy: 0.9260166666666667\n",
            "Batch: 750, Loss: 0.1321455568227499, Accuracy: 0.9255333333333333\n",
            "Batch: 760, Loss: 0.13145393722116672, Accuracy: 0.9259833333333334\n",
            "Batch: 770, Loss: 0.13099480356687912, Accuracy: 0.9264166666666667\n",
            "Batch: 780, Loss: 0.13186537023994835, Accuracy: 0.9259\n",
            "Batch: 790, Loss: 0.13190092794469657, Accuracy: 0.92595\n",
            "Batch: 800, Loss: 0.13290582416993796, Accuracy: 0.9252\n",
            "Batch: 810, Loss: 0.13178363697205922, Accuracy: 0.9257\n",
            "Batch: 820, Loss: 0.13191222529280316, Accuracy: 0.9256666666666666\n",
            "Batch: 830, Loss: 0.1308248128868415, Accuracy: 0.9263833333333333\n",
            "Batch: 840, Loss: 0.13044793802661986, Accuracy: 0.9265166666666667\n",
            "Batch: 850, Loss: 0.13097840320242163, Accuracy: 0.92665\n",
            "Batch: 860, Loss: 0.1320908889518108, Accuracy: 0.9253666666666667\n",
            "Batch: 870, Loss: 0.1313100469931241, Accuracy: 0.9257166666666666\n",
            "Batch: 880, Loss: 0.13107641576919854, Accuracy: 0.9262666666666667\n",
            "Batch: 890, Loss: 0.13130008279448693, Accuracy: 0.9264666666666667\n",
            "Batch: 900, Loss: 0.1314718346497938, Accuracy: 0.92605\n",
            "Batch: 910, Loss: 0.1304921445925713, Accuracy: 0.9268833333333333\n",
            "Batch: 920, Loss: 0.1304170905743263, Accuracy: 0.9268166666666666\n",
            "Batch: 930, Loss: 0.13121752757202587, Accuracy: 0.9262333333333334\n",
            "Epoch: 46, Loss: 0.13135043963762003, Accuracy: 0.9260333333333334\n",
            "Batch: 0, Loss: 0.13142296959477057, Accuracy: 0.9258333333333333\n",
            "Batch: 10, Loss: 0.13268180953211037, Accuracy: 0.9256333333333333\n",
            "Batch: 20, Loss: 0.13089377708780756, Accuracy: 0.9267833333333333\n",
            "Batch: 30, Loss: 0.13040972000639006, Accuracy: 0.9268\n",
            "Batch: 40, Loss: 0.1298790276803443, Accuracy: 0.9271666666666667\n",
            "Batch: 50, Loss: 0.13008343033515266, Accuracy: 0.9266166666666666\n",
            "Batch: 60, Loss: 0.12995122547241306, Accuracy: 0.9269666666666667\n",
            "Batch: 70, Loss: 0.12965039590948021, Accuracy: 0.9271333333333334\n",
            "Batch: 80, Loss: 0.12961766726201082, Accuracy: 0.9273833333333333\n",
            "Batch: 90, Loss: 0.1291793004277114, Accuracy: 0.9276\n",
            "Batch: 100, Loss: 0.12916720463936873, Accuracy: 0.9269\n",
            "Batch: 110, Loss: 0.1294347430188714, Accuracy: 0.9268\n",
            "Batch: 120, Loss: 0.12917751918345174, Accuracy: 0.9273333333333333\n",
            "Batch: 130, Loss: 0.13053131105542093, Accuracy: 0.9263833333333333\n",
            "Batch: 140, Loss: 0.13151488488918547, Accuracy: 0.9258833333333333\n",
            "Batch: 150, Loss: 0.13024153484023954, Accuracy: 0.9264833333333333\n",
            "Batch: 160, Loss: 0.1298377159713369, Accuracy: 0.9265333333333333\n",
            "Batch: 170, Loss: 0.12880086662174994, Accuracy: 0.92735\n",
            "Batch: 180, Loss: 0.12952880385946133, Accuracy: 0.92665\n",
            "Batch: 190, Loss: 0.13029039816829097, Accuracy: 0.9268333333333333\n",
            "Batch: 200, Loss: 0.13036774990306896, Accuracy: 0.9262666666666667\n",
            "Batch: 210, Loss: 0.13081073094115045, Accuracy: 0.9261333333333334\n",
            "Batch: 220, Loss: 0.13126294187532225, Accuracy: 0.92635\n",
            "Batch: 230, Loss: 0.1313482456067523, Accuracy: 0.9266666666666666\n",
            "Batch: 240, Loss: 0.13193766621833564, Accuracy: 0.9263\n",
            "Batch: 250, Loss: 0.13095931435545777, Accuracy: 0.9270333333333334\n",
            "Batch: 260, Loss: 0.13122893190181004, Accuracy: 0.92675\n",
            "Batch: 270, Loss: 0.12960533705932262, Accuracy: 0.92755\n",
            "Batch: 280, Loss: 0.12898640277029438, Accuracy: 0.9276833333333333\n",
            "Batch: 290, Loss: 0.12933529479733238, Accuracy: 0.9275\n",
            "Batch: 300, Loss: 0.1291317902132354, Accuracy: 0.9274166666666667\n",
            "Batch: 310, Loss: 0.12931098207957853, Accuracy: 0.92775\n",
            "Batch: 320, Loss: 0.12909559516677016, Accuracy: 0.9276166666666666\n",
            "Batch: 330, Loss: 0.128963007501593, Accuracy: 0.92765\n",
            "Batch: 340, Loss: 0.12934277236312636, Accuracy: 0.9277166666666666\n",
            "Batch: 350, Loss: 0.12918601547761843, Accuracy: 0.9273166666666667\n",
            "Batch: 360, Loss: 0.13086543332099645, Accuracy: 0.9263333333333333\n",
            "Batch: 370, Loss: 0.12985336391114052, Accuracy: 0.9268166666666666\n",
            "Batch: 380, Loss: 0.12930067100391687, Accuracy: 0.9272666666666667\n",
            "Batch: 390, Loss: 0.12894508269425162, Accuracy: 0.9275833333333333\n",
            "Batch: 400, Loss: 0.12894977141692482, Accuracy: 0.9272333333333334\n",
            "Batch: 410, Loss: 0.1288772881990412, Accuracy: 0.9275666666666667\n",
            "Batch: 420, Loss: 0.12876414498589758, Accuracy: 0.928\n",
            "Batch: 430, Loss: 0.12873807372303483, Accuracy: 0.9279833333333334\n",
            "Batch: 440, Loss: 0.12965250045569063, Accuracy: 0.9273\n",
            "Batch: 450, Loss: 0.12892471339593659, Accuracy: 0.9276\n",
            "Batch: 460, Loss: 0.12905622988970486, Accuracy: 0.9277833333333333\n",
            "Batch: 470, Loss: 0.1288367772645134, Accuracy: 0.9280833333333334\n",
            "Batch: 480, Loss: 0.1284300219103815, Accuracy: 0.9280833333333334\n",
            "Batch: 490, Loss: 0.1287574777528493, Accuracy: 0.92795\n",
            "Batch: 500, Loss: 0.1289167716037346, Accuracy: 0.9278\n",
            "Batch: 510, Loss: 0.12897626157546443, Accuracy: 0.9273333333333333\n",
            "Batch: 520, Loss: 0.12885437036507916, Accuracy: 0.92785\n",
            "Batch: 530, Loss: 0.1289282518914887, Accuracy: 0.9280333333333334\n",
            "Batch: 540, Loss: 0.12865201814744, Accuracy: 0.9281333333333334\n",
            "Batch: 550, Loss: 0.12847692176155265, Accuracy: 0.9279833333333334\n",
            "Batch: 560, Loss: 0.1293022515223852, Accuracy: 0.9272\n",
            "Batch: 570, Loss: 0.1297465937404118, Accuracy: 0.9269333333333334\n",
            "Batch: 580, Loss: 0.1298499855393105, Accuracy: 0.9272\n",
            "Batch: 590, Loss: 0.12904943980345818, Accuracy: 0.9273166666666667\n",
            "Batch: 600, Loss: 0.12902460583063582, Accuracy: 0.92725\n",
            "Batch: 610, Loss: 0.1288754467309933, Accuracy: 0.9273833333333333\n",
            "Batch: 620, Loss: 0.12921130564391034, Accuracy: 0.9273666666666667\n",
            "Batch: 630, Loss: 0.12826712294935508, Accuracy: 0.9276333333333333\n",
            "Batch: 640, Loss: 0.12856834237942563, Accuracy: 0.9278\n",
            "Batch: 650, Loss: 0.12916776437887048, Accuracy: 0.9274333333333333\n",
            "Batch: 660, Loss: 0.12906019197121557, Accuracy: 0.92755\n",
            "Batch: 670, Loss: 0.12876817861062156, Accuracy: 0.92745\n",
            "Batch: 680, Loss: 0.12838321925512425, Accuracy: 0.9275166666666667\n",
            "Batch: 690, Loss: 0.1292432960200724, Accuracy: 0.9275666666666667\n",
            "Batch: 700, Loss: 0.12907287321652058, Accuracy: 0.9273666666666667\n",
            "Batch: 710, Loss: 0.12966579810162984, Accuracy: 0.9265666666666666\n",
            "Batch: 720, Loss: 0.12894554913457282, Accuracy: 0.9272166666666667\n",
            "Batch: 730, Loss: 0.12966564062167543, Accuracy: 0.9268833333333333\n",
            "Batch: 740, Loss: 0.12964266766027283, Accuracy: 0.9269333333333334\n",
            "Batch: 750, Loss: 0.13050383057678025, Accuracy: 0.9264\n",
            "Batch: 760, Loss: 0.12989755572404996, Accuracy: 0.9265833333333333\n",
            "Batch: 770, Loss: 0.12935885562660576, Accuracy: 0.9270833333333334\n",
            "Batch: 780, Loss: 0.1302685452648759, Accuracy: 0.9266333333333333\n",
            "Batch: 790, Loss: 0.13034365996390312, Accuracy: 0.9267166666666666\n",
            "Batch: 800, Loss: 0.13130859505440345, Accuracy: 0.9258833333333333\n",
            "Batch: 810, Loss: 0.13020996235550003, Accuracy: 0.92665\n",
            "Batch: 820, Loss: 0.13036539110555664, Accuracy: 0.9262833333333333\n",
            "Batch: 830, Loss: 0.12929845365997672, Accuracy: 0.9269833333333334\n",
            "Batch: 840, Loss: 0.12888821166462053, Accuracy: 0.9273333333333333\n",
            "Batch: 850, Loss: 0.12941749080427165, Accuracy: 0.9273333333333333\n",
            "Batch: 860, Loss: 0.13052976026213264, Accuracy: 0.92595\n",
            "Batch: 870, Loss: 0.12980071086057154, Accuracy: 0.9265333333333333\n",
            "Batch: 880, Loss: 0.12951911878291467, Accuracy: 0.9270333333333334\n",
            "Batch: 890, Loss: 0.12969006461173122, Accuracy: 0.927\n",
            "Batch: 900, Loss: 0.12986192970279414, Accuracy: 0.9267\n",
            "Batch: 910, Loss: 0.12892540878717731, Accuracy: 0.9274\n",
            "Batch: 920, Loss: 0.12880432305142128, Accuracy: 0.9275666666666667\n",
            "Batch: 930, Loss: 0.12962433439218113, Accuracy: 0.92675\n",
            "Epoch: 47, Loss: 0.12978684415004976, Accuracy: 0.9266333333333333\n",
            "Batch: 0, Loss: 0.12987090013368696, Accuracy: 0.9265833333333333\n",
            "Batch: 10, Loss: 0.1311592141794041, Accuracy: 0.9263833333333333\n",
            "Batch: 20, Loss: 0.12929935821535202, Accuracy: 0.9273833333333333\n",
            "Batch: 30, Loss: 0.1287769934257716, Accuracy: 0.9273666666666667\n",
            "Batch: 40, Loss: 0.12825967003907512, Accuracy: 0.9280166666666667\n",
            "Batch: 50, Loss: 0.1284600208331665, Accuracy: 0.9275\n",
            "Batch: 60, Loss: 0.12832135763429478, Accuracy: 0.9276\n",
            "Batch: 70, Loss: 0.12803154553022228, Accuracy: 0.9279833333333334\n",
            "Batch: 80, Loss: 0.12800452654512431, Accuracy: 0.9281333333333334\n",
            "Batch: 90, Loss: 0.12756262665620546, Accuracy: 0.9282833333333333\n",
            "Batch: 100, Loss: 0.12757296432976287, Accuracy: 0.92735\n",
            "Batch: 110, Loss: 0.12784937038354258, Accuracy: 0.9276666666666666\n",
            "Batch: 120, Loss: 0.12756705122510487, Accuracy: 0.9282833333333333\n",
            "Batch: 130, Loss: 0.1289590905960001, Accuracy: 0.9273166666666667\n",
            "Batch: 140, Loss: 0.12987557591137744, Accuracy: 0.9264333333333333\n",
            "Batch: 150, Loss: 0.12862655277705504, Accuracy: 0.9270333333333334\n",
            "Batch: 160, Loss: 0.1281603209228464, Accuracy: 0.92725\n",
            "Batch: 170, Loss: 0.12714632001953713, Accuracy: 0.9281\n",
            "Batch: 180, Loss: 0.12785133164683296, Accuracy: 0.9273833333333333\n",
            "Batch: 190, Loss: 0.12862914642846474, Accuracy: 0.92755\n",
            "Batch: 200, Loss: 0.12872019293374734, Accuracy: 0.9271666666666667\n",
            "Batch: 210, Loss: 0.12909676898850048, Accuracy: 0.9269\n",
            "Batch: 220, Loss: 0.12954552548566026, Accuracy: 0.9271\n",
            "Batch: 230, Loss: 0.12969847997721046, Accuracy: 0.9273833333333333\n",
            "Batch: 240, Loss: 0.13025775505351422, Accuracy: 0.9269\n",
            "Batch: 250, Loss: 0.12931819670971184, Accuracy: 0.9276\n",
            "Batch: 260, Loss: 0.1294911830130032, Accuracy: 0.9273166666666667\n",
            "Batch: 270, Loss: 0.12795071096671398, Accuracy: 0.9281333333333334\n",
            "Batch: 280, Loss: 0.12739328926914564, Accuracy: 0.9282666666666667\n",
            "Batch: 290, Loss: 0.1277308190054984, Accuracy: 0.9280666666666667\n",
            "Batch: 300, Loss: 0.1275342350921314, Accuracy: 0.9278833333333333\n",
            "Batch: 310, Loss: 0.1276728727111388, Accuracy: 0.9283\n",
            "Batch: 320, Loss: 0.1274237069127766, Accuracy: 0.9281333333333334\n",
            "Batch: 330, Loss: 0.12729624727989758, Accuracy: 0.9281833333333334\n",
            "Batch: 340, Loss: 0.12766968445275523, Accuracy: 0.9282\n",
            "Batch: 350, Loss: 0.12753343198247813, Accuracy: 0.9278166666666666\n",
            "Batch: 360, Loss: 0.1292185603704245, Accuracy: 0.927\n",
            "Batch: 370, Loss: 0.1282957488881558, Accuracy: 0.9273666666666667\n",
            "Batch: 380, Loss: 0.12774404137350798, Accuracy: 0.9278833333333333\n",
            "Batch: 390, Loss: 0.12735838989872758, Accuracy: 0.9283\n",
            "Batch: 400, Loss: 0.1273161570222843, Accuracy: 0.9279166666666666\n",
            "Batch: 410, Loss: 0.12724240792563615, Accuracy: 0.9283833333333333\n",
            "Batch: 420, Loss: 0.12716355359057382, Accuracy: 0.9286833333333333\n",
            "Batch: 430, Loss: 0.12710933561670174, Accuracy: 0.9287\n",
            "Batch: 440, Loss: 0.12799718385125933, Accuracy: 0.9279666666666667\n",
            "Batch: 450, Loss: 0.12725556556127013, Accuracy: 0.9283166666666667\n",
            "Batch: 460, Loss: 0.12736413094920598, Accuracy: 0.92855\n",
            "Batch: 470, Loss: 0.1272427006993945, Accuracy: 0.9286833333333333\n",
            "Batch: 480, Loss: 0.12683718429452973, Accuracy: 0.9287833333333333\n",
            "Batch: 490, Loss: 0.12717584837007506, Accuracy: 0.9286\n",
            "Batch: 500, Loss: 0.12730019913314738, Accuracy: 0.92845\n",
            "Batch: 510, Loss: 0.12735395746963563, Accuracy: 0.9280166666666667\n",
            "Batch: 520, Loss: 0.12723944382566577, Accuracy: 0.9284166666666667\n",
            "Batch: 530, Loss: 0.12733154267534635, Accuracy: 0.9286833333333333\n",
            "Batch: 540, Loss: 0.1271237581714704, Accuracy: 0.9289666666666667\n",
            "Batch: 550, Loss: 0.12686592718527187, Accuracy: 0.92865\n",
            "Batch: 560, Loss: 0.12771035865007768, Accuracy: 0.9280333333333334\n",
            "Batch: 570, Loss: 0.128155611015284, Accuracy: 0.9275666666666667\n",
            "Batch: 580, Loss: 0.1282945144169704, Accuracy: 0.9276333333333333\n",
            "Batch: 590, Loss: 0.12746611510875702, Accuracy: 0.9278833333333333\n",
            "Batch: 600, Loss: 0.12741401774660485, Accuracy: 0.9278833333333333\n",
            "Batch: 610, Loss: 0.1272637041794803, Accuracy: 0.9282\n",
            "Batch: 620, Loss: 0.1276071060284255, Accuracy: 0.9279\n",
            "Batch: 630, Loss: 0.12663909656492672, Accuracy: 0.92835\n",
            "Batch: 640, Loss: 0.12692997483472487, Accuracy: 0.9284666666666667\n",
            "Batch: 650, Loss: 0.12756963791871517, Accuracy: 0.9280666666666667\n",
            "Batch: 660, Loss: 0.1274936348751906, Accuracy: 0.92805\n",
            "Batch: 670, Loss: 0.12718728282497568, Accuracy: 0.9282333333333334\n",
            "Batch: 680, Loss: 0.12674438423312293, Accuracy: 0.9281666666666667\n",
            "Batch: 690, Loss: 0.12760457712293954, Accuracy: 0.9282833333333333\n",
            "Batch: 700, Loss: 0.1274398977967089, Accuracy: 0.9280666666666667\n",
            "Batch: 710, Loss: 0.1280334892921285, Accuracy: 0.9274833333333333\n",
            "Batch: 720, Loss: 0.1273252728600002, Accuracy: 0.928\n",
            "Batch: 730, Loss: 0.1280661617762347, Accuracy: 0.9274333333333333\n",
            "Batch: 740, Loss: 0.1280799305465195, Accuracy: 0.9276166666666666\n",
            "Batch: 750, Loss: 0.12890146752362008, Accuracy: 0.9270833333333334\n",
            "Batch: 760, Loss: 0.1284080580208997, Accuracy: 0.9270333333333334\n",
            "Batch: 770, Loss: 0.1277813693527649, Accuracy: 0.92785\n",
            "Batch: 780, Loss: 0.1287198743304849, Accuracy: 0.9273\n",
            "Batch: 790, Loss: 0.12879322241013927, Accuracy: 0.9274666666666667\n",
            "Batch: 800, Loss: 0.12970920003278458, Accuracy: 0.9267833333333333\n",
            "Batch: 810, Loss: 0.12863786919862408, Accuracy: 0.9274\n",
            "Batch: 820, Loss: 0.12880334559857332, Accuracy: 0.92695\n",
            "Batch: 830, Loss: 0.12778927745406263, Accuracy: 0.9276333333333333\n",
            "Batch: 840, Loss: 0.12735648721518317, Accuracy: 0.928\n",
            "Batch: 850, Loss: 0.12787775662080078, Accuracy: 0.9280833333333334\n",
            "Batch: 860, Loss: 0.12898777716588955, Accuracy: 0.92665\n",
            "Batch: 870, Loss: 0.12831732536260404, Accuracy: 0.9270166666666667\n",
            "Batch: 880, Loss: 0.1279814893184391, Accuracy: 0.9277\n",
            "Batch: 890, Loss: 0.12807135493849833, Accuracy: 0.92775\n",
            "Batch: 900, Loss: 0.1282490233619188, Accuracy: 0.9274\n",
            "Batch: 910, Loss: 0.12738083590959978, Accuracy: 0.9279166666666666\n",
            "Batch: 920, Loss: 0.1272342671638281, Accuracy: 0.92805\n",
            "Batch: 930, Loss: 0.1280605920503278, Accuracy: 0.9274333333333333\n",
            "Epoch: 48, Loss: 0.12825809807971997, Accuracy: 0.9273\n",
            "Batch: 0, Loss: 0.12834585641368146, Accuracy: 0.9273166666666667\n",
            "Batch: 10, Loss: 0.12964446007211794, Accuracy: 0.92685\n",
            "Batch: 20, Loss: 0.12774804295009212, Accuracy: 0.9281666666666667\n",
            "Batch: 30, Loss: 0.12721550249925964, Accuracy: 0.9279\n",
            "Batch: 40, Loss: 0.1267135915372879, Accuracy: 0.9287\n",
            "Batch: 50, Loss: 0.12693583206844083, Accuracy: 0.9281333333333334\n",
            "Batch: 60, Loss: 0.12679335620373994, Accuracy: 0.9281333333333334\n",
            "Batch: 70, Loss: 0.12646873160476857, Accuracy: 0.9285833333333333\n",
            "Batch: 80, Loss: 0.12640174656827938, Accuracy: 0.9284333333333333\n",
            "Batch: 90, Loss: 0.1259458226369054, Accuracy: 0.9287333333333333\n",
            "Batch: 100, Loss: 0.12599200237331698, Accuracy: 0.92835\n",
            "Batch: 110, Loss: 0.12627164347845446, Accuracy: 0.9283833333333333\n",
            "Batch: 120, Loss: 0.12595992850607723, Accuracy: 0.9289\n",
            "Batch: 130, Loss: 0.12737278875376262, Accuracy: 0.9280166666666667\n",
            "Batch: 140, Loss: 0.12823896506506774, Accuracy: 0.9274333333333333\n",
            "Batch: 150, Loss: 0.12702352821507643, Accuracy: 0.9277\n",
            "Batch: 160, Loss: 0.1265299858338979, Accuracy: 0.9279\n",
            "Batch: 170, Loss: 0.12553488201096544, Accuracy: 0.9288833333333333\n",
            "Batch: 180, Loss: 0.12615922765386003, Accuracy: 0.9281333333333334\n",
            "Batch: 190, Loss: 0.12699539715501237, Accuracy: 0.9282333333333334\n",
            "Batch: 200, Loss: 0.1271264689176962, Accuracy: 0.92785\n",
            "Batch: 210, Loss: 0.12746460524101033, Accuracy: 0.9275666666666667\n",
            "Batch: 220, Loss: 0.12788921458131736, Accuracy: 0.9277166666666666\n",
            "Batch: 230, Loss: 0.1280820701165454, Accuracy: 0.9279\n",
            "Batch: 240, Loss: 0.12858655894452542, Accuracy: 0.9275833333333333\n",
            "Batch: 250, Loss: 0.1276871699601155, Accuracy: 0.9281833333333334\n",
            "Batch: 260, Loss: 0.12774453319585508, Accuracy: 0.92805\n",
            "Batch: 270, Loss: 0.12628626220023684, Accuracy: 0.9285833333333333\n",
            "Batch: 280, Loss: 0.1257921845966858, Accuracy: 0.92865\n",
            "Batch: 290, Loss: 0.1261415965848172, Accuracy: 0.9285666666666667\n",
            "Batch: 300, Loss: 0.12596209080487666, Accuracy: 0.9283\n",
            "Batch: 310, Loss: 0.1260953765186119, Accuracy: 0.9288166666666666\n",
            "Batch: 320, Loss: 0.12580540171153076, Accuracy: 0.92875\n",
            "Batch: 330, Loss: 0.1256746024029187, Accuracy: 0.92875\n",
            "Batch: 340, Loss: 0.12604592265618794, Accuracy: 0.9287\n",
            "Batch: 350, Loss: 0.12591867355743805, Accuracy: 0.9285833333333333\n",
            "Batch: 360, Loss: 0.12759230475342762, Accuracy: 0.9278833333333333\n",
            "Batch: 370, Loss: 0.12676979021807389, Accuracy: 0.9280666666666667\n",
            "Batch: 380, Loss: 0.1262090116029794, Accuracy: 0.9283833333333333\n",
            "Batch: 390, Loss: 0.12579919947474286, Accuracy: 0.9288666666666666\n",
            "Batch: 400, Loss: 0.12573785063955267, Accuracy: 0.9286666666666666\n",
            "Batch: 410, Loss: 0.1256410753353234, Accuracy: 0.9290333333333334\n",
            "Batch: 420, Loss: 0.12557506670400134, Accuracy: 0.9291\n",
            "Batch: 430, Loss: 0.12550281638512142, Accuracy: 0.9294833333333333\n",
            "Batch: 440, Loss: 0.12636220489631791, Accuracy: 0.92865\n",
            "Batch: 450, Loss: 0.12559862898524635, Accuracy: 0.92895\n",
            "Batch: 460, Loss: 0.12568161274796935, Accuracy: 0.92915\n",
            "Batch: 470, Loss: 0.12564805011921687, Accuracy: 0.92945\n",
            "Batch: 480, Loss: 0.12526940996696814, Accuracy: 0.9294\n",
            "Batch: 490, Loss: 0.12562437000577378, Accuracy: 0.9291833333333334\n",
            "Batch: 500, Loss: 0.12571764072150088, Accuracy: 0.9289333333333334\n",
            "Batch: 510, Loss: 0.12571542966723823, Accuracy: 0.92875\n",
            "Batch: 520, Loss: 0.1256480861192321, Accuracy: 0.9290333333333334\n",
            "Batch: 530, Loss: 0.12575493911606933, Accuracy: 0.9292166666666667\n",
            "Batch: 540, Loss: 0.12562461729388974, Accuracy: 0.9293666666666667\n",
            "Batch: 550, Loss: 0.12526554320645697, Accuracy: 0.9293333333333333\n",
            "Batch: 560, Loss: 0.12612159131233996, Accuracy: 0.9284166666666667\n",
            "Batch: 570, Loss: 0.12654966029508816, Accuracy: 0.9279166666666666\n",
            "Batch: 580, Loss: 0.1267542154670882, Accuracy: 0.9285166666666667\n",
            "Batch: 590, Loss: 0.12592917495722727, Accuracy: 0.9285333333333333\n",
            "Batch: 600, Loss: 0.12583745969550356, Accuracy: 0.9285\n",
            "Batch: 610, Loss: 0.12569646972080026, Accuracy: 0.9286833333333333\n",
            "Batch: 620, Loss: 0.12603413047887235, Accuracy: 0.9286333333333333\n",
            "Batch: 630, Loss: 0.12503587090668491, Accuracy: 0.9290666666666667\n",
            "Batch: 640, Loss: 0.12531516017514244, Accuracy: 0.9293166666666667\n",
            "Batch: 650, Loss: 0.12595781900391045, Accuracy: 0.9286833333333333\n",
            "Batch: 660, Loss: 0.12593612355928194, Accuracy: 0.9286\n",
            "Batch: 670, Loss: 0.1255890510068783, Accuracy: 0.9286\n",
            "Batch: 680, Loss: 0.12512452562704912, Accuracy: 0.9291333333333334\n",
            "Batch: 690, Loss: 0.12599872302898946, Accuracy: 0.92895\n",
            "Batch: 700, Loss: 0.1258413320112436, Accuracy: 0.9287\n",
            "Batch: 710, Loss: 0.12647267093071146, Accuracy: 0.9281666666666667\n",
            "Batch: 720, Loss: 0.1257586382183258, Accuracy: 0.9285666666666667\n",
            "Batch: 730, Loss: 0.12650516829756067, Accuracy: 0.9281833333333334\n",
            "Batch: 740, Loss: 0.12655451175324559, Accuracy: 0.9282166666666667\n",
            "Batch: 750, Loss: 0.12730693903028414, Accuracy: 0.9278166666666666\n",
            "Batch: 760, Loss: 0.12689432686544447, Accuracy: 0.9279666666666667\n",
            "Batch: 770, Loss: 0.126251128591848, Accuracy: 0.9285333333333333\n",
            "Batch: 780, Loss: 0.12719171461716558, Accuracy: 0.9279\n",
            "Batch: 790, Loss: 0.12722829017601922, Accuracy: 0.9281666666666667\n",
            "Batch: 800, Loss: 0.1281040844500306, Accuracy: 0.9273666666666667\n",
            "Batch: 810, Loss: 0.12706745395013103, Accuracy: 0.9280833333333334\n",
            "Batch: 820, Loss: 0.12723616195110077, Accuracy: 0.9278166666666666\n",
            "Batch: 830, Loss: 0.12627596485938153, Accuracy: 0.92815\n",
            "Batch: 840, Loss: 0.12583919025478396, Accuracy: 0.9285833333333333\n",
            "Batch: 850, Loss: 0.1263458324919429, Accuracy: 0.9286833333333333\n",
            "Batch: 860, Loss: 0.12746882014901875, Accuracy: 0.9273333333333333\n",
            "Batch: 870, Loss: 0.1268620857290731, Accuracy: 0.9276166666666666\n",
            "Batch: 880, Loss: 0.12649611349309617, Accuracy: 0.9283166666666667\n",
            "Batch: 890, Loss: 0.1265516020823226, Accuracy: 0.9283166666666667\n",
            "Batch: 900, Loss: 0.12670917574902638, Accuracy: 0.9282166666666667\n",
            "Batch: 910, Loss: 0.12587793098211297, Accuracy: 0.9287333333333333\n",
            "Batch: 920, Loss: 0.1257101280623911, Accuracy: 0.9287666666666666\n",
            "Batch: 930, Loss: 0.12652911653462842, Accuracy: 0.9282666666666667\n",
            "Epoch: 49, Loss: 0.12675511039400697, Accuracy: 0.92805\n",
            "Batch: 0, Loss: 0.12684228693693958, Accuracy: 0.92805\n",
            "Batch: 10, Loss: 0.1281379795818134, Accuracy: 0.9276333333333333\n",
            "Batch: 20, Loss: 0.12622271292874088, Accuracy: 0.9288\n",
            "Batch: 30, Loss: 0.12570857441562067, Accuracy: 0.9287333333333333\n",
            "Batch: 40, Loss: 0.125214245728902, Accuracy: 0.9292\n",
            "Batch: 50, Loss: 0.1254426100198834, Accuracy: 0.9288166666666666\n",
            "Batch: 60, Loss: 0.12531782374032602, Accuracy: 0.9289333333333334\n",
            "Batch: 70, Loss: 0.12493576147049547, Accuracy: 0.9290166666666667\n",
            "Batch: 80, Loss: 0.12481534495456909, Accuracy: 0.9292\n",
            "Batch: 90, Loss: 0.12434593943408986, Accuracy: 0.9293\n",
            "Batch: 100, Loss: 0.12442730097790178, Accuracy: 0.9291\n",
            "Batch: 110, Loss: 0.12469859756312202, Accuracy: 0.9288833333333333\n",
            "Batch: 120, Loss: 0.12435987472007863, Accuracy: 0.9294833333333333\n",
            "Batch: 130, Loss: 0.1257530443291007, Accuracy: 0.92865\n",
            "Batch: 140, Loss: 0.1266053442437374, Accuracy: 0.9280166666666667\n",
            "Batch: 150, Loss: 0.125424649110687, Accuracy: 0.9283833333333333\n",
            "Batch: 160, Loss: 0.12496497391549281, Accuracy: 0.9286\n",
            "Batch: 170, Loss: 0.12397801350441327, Accuracy: 0.9296166666666666\n",
            "Batch: 180, Loss: 0.12451912537892273, Accuracy: 0.9287333333333333\n",
            "Batch: 190, Loss: 0.12538888262855752, Accuracy: 0.9288\n",
            "Batch: 200, Loss: 0.1255237720915235, Accuracy: 0.9284666666666667\n",
            "Batch: 210, Loss: 0.1258492238676747, Accuracy: 0.9283333333333333\n",
            "Batch: 220, Loss: 0.12624624871655135, Accuracy: 0.9285833333333333\n",
            "Batch: 230, Loss: 0.12645661273578934, Accuracy: 0.92835\n",
            "Batch: 240, Loss: 0.12695009777135452, Accuracy: 0.9281833333333334\n",
            "Batch: 250, Loss: 0.12608825296345783, Accuracy: 0.9288\n",
            "Batch: 260, Loss: 0.12606078472363996, Accuracy: 0.9285333333333333\n",
            "Batch: 270, Loss: 0.12465836154937653, Accuracy: 0.9292833333333334\n",
            "Batch: 280, Loss: 0.12419381607063013, Accuracy: 0.92935\n",
            "Batch: 290, Loss: 0.1245504641670927, Accuracy: 0.9292166666666667\n",
            "Batch: 300, Loss: 0.12442355729973366, Accuracy: 0.9289833333333334\n",
            "Batch: 310, Loss: 0.1245935459363038, Accuracy: 0.9295333333333333\n",
            "Batch: 320, Loss: 0.12423960264111068, Accuracy: 0.9294333333333333\n",
            "Batch: 330, Loss: 0.12410376872837361, Accuracy: 0.9293666666666667\n",
            "Batch: 340, Loss: 0.12447642517151095, Accuracy: 0.9293\n",
            "Batch: 350, Loss: 0.12436610628279858, Accuracy: 0.9292166666666667\n",
            "Batch: 360, Loss: 0.12600066363034754, Accuracy: 0.92845\n",
            "Batch: 370, Loss: 0.1252732858687405, Accuracy: 0.9287166666666666\n",
            "Batch: 380, Loss: 0.1247006421875025, Accuracy: 0.9289666666666667\n",
            "Batch: 390, Loss: 0.12427107360376201, Accuracy: 0.9293833333333333\n",
            "Batch: 400, Loss: 0.12418482581164363, Accuracy: 0.92915\n",
            "Batch: 410, Loss: 0.12406430468744, Accuracy: 0.9295666666666667\n",
            "Batch: 420, Loss: 0.12401000222792262, Accuracy: 0.9296\n",
            "Batch: 430, Loss: 0.12391366630965589, Accuracy: 0.93025\n",
            "Batch: 440, Loss: 0.12475261743670293, Accuracy: 0.9295\n",
            "Batch: 450, Loss: 0.12396826195795713, Accuracy: 0.9297666666666666\n",
            "Batch: 460, Loss: 0.12401622027329198, Accuracy: 0.9301666666666667\n",
            "Batch: 470, Loss: 0.12404564676269379, Accuracy: 0.93005\n",
            "Batch: 480, Loss: 0.12370029496963532, Accuracy: 0.93\n",
            "Batch: 490, Loss: 0.12409706602728628, Accuracy: 0.92965\n",
            "Batch: 500, Loss: 0.12417613467351711, Accuracy: 0.92945\n",
            "Batch: 510, Loss: 0.12409782472224683, Accuracy: 0.9293333333333333\n",
            "Batch: 520, Loss: 0.1240907946914828, Accuracy: 0.9295333333333333\n",
            "Batch: 530, Loss: 0.12420710636531915, Accuracy: 0.9297166666666666\n",
            "Batch: 540, Loss: 0.12413914338915706, Accuracy: 0.92985\n",
            "Batch: 550, Loss: 0.1236898913260403, Accuracy: 0.9299666666666667\n",
            "Batch: 560, Loss: 0.12455063275661021, Accuracy: 0.9291333333333334\n",
            "Batch: 570, Loss: 0.12493883628077088, Accuracy: 0.9285333333333333\n",
            "Batch: 580, Loss: 0.12522700715293225, Accuracy: 0.9291333333333334\n",
            "Batch: 590, Loss: 0.12442540211390248, Accuracy: 0.9292166666666667\n",
            "Batch: 600, Loss: 0.1243053754657723, Accuracy: 0.9292333333333334\n",
            "Batch: 610, Loss: 0.12417362877710904, Accuracy: 0.9294666666666667\n",
            "Batch: 620, Loss: 0.1245038155163574, Accuracy: 0.9292333333333334\n",
            "Batch: 630, Loss: 0.12346244123236176, Accuracy: 0.9297666666666666\n",
            "Batch: 640, Loss: 0.123722904295589, Accuracy: 0.9296333333333333\n",
            "Batch: 650, Loss: 0.12436603818388639, Accuracy: 0.92925\n",
            "Batch: 660, Loss: 0.12438953552940167, Accuracy: 0.9288833333333333\n",
            "Batch: 670, Loss: 0.12396478358027921, Accuracy: 0.92925\n",
            "Batch: 680, Loss: 0.12352375119223187, Accuracy: 0.9298166666666666\n",
            "Batch: 690, Loss: 0.12440282649883205, Accuracy: 0.9294833333333333\n",
            "Batch: 700, Loss: 0.12426148461004316, Accuracy: 0.9294\n",
            "Batch: 710, Loss: 0.12494901015574636, Accuracy: 0.9286\n",
            "Batch: 720, Loss: 0.12421465306781336, Accuracy: 0.9295\n",
            "Batch: 730, Loss: 0.12496375073573505, Accuracy: 0.9289\n",
            "Batch: 740, Loss: 0.1250425428934286, Accuracy: 0.9288\n",
            "Batch: 750, Loss: 0.1257246861976899, Accuracy: 0.9283666666666667\n",
            "Batch: 760, Loss: 0.12535224616329216, Accuracy: 0.9287333333333333\n",
            "Batch: 770, Loss: 0.12475392536310552, Accuracy: 0.9289666666666667\n",
            "Batch: 780, Loss: 0.12568213859222258, Accuracy: 0.9285666666666667\n",
            "Batch: 790, Loss: 0.12566513064911178, Accuracy: 0.92885\n",
            "Batch: 800, Loss: 0.12653277744320776, Accuracy: 0.928\n",
            "Batch: 810, Loss: 0.12552024101197407, Accuracy: 0.92875\n",
            "Batch: 820, Loss: 0.12567783510173172, Accuracy: 0.92855\n",
            "Batch: 830, Loss: 0.12476632287317724, Accuracy: 0.9289\n",
            "Batch: 840, Loss: 0.1243354708159429, Accuracy: 0.9292833333333334\n",
            "Batch: 850, Loss: 0.12482547511333772, Accuracy: 0.9292666666666667\n",
            "Batch: 860, Loss: 0.12596965423775677, Accuracy: 0.92795\n",
            "Batch: 870, Loss: 0.12541975894460802, Accuracy: 0.9282833333333333\n",
            "Batch: 880, Loss: 0.12503972284630133, Accuracy: 0.92875\n",
            "Batch: 890, Loss: 0.1250853284126038, Accuracy: 0.92905\n",
            "Batch: 900, Loss: 0.12520669818788333, Accuracy: 0.9287666666666666\n",
            "Batch: 910, Loss: 0.12438980288195388, Accuracy: 0.9292666666666667\n",
            "Batch: 920, Loss: 0.12420286091934644, Accuracy: 0.9293833333333333\n",
            "Batch: 930, Loss: 0.1250176758845229, Accuracy: 0.9288333333333333\n",
            "Epoch: 50, Loss: 0.12526637905459073, Accuracy: 0.9287666666666666\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 1024\n",
        "output_size = 10\n",
        "batch_size = 64\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.weights1 = np.random.randn(self.input_dim, self.hidden_dim)\n",
        "        self.weights2 = np.random.randn(self.hidden_dim, self.output_dim)\n",
        "\n",
        "        self.bias1 = np.zeros((1, self.hidden_dim))\n",
        "        self.bias2 = np.zeros((1, self.output_dim))\n",
        "\n",
        "    def forward(self, X, bs):\n",
        "        self.batch_size = bs\n",
        "\n",
        "        self.hidden_layer = np.dot(X, self.weights1) + self.bias1\n",
        "        self.hidden_activation = self.relu(self.hidden_layer)\n",
        "        self.output_layer = np.dot(self.hidden_activation, self.weights2) + self.bias2\n",
        "        self.predicted_output = self.softmax(self.output_layer)\n",
        "\n",
        "    def backward(self, X, y, learning_rate):\n",
        "        error = self.predicted_output - y\n",
        "\n",
        "        d_output = error\n",
        "        d_hidden = np.dot(d_output, self.weights2.T) * self.relu_derivative(self.hidden_activation)\n",
        "\n",
        "        self.weights2 -= learning_rate * np.dot(self.hidden_activation.T, d_output) / self.batch_size\n",
        "        self.bias2 -= learning_rate * np.sum(d_output, axis=0, keepdims=True) / self.batch_size\n",
        "        self.weights1 -= learning_rate * np.dot(X.T, d_hidden) / self.batch_size\n",
        "        self.bias1 -= learning_rate * np.sum(d_hidden, axis=0, keepdims=True) / self.batch_size\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exp_values = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def relu_derivative(self, x):\n",
        "        return (x > 0).astype(float)\n",
        "\n",
        "(X_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(-1, input_size) / 255.0\n",
        "\n",
        "y_train_encoded = np.zeros((y_train.shape[0], output_size))\n",
        "y_train_encoded[np.arange(y_train.shape[0]), y_train] = 1\n",
        "\n",
        "mlp = MLP(input_size, hidden_size, output_size)\n",
        "\n",
        "learning_rate = 0.001\n",
        "epochs = 50\n",
        "\n",
        "num_batches = X_train.shape[0] // batch_size\n",
        "\n",
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "def calculate_accuracy(y_actual, d):\n",
        "    correct_predictions = np.sum(np.argmax(y_actual, axis=1) == np.argmax(d, axis=1))\n",
        "    total_predictions = y_actual.shape[0]\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return accuracy\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch in range(num_batches):\n",
        "        start_idx = batch * batch_size\n",
        "        end_idx = (batch + 1) * batch_size\n",
        "\n",
        "        batch_X = X_train[start_idx:end_idx]\n",
        "        batch_y = y_train_encoded[start_idx:end_idx]\n",
        "\n",
        "        mlp.forward(batch_X, batch_size)\n",
        "        mlp.backward(batch_X, batch_y, learning_rate)\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            mlp.forward(X_train, batch_size)\n",
        "            d = mlp.predicted_output\n",
        "            y_actual = y_train_encoded\n",
        "\n",
        "            loss = np.mean(-(y_actual * np.log(d + 1e-10)))\n",
        "            accuracy = calculate_accuracy(y_actual, d)\n",
        "\n",
        "            print(f\"Batch: {batch}, Loss: {loss}, Accuracy: {accuracy}\")\n",
        "\n",
        "    mlp.forward(X_train, batch_size)\n",
        "    d = mlp.predicted_output\n",
        "    y_actual = y_train_encoded\n",
        "\n",
        "    loss = np.mean(-(y_actual * np.log(d + 1e-10)))\n",
        "    accuracy = calculate_accuracy(y_actual, d)\n",
        "\n",
        "    print(f\"Epoch: {epoch + 1}, Loss: {loss}, Accuracy: {accuracy}\")\n",
        "\n",
        "    losses.append(loss)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(epochs), losses)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Epochs vs Loss')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(epochs), accuracies)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Epochs vs Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEwNha46FVsL",
        "outputId": "785f900a-6619-4218-910f-c6f8c8a7e0ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean () = 3.0\n"
          ]
        }
      ],
      "source": [
        "def calculate_mean(x):\n",
        "    mean = sum(x) / len(x)\n",
        "\n",
        "    return mean\n",
        "\n",
        "x = [1, 2, 3, 4, 5]\n",
        "\n",
        "mean = calculate_mean(x)\n",
        "print(\"Mean () =\", mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMO0Vwj7w3WN",
        "outputId": "e6f8d48a-aa61-45e5-a875-64bc5e39f122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E(v) = [ 4.7 11.1]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_E(W, x, b):\n",
        "    W = np.array(W)\n",
        "    x = np.array(x)\n",
        "    b = np.array(b)\n",
        "\n",
        "    assert W.shape[1] == x.shape[0]\n",
        "    assert W.shape[0] == b.shape[0]\n",
        "\n",
        "    E = np.dot(W, x) + b\n",
        "\n",
        "    return E\n",
        "\n",
        "W = [[1, 2, 3], [4, 5, 6]]\n",
        "x = [0.5, 0.7, 0.9]\n",
        "b = [0.1, 0.2]\n",
        "\n",
        "result = calculate_E(W, x, b)\n",
        "print(\"E(v) =\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Drl3XLAM5Krj",
        "outputId": "15036da0-dd3e-48b6-f01e-bdca592aa9b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E(h) = [0.9909867  0.99998489]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_E(W, x, b):\n",
        "    W = np.array(W)\n",
        "    x = np.array(x)\n",
        "    b = np.array(b)\n",
        "\n",
        "    assert W.shape[1] == x.shape[0]\n",
        "    assert W.shape[0] == b.shape[0]\n",
        "\n",
        "    v = np.dot(W, x) + b\n",
        "\n",
        "    return v\n",
        "\n",
        "def calculate_sigmoid(v):\n",
        "    sigmoid = 1 / (1 + np.exp(-v))\n",
        "\n",
        "    return sigmoid\n",
        "\n",
        "W = [[1, 2, 3], [4, 5, 6]]\n",
        "x = [0.5, 0.7, 0.9]\n",
        "b = [0.1, 0.2]\n",
        "\n",
        "v = calculate_E(W, x, b)\n",
        "E_h = calculate_sigmoid(v)\n",
        "print(\"E(h) =\", E_h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yY4OT0w5ooR",
        "outputId": "fd55a285-22c6-4db4-dd44-3d821fd8f24a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E(O) = [0.76 1.2 ]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_E(w, h, B):\n",
        "    w = np.array(w)\n",
        "    h = np.array(h)\n",
        "    B = np.array(B)\n",
        "\n",
        "    assert w.shape[1] == h.shape[0]\n",
        "    assert w.shape[0] == B.shape[0]\n",
        "\n",
        "    E_O = np.dot(w, h) + B\n",
        "\n",
        "    return E_O\n",
        "\n",
        "w = [[0.1, 0.2], [0.3, 0.4]]\n",
        "h = [0.8, 0.9]\n",
        "B = [0.5, 0.6]\n",
        "\n",
        "result = calculate_E(w, h, B)\n",
        "print(\"E(O) =\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ev0Z34m8XyC",
        "outputId": "b8e4a7e9-d206-4b98-f316-700daa4fcc2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E(d) = [0.68135373 0.76852478]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_E(w, h, B):\n",
        "    w = np.array(w)\n",
        "    h = np.array(h)\n",
        "    B = np.array(B)\n",
        "\n",
        "    assert w.shape[1] == h.shape[0]\n",
        "    assert w.shape[0] == B.shape[0]\n",
        "\n",
        "    E_O = np.dot(w, h) + B\n",
        "\n",
        "    return E_O\n",
        "\n",
        "def calculate_sigmoid(O):\n",
        "    sigmoid = 1 / (1 + np.exp(-O))\n",
        "\n",
        "    return sigmoid\n",
        "\n",
        "w = np.array([[0.1, 0.2], [0.3, 0.4]])\n",
        "h = np.array([0.8, 0.9])\n",
        "B = np.array([0.5, 0.6])\n",
        "\n",
        "O = calculate_E(w, h, B)\n",
        "E_d = calculate_sigmoid(O)\n",
        "print(\"E(d) =\", E_d)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxUgokXemxLfbT/TU3bLGu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}